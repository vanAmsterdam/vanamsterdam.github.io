{
  "hash": "ffd49f498d4d7a62af10b58e733c18a1",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Flipping the sign of hazard ratios\neval: true\ndate: 2025-07-04\ncategories:\n- r\n- survival analysis\n- causal inference\n---\n\nHazard ratios are problematic summary measures for survival analysis [@dumasHowHazardRatios2025;@postBuiltinSelectionBias2024;@stensrudLimitationsHazardRatios2019;@aalenDoesCoxAnalysis2015]; even in well-conducted randomized trials, hazard ratios fail to capture a measure of causal effect, unless we make the (ludicrous) assumption that in the control group, every individual has the exact same hazard function.\n\nDumas and Stensrud recently summarized three main problems with hazard ratios [@dumasHowHazardRatios2025]: built-in selection bias, non-collapsibility, and violations of the proportional hazards assumption. \n\n## Non-collapsibility\n\nSay we have two subgroups defined by a feature $X$, for example, men and women.\nLet's assume that some measure of causal effect (e.g. a hazard ratio, odds ratio, risk difference or risk ratio) is $1.4$ in the first subgroup and $1.8$ in the second subgroup, what is then the measure of effect in the combined population?\nIntuitively, we would want this to be somewhere in between $1.4$ and $1.8$, meaning some (potentially weighted) average of the two subgroup effects.\nThis is only true for measures of effect that are collapsible, such as risk difference or risk ratio.\nThe hazard ratio and odds ratio are not collapsible, which means that the effect in the combined population can be below $1.4$ or above $1.8$.\n\n**An important question is: say the hazard ratio is above (or below) 1 in both subgroups, can it ever be below (or above) 1 in the combined population?**\n\nIt turns out that, yes, it can, as shown below in a simulation adapted from Post [@postBuiltinSelectionBias2024].\n\n## Simulation\n\nWe'll simulate 1000000 observations of a hypothetical two-arm randomized trial, with a feature $X$ that follows a compound Poisson-Gamma distribution, a baseline hazard function quadratic in time, and a treatment effect that is multiplicative on the baseline hazard.\n\nThe treatment effect is constant and the same for all values of $X$, meaning that there is heterogeneity in the hazard of the control group depending on $X$, but the **causal hazard ratio** (as defined in Post [@postBuiltinSelectionBias2024]) is constant across all values of $X$.\nIn practice, the hazard ratio estimated in trials is the Survivor Marginalized Causal Hazard Ratio, meaning that it is estimated from the patients who are still alive at a given time point, which is not the same as the causal hazard ratio.\n\nThe example that Post provides shows that the (time-varying) Survivor Marginalized Causal Hazard Ratio can start above 1, but over time drop below 1 because of the depletion of susceptibles in one trial arm (i.e. the hazard ratio's built-in selection bias).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# simulate from compound poisson\nlibrary(data.table)\nlibrary(survival)\n\nn = 1e6\n\nsimulate_cp_gamma <- function(rho, eta, nu, n = 1) {\n  # Simulate n independent draws from CPoi(rho, eta, nu)\n  replicate(n, {\n    N <- rpois(1, rho)\n    if (N == 0) {\n      return(0)\n    } else {\n      sum(rgamma(N, shape = eta, scale = nu))\n    }\n  })\n}\n\nset.seed(421)\n\n# Parameters\ntheta0 = 2 # variance\nrho <- 3/theta0    # Poisson rate (theta0)\neta <- .5     # Gamma shape\nnu  <- theta0 * 2 /3     # Gamma scale\n\n# Simulate 10000 values\nsamples <- simulate_cp_gamma(rho, eta, nu, n = 10000)\n\n# Empirical mean and variance\nemp_mean <- mean(samples)\nemp_var  <- var(samples)\n\n# Theoretical mean and variance\ntheo_mean <- rho * eta * nu\ntheo_var  <- rho * eta * nu^2 * (1 + eta)\n\n# cat(\"Empirical mean:\", emp_mean, \"\\n\")\n# cat(\"Theoretical mean:\", theo_mean, \"\\n\")\n# cat(\"Empirical variance:\", emp_var, \"\\n\")\n# cat(\"Theoretical variance:\", theo_var, \"\\n\")\n\n# Histogram\nhist(samples, breaks = 50, col = \"skyblue\", main = \"Compound Poisson-Gamma Samples\", xlab = \"X\")\n```\n\n::: {.cell-output-display}\n![](250704-hr-sign-flip_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\nWe now define the hazard and cumulative hazard functions used for the simulation.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# add baseline hazard\nl0_t <- function(t) (t^2) / 20\n# treatment effect \nmu = 3\n# hazard function\n\nl0 = function(t, a) {\n  l0_t(t) * mu^a\n}\n\n# cumulative hazard function\nL0 = function(t, a, x) {\n  x * ((t^3) / 60) * mu^a\n}\n\n# inverse of cum hazard fn\nL0_inv <- function(u, a, x) {\n  # Solve for t in L0(t, a, x) = u\n  # u = x * ((t^3) / 60) * mu^a\n  # Rearranging gives t = (60 * u / (x * mu^a))^(1/3)\n  (60 * u / (x * mu^a))^(1/3)\n}\n\n# setup data table\ndf <- data.table(x=samples, a=rep(c(0,1), each=n/2))\n# simulate u\ndf[, u := runif(.N)]\n# find the survival time\ndf[, time := L0_inv(-log(u), a, x)]\n# censor at maxtime\nmaxtime <- 20\ndf[, event:= time<= maxtime]\ndf[time>maxtime, `:=`(time=maxtime, event=0)]\n# plot survfit per a with colors\nsf <- survfit(Surv(time,event)~a, data=df)\nplot(sf, col=1:2)\nlegend(\"topright\", legend=c(\"a=0\", \"a=1\"), col=1:2, lty=1)\n```\n\n::: {.cell-output-display}\n![](250704-hr-sign-flip_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# fit cox model\ncox_model <- coxph(Surv(time,event)~a, data=df)\nprint(summary(cox_model))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCall:\ncoxph(formula = Surv(time, event) ~ a, data = df)\n\n  n= 1000000, number of events= 757625 \n\n    coef exp(coef) se(coef)  z Pr(>|z|)    \na 0.2231    1.2500   0.0023 97   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n  exp(coef) exp(-coef) lower .95 upper .95\na      1.25        0.8     1.244     1.256\n\nConcordance= 0.549  (se = 0 )\nLikelihood ratio test= 9394  on 1 df,   p=<2e-16\nWald test            = 9409  on 1 df,   p=<2e-16\nScore (logrank) test = 9447  on 1 df,   p=<2e-16\n```\n\n\n:::\n:::\n\n\n### Sign-flip over time\n\nThe marginal cox model estimate has the correct sign for the treatment effect, but we will see that over time the hazard ratio changes sign\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## check time-varying hazard\nzph <- cox.zph(cox_model)\nplot(zph, var = \"a\")  # Plots log(HR) over time with smoothing\nabline(h = 0, col = \"red\", lty = 2)  # Add a horizontal line at 0 for reference\n```\n\n::: {.cell-output-display}\n![](250704-hr-sign-flip_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n### Marginal sign-flip with Delayed Entry\n\nCan this ever mean we estimate a marginal hazard ratio of the wrong sign in an RCT? It is possible in the context of delayed entry.\nDelayed entry means that some patients enter the study at a later time point.\nAn example would be if we randomize patients to a certain treatment from $t=0$, but are only able to include their information after some (random) lead time. For example, if we randomize regions in a country to add chloride to the drinking water at a fixed time point $t=0$ [like in @tofailEffectWaterQuality2018], but for logistical reasons, we can only start collecting follow-up data on individuals in those regions in a staggered fashion, with some regions starting data collection at $t=0$, some at $t=1$, and so on.\n\nBecause the hazard ratio changes sign over time, if we include patients who enter the study at a later time point, we can end up with a hazard ratio that is below 1, even though the causal hazard ratio is above 1 for all patients at all time points.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# fit model with delayed entry\ndf[, entry_time:=runif(.N, 0, maxtime)]\ncox_model_delayed <- coxph(Surv(entry_time, time, event) ~ a, data = df[time>entry_time])\nsummary(cox_model_delayed)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCall:\ncoxph(formula = Surv(entry_time, time, event) ~ a, data = df[time > \n    entry_time])\n\n  n= 393157, number of events= 150782 \n\n      coef exp(coef) se(coef)      z Pr(>|z|)    \na -0.08297   0.92037  0.00521 -15.93   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n  exp(coef) exp(-coef) lower .95 upper .95\na    0.9204      1.087     0.911    0.9298\n\nConcordance= 0.524  (se = 0.001 )\nLikelihood ratio test= 254.6  on 1 df,   p=<2e-16\nWald test            = 253.7  on 1 df,   p=<2e-16\nScore (logrank) test = 253.8  on 1 df,   p=<2e-16\n```\n\n\n:::\n:::\n\n\n## Conclusion\n\nCan the marginal hazard ratio estimated in a randomized controlled trial have the wrong sign? Yes, it can—even when the causal hazard ratio is constant—if we allow for delayed entry. Is this likely to happen in practice? Probably not. But that doesn’t mean we should continue using the hazard ratio as a default summary measure. Better alternatives exist that can be directly derived from survival curves, such as absolute risk differences, risk ratios, and differences in restricted mean survival time.\n\n## References\n",
    "supporting": [
      "250704-hr-sign-flip_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}