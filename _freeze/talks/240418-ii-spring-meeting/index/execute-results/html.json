{
  "hash": "03a102478f1c31204ef56ed49af4c4dc",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: AI and its (mis)uses in medical research and practice\ndate: 2024/04/18\ndraft: false\nformat:\n    revealjs:\n        incremental: true\nexecution:\n    echo: false\n---\n\n\n# What is AI? \n\n\n## What is AI?\n\n:::{.callout-tip}\n## What is artificial intelligence?\ncomputers doing tasks that normally require intelligence ^[these are my own definitions]\n:::\n\n:::{.fragment}\n:::{.callout-tip}\n## What is artificial *general* intelligence?\nGeneral purpose AI that performs a range of tasks in different domains like humans\n:::\n:::\n\n## AI subsumes rule-based systems and machine learning\n\n-   Rule-based AI: knowledge base of rules\n-   Machine learning: statistical learning from examples\n    -   (traditional) machine learning (logistic regression, SVM, RF,\n    GBM)\n    -   modern machine learning: deep learning and foundation models\n\n## Rule-based systems are AI\n\n-   rule: all cows are animals\n-   observation: this is a cow $\\to$ it is an animal\n-   applications:\n    - medication interaction checkers\n    - bedside patient monitors\n\n\n## machine learning: statistical learning from examples\n\n-   observe examples from some distribution (age, sex, BMI, medication,\n    side-effect)\n-   *learn* \"patterns\" in the data\n-   different tasks in hierarchical order:\n    -   generation\n    -   conditional generation\n    -   discrimination\n-   policy learning\n    - (maybe not so useful for medicine as requires many experiments)\n\n## Machine learning task: generation\n\n\n::: {.cell}\n\n:::\n\n\n::: {.columns}\n:::: {.column width=\"40%\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-2-1.png){width=960}\n:::\n:::\n\n\n::::\n\n:::: {.column width=\"60%\"}\ndata:\n\\begin{align}\n  \\text{length}_i,\\text{weight}_i,\\text{sex}_i \\sim p(l,w,s)\n\\end{align}\n\n1. generation: use samples to learn model ($\\theta$) for distribution $p$\n\\begin{align}\n  \\text{length}_j,\\text{weight}_j,\\text{sex}_j \\sim p_{\\theta}(l,w,s)\n\\end{align}\n::::\n\n:::\n\n## What is a large-language model like chatGPT?\n\n# Using AI in research and medical practice\n\n## ML versus statistics, when to use what\n\n## Safe use of AI models in medical practice\n\n## When accurate prediction models yield harmful self-fulfilling prophecies\n\n## The rest\n\n\n\n:::::: frame\n### Machine learning tasks\n\n::::: columns\n::: column\n0.5\n\n<figure>\n<p><embed src=\"figs/gen_scatter.pdf\" /> <embed src=\"figs/gen_iso.pdf\" />\n<embed src=\"figs/gen_girl.pdf\" /> <embed\nsrc=\"figs/gen_scatter.pdf\" /></p>\n</figure>\n:::\n\n::: column\n0.5\n\n<figure>\n<p><embed src=\"figs/gen_full.pdf\" /> <embed src=\"figs/gen_boy.pdf\" />\n<embed src=\"figs/class_logistic.pdf\" /></p>\n</figure>\n:::\n:::::\n::::::\n\n::: frame\n### Machine learning task: reinforcement learning\n\n#### Maybe not so useful for clinical research as requires many experiments\n\n![image](figs/reinforcement_learning.png){width=\"80%\"}\n:::\n\n:::::: frame\n### Machine learning is statistical learning with flexible models\n\n::::: columns\n::: column\n0.5\n\n-   There is no fundamental difference between statistics and machine\n    learning\n\n-   both optimize parameters to improve some criterion (loss /\n    likelihood) that measures model fit to data\n\n-   models used in machine learning are more flexible\n:::\n\n::: column\n0.5\n\n<figure>\n<p><img src=\"figs/ml_vs_stats.png\" style=\"width:90.0%\" alt=\"image\" />\n<img src=\"figs/a_machine_learning.jpeg\" style=\"width:90.0%\"\nalt=\"image\" /> <img src=\"figs/curve_fitting_xkcd_ 2048.png\"\nstyle=\"width:90.0%\" alt=\"image\" /></p>\n</figure>\n:::\n:::::\n::::::\n\n::: frame\n### machine learning and statistics differences\n\n-   whereas statistics is more concered with *inference* regarding\n    parameters of a distribution (e.g. difference in survival time\n    between treatments) in which the bespoke model is an integral part,\n    machine learning focusses more on prediction accuracy, treating the\n    model as a black box\n\n-   can learn more complicated relationships (non-linearities,\n    interactions)\n\n-   also: can learn feature representations\n\n-   nothing comes for free: need (much) more data\n:::\n\n::: frame\n### models with much learning capacity can overfit\n\n#### meaning they fit the noise in the training data and fail to genearlize to new data\n\n<figure>\n<p><img src=\"figs/overfitting_underfitting.png\" style=\"width:80.0%\"\nalt=\"image\" /> <img src=\"figs/bias_variance.png\" style=\"width:80.0%\"\nalt=\"image\" /></p>\n</figure>\n:::\n\n::: frame\n### Modern machine learning (neural networks a.k.a. deep learning)\n\n#### computational models with multiple layers loosely inspired by mammalian brain\n\n<figure>\n<p><img src=\"figs/nn.png\" style=\"width:90.0%\" alt=\"image\" /> <img\nsrc=\"figs/cnn_overview.jpg\" style=\"width:90.0%\" alt=\"image\" /></p>\n</figure>\n:::\n\n::: frame\n### Modern machine learning (neural networks a.k.a. deep learning)\n\n-   For complex tasks, neural networks keep getting better with:\n\n    -   more compute resources\n\n    -   bigger data\n\n    -   bigger models (enabled by data and compute)\n:::\n\n::: frame\n### modern machine learning: deep learning and foundation models\n\n-   build models to (extreme) scale in data, compute and number of\n    parameters ![image](figs/biggerdata.png){width=\"70%\"}\n\n-   classical learning theory does not seem to apply (huge models that\n    don't overfit)\n\n-   e.g. convolutional neural networks\n    ![image](figs/breastcancersweden.png){width=\"70%\"}\n\n-   large language models like chatGPT\n:::\n\n::: frame\n### Large language models\n\n#### auto-regressive next word predictors\n\n-   large language models learn from large datasets with self-supervised\n    objectives\n\n-   fine-tune for tasks\n\n-   not well-understood but very impressive\n:::\n\n::: frame\n### Training large language models like chatGPT\n\n#### masked-word prediction\n\n![image](figs/nextwordpred.jpeg){width=\"60%\"}\n\n-   On a large corpus: predict the most likely \\[mask\\] in this sentence\n    (answer = word)\n\n-   Next text generation: start with 'prompt' (=context) and predict\n    next likely word\n\n-   one-word at a time, each time updating the *context* (=\n    *auto-regressive*)\n\n[^1]\n:::\n\n::: frame\n### Does this create 'good answers'? Internet is full of harmful text\n\n#### Need a filter\n\n-   problem: no single good answer, some are unwanted (e.g. abusive)\n\n-   let pre-trained model generate 2 responses to many prompts\n\n-   let human judge which of the 2 is better\n\n-   reinforcement-learning with human feedback (RLHF)\n\n-   huge difference in user experience\n:::\n\n::: frame\n### writing a good prompt\n\n#### tasks that look like language modeling\n\n-   provide context\n\n    -   not: \"describe vancomycin\"\n\n    -   but: \"I'm in training as an hospital pharmacist, learning more\n        about antiobiotic treatments in the intensive care, what is\n        important for me to know about vancomycin?\"\n\n-   tasks that look like natural language completion will tend to work\n    well\n\n    -   not: \\[statement\\] $\\to$ TRUE/FALSE\n\n    -   but: is the following statement true? \\[statement\\], please\n        provide your answer below\n:::\n\n:::::: frame\n### rule-based vs LLMs\n\n::::: columns\n::: column\n0.5 rule-based\n\n-   deduction from explicit knowledge\n\n-   knowledge verifiable and fast\n\n-   constrained to deducible\n\n<figure>\n<p><img src=\"figs/library_bing.jpeg\" style=\"width:60.0%\" alt=\"image\" />\n<img src=\"figs/clippit.png\" style=\"width:60.0%\" alt=\"image\" /></p>\n</figure>\n:::\n\n::: column\n0.5\n\n-   extracted from observed data\n\n-   unverifiable and compute intensive\n\n-   \"chatGPT seems to *know*(?) much\"\n\n<figure>\n<p><img src=\"figs/brain_bing.jpeg\" style=\"width:60.0%\" alt=\"image\" />\n<img src=\"figs/chatgpt.jpg\" style=\"width:60.0%\" alt=\"image\" /></p>\n</figure>\n:::\n:::::\n::::::\n\n::: frame\n### new research in LLMs\n\n#### presented at NeurIPS, december 2023 (toolformer, META-AI)\n\n<figure>\n<p><img src=\"figs/toolformer_motivation.png\" style=\"width:80.0%\"\nalt=\"image\" /> <img src=\"figs/toolformer.png\" style=\"width:80.0%\"\nalt=\"image\" /></p>\n</figure>\n:::\n\n::: frame\n### Take-away part 1:\n\n#### overview of AI and mL\n\n-   AI subsumes rule-based programs and machine learning\n\n-   ML is statistical learning with flexible models\n\n-   modern ML uses large models that seem to violate classical learning\n    theory\n\n-   chatGPT is based on auto-regressive next-token prediction and\n    reinforcement learning with human feedback\n\n-   chatGPT produces beautiful mistakes: eloquently written logical\n    fallacies, and thus needs expert 'supervision'\n\n-   chatGPT does well on natural-language-like tasks (i.e. not \\\"is this\n    sentence true or false\\\")\n:::\n\n::: frame\nbut what to *do*?\n:::\n\n::: frame\n### two questions\n\nQuestion 1\n\n-   prediction model of $Y|X$ fits the data really well (AUC = 0.99 and\n    perfect calibration)\n\n-   will changing $X$ induce a change $Y$?\n:::\n\n::: frame\n### Improving the world is a causal task\n\n-   statistics / ML: what to expect when we passively observe the world\n\n-   *not* how we can *intervene* to make things better\n\n-   Question 1\n\n    -   yellowish fingers predict lung cancer, paint fingers to skin\n        color?\n\n    -   weight loss predicts death in lung cancer, send patients to\n        couch with McDonalds?\n\n    ![image](figs/couch_patato.jpeg){width=\"40%\"}\n:::\n\n::: frame\n### How to learn about the effects of interventions?\n\n#### Do the interventions in (psuedo) experiments\n\n-   Why not look back at data and compare outcomes of patients treated\n    with different medications?\n\n-   Patients who take anti-hypertensive medications have more heart\n    attacks\n\n-   confounding by indication\n:::\n\n::: frame\n### Causal inference\n\n#### Studies causal questions, answers that tell us what to do\n\n-   studies questions on effects of interventions\n\n-   statistics / ML: what to expect when we passively observe the world\n\n-   causal inference: what if I change something?\n\n-   field of causal inference provides a language to express causal\n    quantities\n\n-   and tell us how to anser them\n\n-   these answers tell us what to do\n:::\n\n::: frame\n### Causal effects defined with potential outcomes\n\n#### The individual treatment effect\n\n<figure>\n<p><img src=\"figs/ite1.png\" style=\"width:80.0%\" alt=\"image\" /> <img\nsrc=\"figs/ite2.png\" style=\"width:80.0%\" alt=\"image\" /> <embed\nsrc=\"figs/ite3.pdf\" style=\"width:80.0%\" /> <embed src=\"figs/ite_pos.pdf\"\nstyle=\"width:80.0%\" /></p>\n</figure>\n:::\n\n::: frame\n### Causal effects defined with potential outcomes\n\n#### The average treatment effect\n\n<figure>\n<p><img src=\"figs/ate1.png\" alt=\"image\" /> <img src=\"figs/ate2.png\"\nalt=\"image\" /> <img src=\"figs/ate3.png\" alt=\"image\" /> <img\nsrc=\"figs/ate.png\" alt=\"image\" /></p>\n</figure>\n:::\n\n::: frame\n### Treatment effect estimation requires exchangeability\n\n#### Which is hard to ensure in non-experimental (observational data)\n\n<figure>\n<div class=\"center\">\n\n</div>\n</figure>\n:::\n\n::: frame\n### Randomized controlled trials gaurantee exchangeability\n\n#### Thus allow for causal inference\n\n<figure>\n<div class=\"center\">\n\n</div>\n</figure>\n\n$$\\begin{aligned}\n            \\onslide<2->{Y_t &= Y|T=t}\n            %\\onslide<3->{Y|do(T),Z &= Y|T,Z \\\\}\n            %\\onslide<4->{Y|do(T) &= \\sum_Z Y|T,Z}\n        \n\\end{aligned}$$\n:::\n\n::: frame\n### Causal inference\n\n#### summary\n\n-   defines causal quantities / questions\n\n-   need exchangeability to estimate treatment effects\n\n-   holds by design in RCTs\n\n-   may hold outside of RCTs (=observational data), conditional on\n    covariates\n\n-   may be unobserved confounding\n\n-   RCT for everything?\n:::\n\n:::: frame\n### Problems with RCTs for medical decision making\n\n#### RCTs solve confounding but have their own limitations\n\n::: columns\n:::\n::::\n\n:::::: frame\n### Ways forward\n\n-   make right assumptions with observational data\n\n    -   known confounders\n\n    -   known functional forms for phenomena\n\n-   use observational and RCT data\n\n-   *active area of research*\n\n    -   ML x CI: more flexible causal inference\n\n    -   other way around: make ML more robust with CI insights\n\n        -   sources of variation (*domain shifts*)\n\n        -   unwanted biases\n\n        -   make ML more efficient by generating pre-training data\n\n::::: columns\n::: column\n0.7\n\n<figure>\n<p><img src=\"figs/elimbias_title.png\" style=\"width:80.0%\" alt=\"image\" />\n<img src=\"figs/protect_title.png\" style=\"width:80.0%\" alt=\"image\" />\n<img src=\"figs/offset_title.png\" style=\"width:80.0%\" alt=\"image\" /></p>\n</figure>\n:::\n\n::: column\n0.3\n\n<figure>\n<p><img src=\"figs/qr_elimbias.png\" style=\"width:80.0%\" alt=\"image\" />\n<img src=\"figs/qr_protect.png\" style=\"width:80.0%\" alt=\"image\" /> <img\nsrc=\"figs/qr_offset.png\" style=\"width:80.0%\" alt=\"image\" /></p>\n</figure>\n:::\n:::::\n::::::\n\n::: frame\nML and causal inference\\\nQuestion 2: risk prediction model used for treatment decisions\\\naccurate outcome prediction models can yield harmful self-fulfilling\nprophecies\\\n:::\n\n::: frame\n#### accurate outcome prediction models can yield harmful self-fulfilling prophecies\n\n<figure>\n<p><embed src=\"figs/new_overview1a.pdf\" style=\"width:70.0%\" /> <embed\nsrc=\"figs/new_overview1b.pdf\" style=\"width:70.0%\" /> <embed\nsrc=\"figs/new_overview1c.pdf\" style=\"width:70.0%\" /> <embed\nsrc=\"figs/new_overview2a.pdf\" style=\"width:70.0%\" /> <embed\nsrc=\"figs/new_overview2b.pdf\" style=\"width:70.0%\" /> <embed\nsrc=\"figs/new_overview3a.pdf\" style=\"width:70.0%\" /> <embed\nsrc=\"figs/new_overview3b.pdf\" style=\"width:70.0%\" /></p>\n</figure>\n:::\n\n::: frame\n### Prediction modeling very popular in medical research\n\n![image](figs/predmodelsoverview.pdf){width=\"70%\"}\n:::\n\n::: frame\nbuilding models for decision support without regards for the historic\ntreatment policy is a bad idea\n:::\n\n::: frame\n![image](figs/policy_changea1.png){width=\"\\\\textwidth\"}\n![image](figs/policy_changea3.png){width=\"\\\\textwidth\"}\n![image](figs/policy_changeax.png){width=\"\\\\textwidth\"}\n![image](figs/policy_changeb2.png){width=\"\\\\textwidth\"}\n![image](figs/policy_changebx.png){width=\"\\\\textwidth\"}\n:::\n\n::: frame\nthe question is not \"is my model accurate before / after deploytment\",\nbut did deploying the model improve patient outcomes?\n:::\n\n::: frame\nTreatment-naive risk models\n![image](figs/txnaive1.png){width=\"\\\\textwidth\"}\n![image](figs/txnaive2.png){width=\"\\\\textwidth\"}\n:::\n\n::: frame\nOther risk models: condition on given treatment and traits\n![image](figs/postdecision1.png){width=\".9\\\\textwidth\"}\n:::\n\n::: frame\nOther risk models: condition on given treatment and traits\n![image](figs/postdecision2.png){width=\".9\\\\textwidth\"} unobserved\nconfounding (hat type) leads to wrong treatment decisions\n:::\n\n::: frame\nRecommended validation practices do not protect against harmbecause they\ndo not evaluate the policy change\n![image](figs/tripod_title.png){width=\".5\\\\textwidth\"}\n![image](figs/ajcc_title.png){width=\".5\\\\textwidth\"}\n:::\n\n::: frame\nBigger data does not protect against harmful risk models\n![image](figs/biggerdata.png){width=\"80%\"}\n:::\n\n::: frame\nMore flexible models do not protect against harmful risk models\n![image](figs/morelayers.png){width=\"50%\"}\n:::\n\n::: frame\n### Gap between prediction accuracy and value for decision making\n\n![image](figs/mindthegap.pdf){width=\"80%\"}\n:::\n\n::: frame\n[what to do?]{.alert}\n\n1.  Evaluate policy change (cluster randomized controlled trial)\n\n2.  Build models that are likely to have value for decision making\n:::\n\n::: frame\nPrediction-under-intervention modelsPredict outcome *under hypothetical\nintervention* of giving certain treatment\n![image](figs/predictionunderintervention.png){width=\"\\\\textwidth\"}\n:::\n\n::: frame\nWhen developing risk models, always discuss:\n![image](figs/policy_changeb1.png){height=\".6\\\\textheight\"}\n![image](figs/policy_changeb2.png){height=\".6\\\\textheight\"}\n![image](figs/policy_changebx.png){height=\".6\\\\textheight\"}\n\n1.  what is effect on treatment policy?\n\n2.  what is effect on patient outcomes?\n:::\n\n:::::: frame\nTakeaway Don't assume predicting well leads to good decisions, think\nabout the policy change\\\nÂ \\\n\n::::: columns\n::: column\n0.5 ![image](figs/comment_qr.png){width=\".5\\\\textwidth\"}\\\nDecision making in cancer: causal questions require causal answers\n:::\n\n::: column\n0.5 ![image](figs/qr_selffulfilling.png){width=\".5\\\\textwidth\"}\\\nWhen accurate prediction models yield harmful sel-fulfilling prophecies\n:::\n:::::\n::::::\n\n::: frame\n### take-aways\n\n-   AI subsumes rule-based programs and machine learning\n\n-   machine learning is statistical learning from data with flexible\n    mdoels\n\n-   modern machine learning does well with scale\n\n-   chatGPT is based on auto-regressive next-token prediction and\n    reinforcement learning with human feedback\n\n-   chatGPT produces beautiful mistakes: eloquently written logical\n    fallacies\n\n-   chatGPT does well on natural-language-like tasks\n\n-   prediction: what to expect when passively observing the world\n\n-   causal inference: what happens when I change something?\n\n-   prediction models can cause harmful self-fulfilling prophecies when\n    used for decision making\n\n-   when building prediction models for decision support, you cannot\n    ignore decisions on the treatments in historic data\n\n-   models for prediction-under-intervention have foreseeable effects\n    when used for decision making\n\n-   ultimate test of model utility is determined by outcomes in\n    (cluster) RCT\n:::\n\n::: frame\nthank you\n:::\n\n[^1]: image by akshay pachaar\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}