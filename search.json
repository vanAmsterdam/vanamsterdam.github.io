[
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Posts",
    "section": "",
    "text": "The difference between intervention and counterfactuals\n\n\n\n\n\n\ncausal inference\n\n\nstatistics\n\n\n\n\n\n\n\n\n\nJul 25, 2021\n\n\nWouter van Amsterdam\n\n\n\n\n\n\n\n\n\n\n\n\nWhen good predictions lead to bad decisions\n\n\n\n\n\n\ncausal inference\n\n\npredictions\n\n\n\n\n\n\n\n\n\nJul 20, 2021\n\n\nWouter van Amsterdam\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "talks/240312-dsbiostats-twitter/index.html#why-i-use-x-1",
    "href": "talks/240312-dsbiostats-twitter/index.html#why-i-use-x-1",
    "title": "Wouter’s twitter X-peri(ments/ences)",
    "section": "Why (I) use X?",
    "text": "Why (I) use X?\n\nlearn\n\npapers\nevents (AAAI 2019)\ndiscussions of (/ with?) famous researchers\n\nadvertise work\n\nRCT of tweeted papers: 4x citations in 1y (group of 58k followers) \n\nconnect"
  },
  {
    "objectID": "talks/240312-dsbiostats-twitter/index.html#why-not-use-x",
    "href": "talks/240312-dsbiostats-twitter/index.html#why-not-use-x",
    "title": "Wouter’s twitter X-peri(ments/ences)",
    "section": "Why not use X?",
    "text": "Why not use X?\n\ntwitter is dead, and X is dying\ndistractions\npolitics"
  },
  {
    "objectID": "talks/240312-dsbiostats-twitter/index.html#x-compared-to",
    "href": "talks/240312-dsbiostats-twitter/index.html#x-compared-to",
    "title": "Wouter’s twitter X-peri(ments/ences)",
    "section": "X compared to",
    "text": "X compared to\n\nlinkedin: fake interactions\ntwitter: too real interactions\nmastodon: too hacky / nerdy?\nthreads: twitter clone by meta (facebook)\nbluesky: way to go?"
  },
  {
    "objectID": "talks/240312-dsbiostats-twitter/index.html#twitter-history-and-status",
    "href": "talks/240312-dsbiostats-twitter/index.html#twitter-history-and-status",
    "title": "Wouter’s twitter X-peri(ments/ences)",
    "section": "Twitter history and status",
    "text": "Twitter history and status\n\njoined: Jan 2014   \n500-ish followers (Maarten has approx. 41400)\n500-ish following\n15-minutes a day but waning"
  },
  {
    "objectID": "talks/240312-dsbiostats-twitter/index.html#first-tweet-that-got-a-like",
    "href": "talks/240312-dsbiostats-twitter/index.html#first-tweet-that-got-a-like",
    "title": "Wouter’s twitter X-peri(ments/ences)",
    "section": "first tweet that got a like",
    "text": "first tweet that got a like"
  },
  {
    "objectID": "talks/240312-dsbiostats-twitter/index.html#first-ad-for-own-paper-on-causal-ml-liked-by-judea-pearl",
    "href": "talks/240312-dsbiostats-twitter/index.html#first-ad-for-own-paper-on-causal-ml-liked-by-judea-pearl",
    "title": "Wouter’s twitter X-peri(ments/ences)",
    "section": "first ad for own paper on causal ML (liked by judea pearl)",
    "text": "first ad for own paper on causal ML (liked by judea pearl)"
  },
  {
    "objectID": "talks/240312-dsbiostats-twitter/index.html#first-joke-kind-of-success",
    "href": "talks/240312-dsbiostats-twitter/index.html#first-joke-kind-of-success",
    "title": "Wouter’s twitter X-peri(ments/ences)",
    "section": "first joke (kind-of success)",
    "text": "first joke (kind-of success)"
  },
  {
    "objectID": "talks/240312-dsbiostats-twitter/index.html#first-tweet-that-went-viral-recommending-a-paper",
    "href": "talks/240312-dsbiostats-twitter/index.html#first-tweet-that-went-viral-recommending-a-paper",
    "title": "Wouter’s twitter X-peri(ments/ences)",
    "section": "first tweet that went ‘viral’: recommending a paper",
    "text": "first tweet that went ‘viral’: recommending a paper\n\n\n\n\n\n\n259 retweets\n697 likes\n126k views\n8 new followers\nelias bareinboim (respected researcher in field) reached out and congratulated me"
  },
  {
    "objectID": "talks/240312-dsbiostats-twitter/index.html#first-paper-run-through-tweet-35-retweet-86-likes-now-20-citations",
    "href": "talks/240312-dsbiostats-twitter/index.html#first-paper-run-through-tweet-35-retweet-86-likes-now-20-citations",
    "title": "Wouter’s twitter X-peri(ments/ences)",
    "section": "first paper run-through tweet (35 retweet, 86 likes); now 20 citations",
    "text": "first paper run-through tweet (35 retweet, 86 likes); now 20 citations\nhttps://x.com/WvanAmsterdam/status/1204732856867704833?s=20\n\nnice reactions:\n\nhttps://x.com/JAASANTINHA/status/1221926874953154563?s=20\nhttps://x.com/hilseth_mistrov/status/1204878693149134848?s=20\n\nfavorite tweet (meme on prediction models) https://x.com/WvanAmsterdam/status/1417886117530112000?s=20\nsnarky reply (Andrew Vickers): https://x.com/VickersBiostats/status/1417905175948374016?s=20\nreply from yudea pearl https://x.com/yudapearl/status/1428026853365673986?s=20\nbiggest own tweet (thesis cover): https://x.com/WvanAmsterdam/status/1564209229745033217?s=20\n93k impressions\n673 likes\n53 retweets\n6 new followers\nask for help (prospective general population cohorts) https://x.com/WvanAmsterdam/status/1582304674321158144?s=20 ## Twitter post 1 using embed plugin\n\nTo embed a Tweet into your Quarto html document you can use the shortcode like this:"
  },
  {
    "objectID": "talks/240312-dsbiostats-twitter/index.html#twitter-post-with-html-embedding",
    "href": "talks/240312-dsbiostats-twitter/index.html#twitter-post-with-html-embedding",
    "title": "Wouter’s twitter X-peri(ments/ences)",
    "section": "twitter post with html embedding",
    "text": "twitter post with html embedding"
  },
  {
    "objectID": "posts/210725-counterfactualvsinterventional.html",
    "href": "posts/210725-counterfactualvsinterventional.html",
    "title": "The difference between intervention and counterfactuals",
    "section": "",
    "text": "Sometimes there is confusion about the difference between counterfactual predictions and interventional predictions. According to the ladder of causation introduced by Pearl and presented in the ‘Book of Why’, interventional is rung 2 and counterfactuals are rung 3 (associations are rung 1). Models that predict the treatment effect for a new patient based on some covariates \\(X\\) require interventional models, not counterfactual. The difference between interventional and counterfactual models is relevant as counterfactual models require more assumptions, they require knowledge of the structural mechanisms. In words, the interventional question is “What is the expected outcome under treatment \\(t\\) given that we know \\(X\\)”, or “What is the expected difference in outcomes between treatment \\(t\\) and \\(t'\\) given that we know \\(X\\)”. The counterfactual question is “What would have been the outcome if we had given treatment \\(t'\\) given that we gave \\(t\\) and observed outcome \\(y\\)”."
  },
  {
    "objectID": "posts/210725-counterfactualvsinterventional.html#intro",
    "href": "posts/210725-counterfactualvsinterventional.html#intro",
    "title": "The difference between intervention and counterfactuals",
    "section": "",
    "text": "Sometimes there is confusion about the difference between counterfactual predictions and interventional predictions. According to the ladder of causation introduced by Pearl and presented in the ‘Book of Why’, interventional is rung 2 and counterfactuals are rung 3 (associations are rung 1). Models that predict the treatment effect for a new patient based on some covariates \\(X\\) require interventional models, not counterfactual. The difference between interventional and counterfactual models is relevant as counterfactual models require more assumptions, they require knowledge of the structural mechanisms. In words, the interventional question is “What is the expected outcome under treatment \\(t\\) given that we know \\(X\\)”, or “What is the expected difference in outcomes between treatment \\(t\\) and \\(t'\\) given that we know \\(X\\)”. The counterfactual question is “What would have been the outcome if we had given treatment \\(t'\\) given that we gave \\(t\\) and observed outcome \\(y\\)”."
  },
  {
    "objectID": "posts/210725-counterfactualvsinterventional.html#example",
    "href": "posts/210725-counterfactualvsinterventional.html#example",
    "title": "The difference between intervention and counterfactuals",
    "section": "Example",
    "text": "Example\nTo illustrate the difference between a counterfactual prediction and an interventional prediction (or conditional average treatment effect estimates), consider this very simple setup.\nYou have data from a randomized trial with two treatment arms \\(t \\in \\{0,1\\}\\) and an outcome \\(Y\\) on a continuous scale. Denote \\(Y_0\\) the potential outcome under intervening on treatment \\(t=0\\) and \\(Y_1\\) the potential outcome under intervening on treatment \\(t=1\\). As we are dealing with data from a randomized trial, we can easily estimate the average treatment effect as \\(E[Y_1 - Y_0] = E[Y|t=0] - E[Y|t=1]\\), assuming consistency (ignorability and overlap are satisfied due to the study design).\nA counterfactual question is: what would have been the outcome \\(Y_0\\) under treatment \\(t=1\\), given that we observed the outcome \\(y_1\\) under treamtent \\(t=1\\), so it is \\(E[Y_0|Y=y_1, t=1]\\).\nNow assume that the data come from a mixture of Gaussians such that\n\\[y|t \\sim (1 - t) \\mathcal{N}(1,0.1^2) + t \\mathcal{N}(10,2.5^2)\\]\nAnd \\(p(t=1)=0.5\\) so both arms are equally large. Treatment \\(t=1\\) leads to higher outcome but also more spread. The relevant interventional expectations are easily calculated by just calculating group means \\(E[Y_0] = E[Y|t=0] = 1\\), \\(E[Y_1] = E[Y|t=1] = 10\\).\n\nCalculating the counterfactuals\nTo see that calculating counterfactuals requires more knowledge, namely of the structural equations, we now calculate the counterfactual prediction for a patient with \\(Y=Y_1=15\\). This is a patient with a relatively large ‘residual’, the outcome is 2 standard deviations above the mean for treatment group \\(t=1\\).\nFirst we calculate the counterfactual outcome under a wrong outcome model. Researchers tried to model the outcomes using linear regression, and failed to appreciate the difference in variances between the two treatment arms (heteroscedasticity). Assuming a large sample, they will arrive at a model:\n\\[\\hat{y}_{\\text{wrong}} = 1 + t * 9 + \\mathcal{N}(0,\\sigma^2)\\]\nWhere \\(\\sigma = \\sqrt{\\frac{0.1^2 + 2.5^2}{2}} \\approx 1.77\\) (standard devation of mixture of Gaussians with (conditional) mean of 0 and standard deviations 0.1 and 2.5, with 50 / 50 mixing). Note that the estimate of the treatment effect is correct, and so are \\(E[Y_0]\\) and \\(E[Y_1]\\). If there was a binary pre-treatment covariate, the conditional average treatment effect could be estimated by repeating this exercise for both levels of the covariate. To calculate the counterfactual outcome of our patient, we first need to determine the value of their noise variable for the outcome. According to \\(\\hat{y}_{\\text{wrong}}\\), the residual for a patient with \\(Y_1=15\\) is \\(5\\), which is \\(5/\\sigma \\approx 2.82\\) standard deviations away from the expected value for \\(t=1\\). Given this residual we can now calculate the counterfactual:\n\\[\\widehat{E_{\\text{wrong}}}[Y_0|Y=15,t=1] \\approx E[Y_0] + 2.82 \\sigma =6\\]\nGiven that we know the data generating mechanism, we know that this counterfactual prediction is 50 standard deviations from the conditional mean of \\(t=0\\) in the data generating mechanism, clearly this counterfactual prediction is wrong.\nIf we did model the data correctly with a mixture of Gaussians indexed by the treatment group, we would instead say that \\(Y_1=15\\) is 2 standard deviations above the conditional mean, and we would calculate:\n\\[\\widehat{E^*}[Y_0|Y=15,t=1] = E[Y_0] + 2 * 0.1 =1.2\\]\nWhich is correct."
  },
  {
    "objectID": "posts/210725-counterfactualvsinterventional.html#conclusion",
    "href": "posts/210725-counterfactualvsinterventional.html#conclusion",
    "title": "The difference between intervention and counterfactuals",
    "section": "Conclusion",
    "text": "Conclusion\nTo calculate counterfactual predictions, you need to correctly specify the structural equations. For treatment recommendations for future patients, these are not needed, interventional estimates (conditional average treatment effect) are sufficient, and obviously the factual outcome is not observed yet so it is impossible to calculate counterfactuals (the factual is not yet known).\nPost-script: for ‘real’ patient counsellling the expected values under the treatments would generally not suffice, some measure of spread / uncertainty would be required. Ideally, one would learn the distribution of the potential outcomes."
  },
  {
    "objectID": "posts/210720-good_predictions_bad_decisions.html",
    "href": "posts/210720-good_predictions_bad_decisions.html",
    "title": "When good predictions lead to bad decisions",
    "section": "",
    "text": "A common premise in prediction research for clinical outcomes is that better predictions lead to better (informed) decisions. This causal statement, that the intervention of introducing a new prediction rule leads to better decisions and thus better outcomes, is generally not substantiated with sufficient causal arguments. We now present an example where naively introducing a validated new prediction rule can lead to worse clinical decisions.\nFor a certain cancer type there are two treatment options: treatment A and treatment B. From randomized trials, it is known that treatment A is more effective in treating the tumor than treatment B. There is no known variation of treatment effect among subgroups defined by clinical patient characteristics. However, not all patients respond well to treatment. Treatment A is a longer and more intensive treatment regimen than treatment B and leads to more side-effects. The consensus is that it is unethical to give treatment A to patients with a lower than 10% chance of surviving one year, due to the higher risk of side-effects and the lengthy treatment regimen associated with treatment A. In current clinical practice, the probability of 1-year survival is estimated using clinical characteristics. A new research group tries to improve the 1-year survival predictions using a new biomarker. The research endeavor is a success as it turns out that predicting survival with the clinical characteristics and the new biomarker is significantly more accurate than using only the clinical characteristics. A high value for the biomarker is associated with worse overall survival. Having conducted a predictive study, it is not discovered that the treatment effect of treatment A versus B is actually more in favor of treatment A for patients with higher levels of the biomarker. If the new prediction rule would be implemented naively with the same 10% cut-off for 1-year overall survival, this would lead to worse treatment decisions than without using the new prediction model. Some patients with high biomarker values will fall under the 10% cut-off based on the new biomarker, while without the biomarker they would have had a higher than 10% survival probability. This erroneously leads to not recommending treatment A, even though these patients have a high benefit of treatment A.\nNote that this is not an unreasonable example for cancer, as aggressive / fast-growing cancers tend to respond better to treatments like chemotherapy and radiotherapy. One example is non-seminoma versus seminoma testicular cancer."
  },
  {
    "objectID": "posts/210720-good_predictions_bad_decisions.html#defining-the-policies",
    "href": "posts/210720-good_predictions_bad_decisions.html#defining-the-policies",
    "title": "When good predictions lead to bad decisions",
    "section": "Defining the policies",
    "text": "Defining the policies\nThe current clinical policy is:\n\\[\\pi_0(x) = \\mathbf{I}_{E[y|x] &gt; 0}\\]\nSo we should give treatment \\(t=1\\) whenever the expected outcome exceeds the reference cut-off. Let the true data generating mechanism be as following:\n\\[y = \\beta z t + x - z\\]\nAs \\(y\\) is a deterministic function of \\(t,x,z\\), we drop the expectation symbol in the following discussion. Let \\(x,z \\sim \\mathbf{U}(-1,1)\\) be independent variables following a uniform distribution between -1 and 1. We can new express the baseline policy as \\[\\pi_0(x) = \\mathbf{I}_{y|x &gt; 0} = \\mathbf{I}_{E_{z}[y|x,z]&gt;0} \\iff \\mathbf{I}_{x &gt; 0}\\]\nA naive implementation of the new prediction rule incorporating \\(z\\) would lead to the policy \\(\\pi_z(x,z) = \\mathbf{I}_{y|x,z &gt; 0}\\). Plugging in the data generating mechanism we can identify\n\\[\\begin{aligned}\n  y|x,z &= E_{t \\sim \\pi_0(x)}[y|t,x,z] \\\\\n    &= E_{t \\sim \\pi_0(x)}[\\beta z t + x - z] \\\\\n    &= \\beta z E_{t \\sim \\pi_0(x)} [t] + x - z \\\\\n    &= \\beta z E_x [\\mathbf{I}_{x &gt; 0}] + x - z \\\\\n    &= 0.5 \\beta z  + x - z \\\\\n    &= x - (1 - 0.5 \\beta)z\\end{aligned}\\]\nThus \\(\\pi_z(x,z) = \\mathbf{I}_{x + (0.5 \\beta - 1)z &gt; 0}\\).\nFrom the data generating mechanism it is clear that the conditional average treatment effect reduces to\n\\[\\begin{aligned}\n  \\text{CATE(x,z)} &= E[y|\\text{do}(t=1),x,z] - E[y|\\text{do}(t=0),x,z] \\\\\n                   &= \\beta z - 0\\end{aligned}\\]\nThe policy that maximizes the outcome \\(y\\) is \\(\\pi_{\\text{max}(y)}(z) = \\mathbf{I}_{z &gt; 0}\\) as \\(\\text{do}(t=1)\\) leads to better outcomes if and only if \\(z&gt;0\\). To conform with the ethical consensus that the intensive treatment is justified when \\(y|\\text{do}(t),x,z&gt;0\\), we set\n\\[\\begin{aligned}\n    \\pi^*(x,z) &= \\mathbf{I}_{y|\\text{do}(t=1),x,z &gt; 0} \\\\\n           &= \\mathbf{I}_{\\beta z * 1 + x - z &gt; 0} \\\\\n           &= \\mathbf{I}_{x + (\\beta - 1) z &gt; 0}\\end{aligned}\\]"
  },
  {
    "objectID": "posts/210720-good_predictions_bad_decisions.html#expected-utility-of-different-policies",
    "href": "posts/210720-good_predictions_bad_decisions.html#expected-utility-of-different-policies",
    "title": "When good predictions lead to bad decisions",
    "section": "Expected utility of different policies",
    "text": "Expected utility of different policies\nWe can now calculate the expected utility of the different policies \\(\\pi \\in \\{\\pi_0,\\pi_z,\\pi_{\\text{max}(y)},\\pi^*\\}\\) as the expected outcome, \\(U(\\pi) = E_{x,z}E_{t\\sim \\pi(x,z)}y|t,x,z = E_{x,z}\\beta z \\pi(x,z) + x - z\\). The calculation of these expected utilities depends on the treatment effect, which will we assume to be \\(\\beta = 1.5\\). We will use the marginal indepence of \\(x\\) and \\(z\\) to equate \\(E_{x,z}[.] = E_z E_x [.]\\).\n\\[\\begin{aligned}\n    U(\\pi_0) &= E_z E_x [\\beta z \\mathbf{I}_{x &gt; 0} + x - z] \\\\\n         &= \\beta E_z z E_x \\mathbf{I}_{x&gt;0} \\\\\n         &= \\beta E_z z 0.5 \\\\\n         &= 0\\end{aligned}\\]\nWe have \\(\\pi_z(x,z) = \\mathbf{I}_{x - (1 - 0.5 \\beta)z &gt; 0} = \\mathbf{I}_{x &gt; 0.25z}\\)\n\\[\\begin{aligned}\n    U(\\pi_z) &= E_z E_x [\\beta z \\mathbf{I}_{x &gt; 0.25z} + x - z] \\\\\n         &= \\beta E_z z E_x \\mathbf{I}_{x &gt; 0.25z} \\\\\n         &= \\beta E_z z \\text{Pr}(x &gt; 0.25z) \\\\\n         &=^1 \\frac{\\beta}{2} \\int_{-1}^{1} z \\text{Pr}(x &gt; 0.25z) dz\\\\\n         &=^2 \\frac{\\beta}{2} \\int_{-1}^{1} z (1 - \\frac{0.25z+1}{2}) dz\\\\\n         &= \\frac{\\beta}{4} \\int_{-1}^{1} z (1 - 0.25z)dz \\\\\n         &= \\frac{\\beta}{4} \\left[ \\frac{1}{2} z^2 - \\frac{0.25}{3}z^3 + C \\right]_{-1}^1 \\\\\n         &= \\frac{\\beta}{4} \\left( ( \\frac{1}{2} - \\frac{0.25}{3}) - ( \\frac{1}{2} + \\frac{0.25}{3}) \\right) \\\\\n         &= - \\frac{\\beta}{2} \\frac{0.25}{3} \\\\\n         &= - 0.075\\end{aligned}\\]\nWhere in \\(^1\\) we used the \\(U(-1,1)\\) distribution of \\(z\\) and in \\(^2\\) we used the probability density function of \\(x\\) and the fact that \\(-1 &lt; 0.25z &lt; 1\\). This demonstrates that the policy following the (accurate!) prediction model \\(y|x,z\\) leads to worse clinical outcomes than the previous situation that relied on \\(x\\) only.\nThe reader may verify that \\[\\begin{aligned}\n    U(\\pi_{\\text{max}(y)}) &= 0.375 \\\\\n    U(\\pi^*) &= 0.125\\end{aligned}\\]"
  },
  {
    "objectID": "talks.html",
    "href": "talks.html",
    "title": "Talks",
    "section": "",
    "text": "Wouter’s twitter X-peri(ments/ences)\n\n\n\n\n\n\n\n\n\n\n\nMar 12, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Wouter van Amsterdam, MD, PhD",
    "section": "",
    "text": "Twitter\n  \n  \n    \n     Linkedin\n  \n  \n    \n     ORCID\n  \n  \n    \n     github\n  \n  \n    \n     pubmed\n  \n  \n    \n     google-scholar\n  \n\n  \n  \n\n\nWouter van Amsterdam is an assistant professor at the University Medical Center Utrecht, working on methods and applications of machine learning and causal inference for health care.\nMaster students with a background in statistics or machine learning who want to work with me are welcome to contact me. Students enrolled at Utrecht University or UMC Utrecht can find open master projects on konjoin\n\n\n\nUniversity Medical Center Utrecht / Utrecht University\nBSc. in Physics | 2010\nM.D. | 2017\nMSc. in epidemiology (med. statistics track) | 2021\nPhD. machine learning for healthcare | 2022 | co-advised by Rajesh Ranganath from NYU\n\n\n\nUMC Utrecht| Assistant Professor | 2023 - now\nBabylon Health | Senior Research Scientist | 2021 - 2023\nCV (pdf)"
  },
  {
    "objectID": "index.html#selected-papers",
    "href": "index.html#selected-papers",
    "title": "Wouter van Amsterdam, MD, PhD",
    "section": "Selected papers",
    "text": "Selected papers\ngoogle scholar\nWhen accurate prediction models yield harmful self-fulfilling prophecies (arXiv:2312.01210).\nvan Amsterdam, W. A. C., van Geloven, N., Krijthe, J. H., Ranganath, R., & Ciná, G. (2024). ML4H 2023 findings-track\npdf\nIndividual treatment effect estimation in the presence of unobserved confounding using proxies: A cohort study in stage III non-small cell lung cancer.  van Amsterdam, W. A. C., Verhoeff, J. J. C., Harlianto, N. I., Bartholomeus, G. A., Puli, A. M., de Jong, P. A., Leiner, T., van Lindert, A. S. R., Eijkemans, M. J. C., & Ranganath, R. (2022). Scientific Reports\npdf\nConditional average treatment effect estimation with marginally constrained models.\nvan Amsterdam, W. A. C., & Ranganath, R. (2023). Journal of Causal Inference\npdf\nDecision making in cancer: Causal questions require causal answers.\nvan Amsterdam, W. A. C., de Jong, P. A., Suijkerbuijk, K. P. M., Verhoeff, J. J. C., Leiner, T., & Ranganath, R. (2022). ArXiv pre-print\npdf\nEliminating biasing signals in lung cancer images for prognosis predictions with deep learning.\nvan Amsterdam, W. A. C., Verhoeff, J. J. C., de Jong, P. A., Leiner, T., & Eijkemans, M. J. C. (2019). Npj Digital Medicine\npdf"
  },
  {
    "objectID": "index.html#posts",
    "href": "index.html#posts",
    "title": "Wouter van Amsterdam, MD, PhD",
    "section": "Posts",
    "text": "Posts\n\n\n\n\n\n\n\n\nThe difference between intervention and counterfactuals\n\n\n\n\n\n\nWouter van Amsterdam\n\n\nJul 25, 2021\n\n\n\n\n\n\n\n\n\n\n\n\nWhen good predictions lead to bad decisions\n\n\n\n\n\n\nWouter van Amsterdam\n\n\nJul 20, 2021\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#contact",
    "href": "index.html#contact",
    "title": "Wouter van Amsterdam, MD, PhD",
    "section": "Contact",
    "text": "Contact\nwamster3 at umcutrecht dot nl"
  }
]