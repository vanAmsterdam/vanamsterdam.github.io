[
  {
    "objectID": "talks/250522-hds-ccm/index.html#motivation",
    "href": "talks/250522-hds-ccm/index.html#motivation",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Motivation",
    "text": "Motivation\n\n\nclinicians use prediction models for medical decisions, e.g.\n\nmaking a diagnosis:\n\nobserve symptoms (paralysis)\ntry to infer the cause (diagnosis = stroke)\n\nestimating a patients prognosis\n\nobserve patient features / risk factors (cholesterol, age)\npredict future outcomes (heart attack)\n\n\nthese prediction models need reliable performance\nissue: potential substantive difference between last evaluation and current use"
  },
  {
    "objectID": "talks/250522-hds-ccm/index.html#change-in-setting",
    "href": "talks/250522-hds-ccm/index.html#change-in-setting",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Change in setting",
    "text": "Change in setting\nWhat can we expect from the model’s performance (if anything) in the new setting?\n\n\n\n\n\n\nmodel trained / evaluated in tertiary care hospital\n\n\n\n\n\n\n\nmodel used in GP setting"
  },
  {
    "objectID": "talks/250522-hds-ccm/index.html#this-paper-talk",
    "href": "talks/250522-hds-ccm/index.html#this-paper-talk",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "This paper / talk",
    "text": "This paper / talk\n\nrecap performance: discrimination, calibration\nlook at the causal direction of the prediction:\n\nare we predicting an effect based on its causes (e.g. heart attack, based on cholesterol and age) - typical in prognosis\nare we predicting a cause based on its effects (infer presence of stroke based on neurological symptoms) - typical in diagnosis\n\ndefine shift in case-mix as a change in the marginal distribution of the cause variable\nconclude that in theory:\n\nfor prognosis models: expect stable calibration, not discrimination\nfor diagnosis models: expect stable discrimination, not calibration\n\nillustrate with simulation\nevaluate on 2030+ prediction model evaluations"
  },
  {
    "objectID": "talks/250522-hds-ccm/index.html#discrimination-sensitivity-specificity-auc",
    "href": "talks/250522-hds-ccm/index.html#discrimination-sensitivity-specificity-auc",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Discrimination: sensitivity, specificity, AUC",
    "text": "Discrimination: sensitivity, specificity, AUC\n\ntake a threshold \\(\\tau\\), such that \\(f(x) &gt; \\tau\\) is a positive prediction\ntabulate predictions vs outcomes\n\n\n\n\n\n\n\noutcome\n\n\n\n\n\n\n\n1\n0\n\n\nprediction\n1\ntrue positives\nfalse positives\n\n\n\n0\nfalse negatives\ntrue negatives"
  },
  {
    "objectID": "talks/250522-hds-ccm/index.html#discrimination-sensitivity-specificity",
    "href": "talks/250522-hds-ccm/index.html#discrimination-sensitivity-specificity",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Discrimination: sensitivity, specificity",
    "text": "Discrimination: sensitivity, specificity\n\n\n\n\n\n\n\n\n\n\n\n\noutcome\n\n\n\n\n\n\n\n1\n0\n\n\nprediction\n1\ntrue positives\nfalse positives\n\n\n\n0\nfalse negatives\ntrue negatives\n\n\n\n\nsensitivity: TP / (TP+FN)\nspecificity: TN / (TN+FP)\n\n\n\n\n\nsensitivity: \\(P(\\hat{Y}=1 | Y=1)\\)\n\n\\(=P(X \\in \\{X: f(X) &gt; \\tau \\} | Y=1)\\) (assuming deterministic \\(f\\))\n\nspecificity: \\(P(\\hat{Y}=0 | Y=0)\\)\nnote: sensitivity only requires data from the column of postive cases (i.e. \\(Y=1\\)), and specificity on negatives\nevent-rate: fraction of \\(Y=1\\) of total cases\nin theory discrimination is event-rate independent (Hond 2023)"
  },
  {
    "objectID": "talks/250522-hds-ccm/index.html#discrimination-roc-curve-and-auc",
    "href": "talks/250522-hds-ccm/index.html#discrimination-roc-curve-and-auc",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Discrimination: ROC curve and AUC",
    "text": "Discrimination: ROC curve and AUC\nif we vary the threshold \\(0 \\leq \\tau \\leq 1\\), we get a ROC curve, and the AUC is the area under this curve"
  },
  {
    "objectID": "talks/250522-hds-ccm/index.html#calibration",
    "href": "talks/250522-hds-ccm/index.html#calibration",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Calibration",
    "text": "Calibration\n“A model is said to be well calibrated if for every 100 patients given a risk of x%, close to x have the event.” (Van Calster and Vickers 2015)\n\n\n\n\n\n\npopulation\n\n\n\n\n\n\n\nsubgroup where \\(f(x)=10\\)%\n\n\n\n\n\n\n\nevent rate in said subgroup is 10%: \\(p(Y=1|f(x)=10\\%) = 10\\%\\)"
  },
  {
    "objectID": "talks/250522-hds-ccm/index.html#calibration-plot",
    "href": "talks/250522-hds-ccm/index.html#calibration-plot",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Calibration plot",
    "text": "Calibration plot\n\n\n\n\\(p(Y=1|X)\\) versus \\(f(x)\\)\n\n\n\ncalibration\n\n\n\n\n\n\ncalibration-plot"
  },
  {
    "objectID": "talks/250522-hds-ccm/index.html#performance-metrics-summary",
    "href": "talks/250522-hds-ccm/index.html#performance-metrics-summary",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Performance metrics summary",
    "text": "Performance metrics summary\n\nperformance metrics for \\(m_f\\) are in general functionals of the joint distribution \\(P(X,Y)\\)\ndiscrimination: function of conditional \\(P(X|Y)\\) (features given outcome)\ncalibration: function of conditional \\(P(Y|X)\\) (outcome given features)"
  },
  {
    "objectID": "talks/250522-hds-ccm/index.html#where-does-the-association-come-from",
    "href": "talks/250522-hds-ccm/index.html#where-does-the-association-come-from",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Where does the association come from?",
    "text": "Where does the association come from?\nIn prediction, we have features \\(X\\) and outcome \\(Y\\) and model \\(Y|X\\)\n1. \\(X\\) causes \\(Y\\): often in prognosis (\\(Y\\): heart-attack, \\(X\\): cholesterol and age)\n2. \\(Y\\) causes \\(X\\): often in diagnosis (stroke, based on neurological symptoms)\n3. \\(Z\\) causes both \\(X\\) and \\(Y\\): confounding (yellow fingers predict lung cancer)"
  },
  {
    "objectID": "talks/250522-hds-ccm/index.html#defining-a-shift-in-case-mix",
    "href": "talks/250522-hds-ccm/index.html#defining-a-shift-in-case-mix",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Defining a shift in case-mix",
    "text": "Defining a shift in case-mix\nDefine a shift in case-mix a change in the marginal distribution of the cause variable. Denoting environment as variable \\(E\\):\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npregnancy outcome prediction\n\ngeneral ‘midwife’ population\npregnant women with type 1 diabetes are counselled by gynaecologists in hospital\n\n\nthis is filtering on patient characteristics (making distribution of \\(X\\) different)\n\npredict occurence of stroke\n\ngeneral emergency center\npatients with clear neurological symptoms are sent to stroke center\n\n\nfilter on outcome risk (different distribution of \\(Y\\))"
  },
  {
    "objectID": "talks/250522-hds-ccm/index.html#what-does-this-definition-imply",
    "href": "talks/250522-hds-ccm/index.html#what-does-this-definition-imply",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "What does this definition imply?",
    "text": "What does this definition imply?\n\n\n\n\n\n\n\nin general, may decompose \\(P(X,Y,E)\\) as:\n\n\\(P(Y|X,E)P(X,E)\\)\n\\(P(X|Y,E)P(Y,E)\\)\n…\n\nlooking at the DAG: \\(P(Y|X,E) = P(Y|X)\\)\n\nin words: \\(P(Y|X)\\) is transportable across environments\nbecause there is no arrow from \\(E\\) to \\(Y\\), \\(X\\) blocks effect of \\(E\\) on \\(Y\\)\n\n\\(P(X|Y,E) \\neq P(X|Y)\\)\n\nin words: \\(P(X|Y)\\) is not transportable across environments\n\nimplication for causal (prognosis) prediction:\n\ncalibration is functional of \\(P(Y|X)\\), thus stable\ndiscrimination is functional of \\(P(X|Y)\\), thus not stable\n\nfor anti-causal (diagnosis) prediction: the reverse\nmain result: discrimination or calibration may be preserved under changes in case-mix, but never both"
  },
  {
    "objectID": "talks/250522-hds-ccm/index.html#why-define-a-shift-in-case-mix-this-way",
    "href": "talks/250522-hds-ccm/index.html#why-define-a-shift-in-case-mix-this-way",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Why define a shift in case-mix this way?",
    "text": "Why define a shift in case-mix this way?\n\ncause is temporally prior to effect, filtering at least on cause may be likely in many settings\nfiltering on both: anything goes, cannot say anything about expected performance based on graphical information"
  },
  {
    "objectID": "talks/250522-hds-ccm/index.html#simulation-setup",
    "href": "talks/250522-hds-ccm/index.html#simulation-setup",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Simulation setup",
    "text": "Simulation setup\n\\[\\begin{align*}\n    \\label{eq:dgm-prognosis}\n    \\text{prognosis:} &                     & \\text{diagnosis:} & \\\\\n    P_y &\\sim \\text{Beta}(\\alpha_e,\\beta_e) & y &\\sim \\text{Bernouli}(P_e) \\\\\n    x   &= \\text{logit}(P_y)                 & x &\\sim N(y, 1) \\\\\n    y   &\\sim \\text{Bernoulli}(P_y)         &   &\n\\end{align*}\\]"
  },
  {
    "objectID": "talks/250522-hds-ccm/index.html#empirical-evaluation",
    "href": "talks/250522-hds-ccm/index.html#empirical-evaluation",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Empirical evaluation",
    "text": "Empirical evaluation\n\na study of 2030+ evaluations of 1300+ prediction models (Wessler et al. 2021)\n\n\n\nregistry: all data available with only 4000 clicks\nsolution: scrape the website"
  },
  {
    "objectID": "talks/250522-hds-ccm/index.html#results",
    "href": "talks/250522-hds-ccm/index.html#results",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Results",
    "text": "Results\n\nfor each study, extract AUC on internal validation and for each external validation (no calibration data available)\ncalculate scaled deviation from internal AUC (\\(\\delta\\))\ntheory implies:\n\nfor prognosis models: \\(\\delta \\neq 0\\)\nfor diagnostic models: \\(\\delta=0\\)\n\ntest: variance of \\(\\delta\\) between evaluations of diagnostic or prognostic models (F-test)\nresult: \\(\\text{VAR}(\\delta_{\\text{prognostic}}) \\approx 8.2 * \\text{VAR}(\\delta_{\\text{diagnostic}}) = 0.019\\), p-value\\(&lt;0.001\\)"
  },
  {
    "objectID": "talks/250522-hds-ccm/index.html#conclusion",
    "href": "talks/250522-hds-ccm/index.html#conclusion",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Conclusion",
    "text": "Conclusion\n\ndiscrimination: a function of distribution of features given outcome\ncalibration: a function of distribution of outcome given features\nare we predicting an effect based on its causes (e.g. heart attack, based on cholesterol and age)\nare we predicting a cause based on its effects (infer presence of stroke based on neurological symptoms)\ndefine shift in case-mix as a change in the marginal distribution of the cause variable\nconclude that in theory:\n\nfor prognosis models: expect stable calibration, not discrimination\nfor diagnosis models: expect stable discrimination, not calibration\n\nillustrated with simulation, evaluated on 2030+ prediction model evaluations, one direction of theory seems confirmed\nfuture work: more empirical validations"
  },
  {
    "objectID": "talks/250522-hds-ccm/index.html#references",
    "href": "talks/250522-hds-ccm/index.html#references",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "References",
    "text": "References\n\n\n\n\nHond, A. A. H. de. 2023. “From Code to Clinic: Theory and Practice for Artificial Intelligence Prediction Algorithms.” Leiden University. https://hdl.handle.net/1887/3643729.\n\n\nVan Calster, Ben, and Andrew J. Vickers. 2015. “Calibration of Risk Prediction Models: Impact on Decision-Analytic Performance.” Medical Decision Making 35 (2): 162–69. https://doi.org/10.1177/0272989X14547233.\n\n\nWessler, Benjamin S., Jason Nelson, Jinny G. Park, Hannah McGinnes, Gaurav Gulati, Riley Brazil, Ben Van Calster, et al. 2021. “External Validations of Cardiovascular Clinical Prediction Models: A Large-Scale Review of the Literature.” Circulation: Cardiovascular Quality and Outcomes 14 (8): e007858. https://doi.org/10.1161/CIRCOUTCOMES.121.007858."
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#prediction",
    "href": "talks/240516-sig-causality-prediction/index.html#prediction",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "Prediction",
    "text": "Prediction\n\nhave some features \\(X\\) (patient characteristics, medical images, lab results)\ndefine relevant outcome \\(Y\\) (e.g. 1-year survival, blood pressure, treatment complication)\nbuild prediction model \\(f: \\mathbb{X} \\to \\mathbb{Y}\\) that predicts \\(Y\\) from \\(X\\), e.g.:\n\n\n\\[ \\theta^* = \\arg \\min_{\\theta} \\sum_i^n ( f_{\\theta}(x_i) - y_i )^2 \\]\n\n\nHoping that\n\\[ \\lim_{n \\to \\infty} f_{\\theta^*} = E[Y|X] \\]"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#prediction-typical-approach",
    "href": "talks/240516-sig-causality-prediction/index.html#prediction-typical-approach",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "Prediction: typical approach",
    "text": "Prediction: typical approach\n\ndefine population, start a (prospective) longitudinal cohort\nmeasure \\(X\\) at prediction baseline\nfollow-up patients to measure \\(Y\\)\nfit model \\(f\\) to \\(\\{x_i,y_i\\}\\)\nevaluate prediction performance with e.g. discrimination, calibration, \\(R^2\\)"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#causal-inference",
    "href": "talks/240516-sig-causality-prediction/index.html#causal-inference",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "Causal inference",
    "text": "Causal inference\n\\(y^0:=\\) imaginative outcome if I don’t treat the patient\n\n\n\n\n\n\n\n\n\n\n\\[\\begin{align}\ny^0 &= \\mu_0 + \\epsilon, \\quad \\epsilon \\overset{\\mathrm{iid}}{\\sim} N(0,\\sigma)\\\\\n\\end{align}\\]\n\n\nthis formula together with distribution over error term gives rise to a distribution over the outcome when intervening on treatment (i.e. an interventional distribution)\n\\[\nP(Y=y|\\text{do}(T=0))\n\\]"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#causal-inference-1",
    "href": "talks/240516-sig-causality-prediction/index.html#causal-inference-1",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "Causal inference",
    "text": "Causal inference\n\\(y^0:=\\) imaginative outcome if I don’t treat the patient\n\\(y^1:=\\) imaginative outcome if I do treat\n\n\\[\\begin{align}\ny^0 &= \\mu_0 + \\epsilon, \\quad \\epsilon \\overset{\\mathrm{iid}}{\\sim} N(0,\\sigma) \\to &P(Y=y|\\text{do}(T=0))\\\\\ny^1 &= \\mu_1 + \\epsilon, \\quad \\epsilon \\overset{\\mathrm{iid}}{\\sim} N(0,\\sigma) \\to &P(Y=y|\\text{do}(T=1))\n\\end{align}\\]\n\n\\[\\begin{align}\n\\text{treatment effect} &:= E[y^1] - E[y^0] = \\mu_1 - \\mu_0 \\\\\n                        &:= E[Y|\\text{do}(T=1)] - E[Y|\\text{do}(T=0)]\n\\end{align}\\]"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#causal-inference-typical-approach",
    "href": "talks/240516-sig-causality-prediction/index.html#causal-inference-typical-approach",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "Causal inference: typical approach",
    "text": "Causal inference: typical approach\n\ndefine target population and targeted treatment comparison\nrun randomized controlled trial, randomizing treatment allocation\nmeasure patient outcomes\nestimate parameter that summarizes average treatment effect (ATE)\n\n\n\n\n\nWhat if you cannot do a (big enough) RCT?\n\n\nEmulate / approximate the ideal trial in observational data you do have, using causal inference techniques\n(which rely on untestable assumptions)"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#causal-inference-versus-prediction",
    "href": "talks/240516-sig-causality-prediction/index.html#causal-inference-versus-prediction",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "Causal inference versus prediction",
    "text": "Causal inference versus prediction\n\n\nprediction\n\ntypical estimand \\(E[Y|X]\\)\ntypical study: longitudinal cohort\ntypical interpretation: \\(X\\) predicts \\(Y\\)\nprimary use: know what \\(Y\\) to expect when observing \\(X\\) assuming no change in joint distribution\n\n\ncausal inference\n\ntypical estimand \\(E[Y|\\text{do}(T=1)] - E[Y|\\text{do}(T=0)]\\)\ntypical study: RCT\ntypical interpretation: causal effect of \\(T\\) on \\(Y\\)\nprimary use: know what treatment to give"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#the-in-between-using-prediction-models-for-medical-decision-making",
    "href": "talks/240516-sig-causality-prediction/index.html#the-in-between-using-prediction-models-for-medical-decision-making",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "The in-between: using prediction models for (medical) decision making",
    "text": "The in-between: using prediction models for (medical) decision making"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#using-prediction-models-for-decision-making-is-often-thought-of-as-a-good-idea",
    "href": "talks/240516-sig-causality-prediction/index.html#using-prediction-models-for-decision-making-is-often-thought-of-as-a-good-idea",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "Using prediction models for decision making is often thought of as a good idea",
    "text": "Using prediction models for decision making is often thought of as a good idea\nFor example:\n\ngive chemotherapy to cancer patients with high predicted risk of recurrence\ngive statins to patients with a high risk of a heart attack\n\n\n\n\n\nTRIPOD+AI on prediction models (collinsTRIPODAIStatement2024?)\n\n\n“Their primary use is to support clinical decision making, such as … initiate treatment or lifestyle changes.”"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#prediction-modeling-is-very-popular-in-medical-research",
    "href": "talks/240516-sig-causality-prediction/index.html#prediction-modeling-is-very-popular-in-medical-research",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "Prediction modeling is very popular in medical research",
    "text": "Prediction modeling is very popular in medical research"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#treatment-naive-risk-models",
    "href": "talks/240516-sig-causality-prediction/index.html#treatment-naive-risk-models",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "Treatment-naive risk models",
    "text": "Treatment-naive risk models\n\n\n\n\n\\[\\begin{align}\n    E[Y|X] \\class{fragment}{= E[E_{t~\\sim \\pi_0(X)}[Y|X,t]]}\n\\end{align}\\]"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#is-this-obvious",
    "href": "talks/240516-sig-causality-prediction/index.html#is-this-obvious",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "Is this obvious?",
    "text": "Is this obvious?\n\n\n\n\n\n\nTip\n\n\nIt may seem obvious that you should not ignore historical treatments in your prediction models, if you want to improve treatment decisions, but many of these models are published daily, and some guidelines even allow for implementing these models based on predictve performance only"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#recommended-validation-practices-do-not-protect-against-harm",
    "href": "talks/240516-sig-causality-prediction/index.html#recommended-validation-practices-do-not-protect-against-harm",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "Recommended validation practices do not protect against harm",
    "text": "Recommended validation practices do not protect against harm\nbecause they do not evaluate the policy change"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#bigger-data-does-not-protect-against-harmful-risk-models",
    "href": "talks/240516-sig-causality-prediction/index.html#bigger-data-does-not-protect-against-harmful-risk-models",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "Bigger data does not protect against harmful risk models",
    "text": "Bigger data does not protect against harmful risk models"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#more-flexible-models-do-not-protect-against-harmful-risk-models",
    "href": "talks/240516-sig-causality-prediction/index.html#more-flexible-models-do-not-protect-against-harmful-risk-models",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "More flexible models do not protect against harmful risk models",
    "text": "More flexible models do not protect against harmful risk models"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#gap-between-prediction-accuracy-and-value-for-decision-making",
    "href": "talks/240516-sig-causality-prediction/index.html#gap-between-prediction-accuracy-and-value-for-decision-making",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "Gap between prediction accuracy and value for decision making",
    "text": "Gap between prediction accuracy and value for decision making"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#section",
    "href": "talks/240516-sig-causality-prediction/index.html#section",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "",
    "text": "What to do?"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#section-1",
    "href": "talks/240516-sig-causality-prediction/index.html#section-1",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "",
    "text": "What to do?\n\n\nEvaluate policy change (cluster randomized controlled trial)\nBuild models that are likely to have value for decision making"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#deploying-a-model-is-an-intervention-that-changes-the-way-treatment-decisions-are-made",
    "href": "talks/240516-sig-causality-prediction/index.html#deploying-a-model-is-an-intervention-that-changes-the-way-treatment-decisions-are-made",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "Deploying a model is an intervention that changes the way treatment decisions are made",
    "text": "Deploying a model is an intervention that changes the way treatment decisions are made"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#how-do-we-learn-about-the-effect-of-an-intervention",
    "href": "talks/240516-sig-causality-prediction/index.html#how-do-we-learn-about-the-effect-of-an-intervention",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "How do we learn about the effect of an intervention?",
    "text": "How do we learn about the effect of an intervention?\nWith causal inference!\n\nfor using a decision support model, the unit of intervention is usually the doctor\nrandomly assign doctors to have access to the model or not\nmeasure differences in treatment decisions and patient outcomes\nthis called a cluster RCT\nif using model improves outcomes, use that one\n\n\n\n\n\nUsing cluster RCTs to evaluated models for decision making is not a new idea (Cooper et al. 1997)\n\n\n“As one possibility, suppose that a trial is performed in which clinicians are randomized either to have or not to have access to such a decision aid in making decisions about where to treat patients who present with pneumonia.”\n\n\n\n\n\n\n\n\n\n\n\nWhat we don’t learn\n\n\nwas the model predicting anything sensible?"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#so-build-prediction-models-and-trial-them",
    "href": "talks/240516-sig-causality-prediction/index.html#so-build-prediction-models-and-trial-them",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "So build prediction models and trial them?",
    "text": "So build prediction models and trial them?\nNot a good idea\n\nbaking a cake without a recipe\nhoping it turns into something nice\nnot pleasant to people that need to taste the experiment\n\n(i.e. patients may have side-effects / die)"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#models-that-are-likely-to-be-valuable-for-decision-making",
    "href": "talks/240516-sig-causality-prediction/index.html#models-that-are-likely-to-be-valuable-for-decision-making",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "Models that are likely to be valuable for decision making",
    "text": "Models that are likely to be valuable for decision making\n\nprediction under hypothetical interventions (prediction-under-intervention) models predict expected outcomes under the hypothetical intervention of giving a certain treatment\n\n\n\n\n\nHilden and Habbema on prognosis (Hilden and Habbema 1987)\n\n\n“Prognosis cannot be divorced from contemplated medical action, nor from action to be taken by the patient in response to prognostication.”\n\n\n\n\nwhereas treatment-naive prediction models average out over the historic treatment policy, prediction-under-intervention allows the user to select a treatment option\nprediction-under-intervention is not a new idea, but language and methods on causality have come a long way since (Hilden and Habbema 1987)."
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#estimand-for-prediction-under-intervention-models",
    "href": "talks/240516-sig-causality-prediction/index.html#estimand-for-prediction-under-intervention-models",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "Estimand for prediction-under-intervention models",
    "text": "Estimand for prediction-under-intervention models\nWhat is the estimand?\n\nprediction: \\(E[Y|X]\\)\ntreatment effect: \\(E[Y|\\text{do}(T=1)] - E[Y|\\text{do}(T=0)]\\)\nprediction-under-intervention: \\(E[Y|\\text{do}(T=t),X]\\)"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#estimating-prediction-under-intervention-models",
    "href": "talks/240516-sig-causality-prediction/index.html#estimating-prediction-under-intervention-models",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "Estimating prediction-under-intervention models",
    "text": "Estimating prediction-under-intervention models\n\nthe estimand \\(E[Y|\\text{do}(T=t),X]\\) is an interventional distribution\nRCTs randomly sample from interventional distributions\nprediction-under-intervention models may be estimated and evaluated in RCT data\nhowever, RCTs are typically designed to estimate a single parameter\nprediction models need more data\nin comes causal inference from observational data?"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#challenges-with-observational-data",
    "href": "talks/240516-sig-causality-prediction/index.html#challenges-with-observational-data",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "Challenges with observational data",
    "text": "Challenges with observational data\n\nassumption of no unobserved confounding may be hard to justify\nbut there’s more between heaven (RCT) and earth (confounder adjustment)\n\nproxy-variable methods\nconstant relative treatment effect assumption\ndiff-in-diff\ninstrumental variable analysis (high variance estimates)\nfront-door analysis"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#proxy-variables",
    "href": "talks/240516-sig-causality-prediction/index.html#proxy-variables",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "Proxy variables?",
    "text": "Proxy variables?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nproblem: didn’t observe confounder fitness so cannot do confounder adjustment\ninstead, leverage assumptions on confounder - proxy relationship (e.g. monotonicity)\neffect may still be identifyable (van Amsterdam et al. 2022)"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#constant-relative-treatment-effect",
    "href": "talks/240516-sig-causality-prediction/index.html#constant-relative-treatment-effect",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "Constant relative treatment effect?",
    "text": "Constant relative treatment effect?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWidely used paradigm (cardiovascular risk, chemotherapy in breast cancer, …)\nUntreated risk is a quantity of the interventional distribution (i.e. causal)\nCurrent risk-models: mix of treated / untreated patients (amsterdamAlgorithmsActionImproving2024?),\nor ungrounded methods (Candido dos Reis et al. 2017; Xu et al. 2021).\nNeed better `causal’ methods (van Amsterdam and Ranganath 2023)"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#prediction-under-intervention-approaches-sound-great",
    "href": "talks/240516-sig-causality-prediction/index.html#prediction-under-intervention-approaches-sound-great",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "Prediction-under-intervention approaches sound great",
    "text": "Prediction-under-intervention approaches sound great\n\nbut come with their own assumptions and trade-offs\ndo sensitivity analysis\nmay not have treatment information\nmay be many decision time-points, hard to formulate estimand over long time-horizon"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#how-to-proceed",
    "href": "talks/240516-sig-causality-prediction/index.html#how-to-proceed",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "How to proceed?",
    "text": "How to proceed?\n\nbuild prediction-under-intervention model with best data + assumptions\ntest policy value in historical RCT data of competing policies (e.g. current practice vs policy by new model)\n\nfor each patient in RCT, determine recommended treatment according to policy\nif actual (randomly allocated) treatment is concordant, keep the patient\nif not, drop observation\ncalculate average outcomes in the subpopulation\npolicy with highest average outcomes is best\n\nthen do a cluster RCT"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#take-aways",
    "href": "talks/240516-sig-causality-prediction/index.html#take-aways",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "Take-aways",
    "text": "Take-aways\n\nPrediction and causal inference come together neatly by declaring \\(E[Y|\\text{do}(T=t),X]\\) as the estimand\n(mis)using prediction models for treatment decisions without causal thinking and evaluation is a bad idea\ndeploying models for decision support is an intervention and should be evaluated as such\n\n\n\n\n\n\n\n\n\nFrom algorithms to action: improving patient care requires causality (amsterdamAlgorithmsActionImproving2024?)\n\n\n\n\n\n\nWhen accurate prediction models yield harmful sel-fulfilling prophecies (vanamsterdamWhenAccuratePrediction2024a?)"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#references",
    "href": "talks/240516-sig-causality-prediction/index.html#references",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "References",
    "text": "References\n\n\n\n\nAmsterdam, Wouter A. C. van, and Rajesh Ranganath. 2023. “Conditional Average Treatment Effect Estimation with Marginally Constrained Models.” Journal of Causal Inference 11 (1): 20220027. https://doi.org/10.1515/jci-2022-0027.\n\n\nAmsterdam, Wouter A. C. van, Joost J. C. Verhoeff, Netanja I. Harlianto, Gijs A. Bartholomeus, Aahlad Manas Puli, Pim A. de Jong, Tim Leiner, Anne S. R. van Lindert, Marinus J. C. Eijkemans, and Rajesh Ranganath. 2022. “Individual Treatment Effect Estimation in the Presence of Unobserved Confounding Using Proxies: A Cohort Study in Stage III Non-Small Cell Lung Cancer.” Scientific Reports 12 (1, 1): 5848. https://doi.org/10.1038/s41598-022-09775-9.\n\n\nCandido dos Reis, Francisco J., Gordon C. Wishart, Ed M. Dicks, David Greenberg, Jem Rashbass, Marjanka K. Schmidt, Alexandra J. van den Broek, et al. 2017. “An Updated PREDICT Breast Cancer Prognostication and Treatment Benefit Prediction Model with Independent Validation.” Breast Cancer Research 19 (1): 58. https://doi.org/10/gbhgpq.\n\n\nCooper, Gregory F., Constantin F. Aliferis, Richard Ambrosino, John Aronis, Bruce G. Buchanan, Richard Caruana, Michael J. Fine, et al. 1997. “An Evaluation of Machine-Learning Methods for Predicting Pneumonia Mortality.” Artificial Intelligence in Medicine 9 (2): 107–38. https://doi.org/10.1016/S0933-3657(96)00367-3.\n\n\nHilden, Jørgen, and J. Dik F. Habbema. 1987. “Prognosis in Medicine: An Analysis of Its Meaning and Rôles.” Theoretical Medicine 8 (3): 349–65. https://doi.org/10.1007/BF00489469.\n\n\nXu, Zhe, Matthew Arnold, David Stevens, Stephen Kaptoge, Lisa Pennells, Michael J Sweeting, Jessica Barrett, Emanuele Di Angelantonio, and Angela M Wood. 2021. “Prediction of Cardiovascular Disease Risk Accounting for Future Initiation of Statin Treatment.” American Journal of Epidemiology, February, kwab031. https://doi.org/10/gmj9rw."
  },
  {
    "objectID": "talks/240515-aibia-ai-medical-imaging-decision-support/index.html#outline",
    "href": "talks/240515-aibia-ai-medical-imaging-decision-support/index.html#outline",
    "title": "Decision support based on AI in medical imaging",
    "section": "Outline",
    "text": "Outline\n\ndifferent uses of AI in medical imaging\nusing AI for treatment effect estimation\nwarning: harmful self-fulfilling prophecies"
  },
  {
    "objectID": "talks/240515-aibia-ai-medical-imaging-decision-support/index.html#uses-of-ai-in-medical-imaging",
    "href": "talks/240515-aibia-ai-medical-imaging-decision-support/index.html#uses-of-ai-in-medical-imaging",
    "title": "Decision support based on AI in medical imaging",
    "section": "Uses of AI in medical imaging",
    "text": "Uses of AI in medical imaging\n\nAcquisition (\\(S \\to X\\)) \ndetection / segmentation (\\(X \\to X\\)) \ninference / diagnosis (\\(X \\to D\\), both at prediction time) \nprognosis (\\(X \\to Y\\), \\(Y\\) in the future) \ntreatment effect (\\(X\\) determines effect of a treatment)"
  },
  {
    "objectID": "talks/240515-aibia-ai-medical-imaging-decision-support/index.html#ai-treatment-effect",
    "href": "talks/240515-aibia-ai-medical-imaging-decision-support/index.html#ai-treatment-effect",
    "title": "Decision support based on AI in medical imaging",
    "section": "Why would you estimate treatment effects based on images?",
    "text": "Why would you estimate treatment effects based on images?\n\ntreatments have different effects on patients based on their (disease) characteristics\nfor example, whether tamoxifen increases survival for breast cancer patients depends on whether their tumor is hormone sensitive\nsome characteristics may be well captured in medical imaging:\n\nT-cell distributions around tumors related to effect of immunotherapy in cancer"
  },
  {
    "objectID": "talks/240515-aibia-ai-medical-imaging-decision-support/index.html#how-to-estimate-treatment-effects-based-on-images",
    "href": "talks/240515-aibia-ai-medical-imaging-decision-support/index.html#how-to-estimate-treatment-effects-based-on-images",
    "title": "Decision support based on AI in medical imaging",
    "section": "How to estimate treatment effects based on images?",
    "text": "How to estimate treatment effects based on images?\nIn principle the same as estimating a subgroup treatment effect (e.g. male vs female)\n\nConduct a randomized controlled trial where the treatments of interest are randomly allocated\nCollect (imaging) data at randomization timepoint\nUse a statistical learning technique like TARnet (Shalit, Johansson, and Sontag 2017) to estimate outcomes conditional on image and treatment\nconditional treatment effect \\(= f(X,T=1) - f(X,T=0)\\)\n\n\n\n\n\nWhat if you cannot do a (big enough) RCT?\n\n\nEmulate / approximate the ideal trial in observational data you do have, using causal inference techniques\n(which rely on untestable assumptions)"
  },
  {
    "objectID": "talks/240515-aibia-ai-medical-imaging-decision-support/index.html#the-in-between-predicting-prognosis-and-using-the-predictions-for-decision-support",
    "href": "talks/240515-aibia-ai-medical-imaging-decision-support/index.html#the-in-between-predicting-prognosis-and-using-the-predictions-for-decision-support",
    "title": "Decision support based on AI in medical imaging",
    "section": "The in-between: predicting prognosis and using the predictions for decision support",
    "text": "The in-between: predicting prognosis and using the predictions for decision support\nFor example:\n\ngive chemotherapy to cancer patients with high predicted risk of recurrence\ngive statins to patients with a high risk of a heart attack\n\n\n\n\n\nTRIPOD+AI on prediction models (Collins et al. 2024)\n\n\n“Their primary use is to support clinical decision making, such as … initiate treatment or lifestyle changes.”"
  },
  {
    "objectID": "talks/240515-aibia-ai-medical-imaging-decision-support/index.html#when-building-a-prediction-model-always-discuss",
    "href": "talks/240515-aibia-ai-medical-imaging-decision-support/index.html#when-building-a-prediction-model-always-discuss",
    "title": "Decision support based on AI in medical imaging",
    "section": "When building a prediction model, always discuss",
    "text": "When building a prediction model, always discuss\n\nwhat treatments are assumed in the predicted risk?\nwhat is the effect of using the model on the treatment policy?\nwhat is the effect on patient outcomes?\n\n\n\n\n\nFrom algorithms to action: improving patient care requires causality (W. A. C. van Amsterdam et al. 2024b)\n\n\nWhen accurate prediction models yield harmful sel-fulfilling prophecies (W. A. C. van Amsterdam et al. 2024a)"
  },
  {
    "objectID": "talks/240515-aibia-ai-medical-imaging-decision-support/index.html#references",
    "href": "talks/240515-aibia-ai-medical-imaging-decision-support/index.html#references",
    "title": "Decision support based on AI in medical imaging",
    "section": "References",
    "text": "References\n\n\n\n\nAmsterdam, Wouter A. C. van, Nan van Geloven, Jesse H. Krijthe, Rajesh Ranganath, and Giovanni Ciná. 2024a. “When Accurate Prediction Models Yield Harmful Self-Fulfilling Prophecies.” arXiv. https://doi.org/10.48550/arXiv.2312.01210.\n\n\nAmsterdam, Wouter A. C. van, Pim A. de Jong, Joost J. C. Verhoeff, Tim Leiner, and Rajesh Ranganath. 2024b. “From Algorithms to Action: Improving Patient Care Requires Causality.” BMC Medical Informatics and Decision Making 24 (1). https://doi.org/10.1186/s12911-024-02513-3.\n\n\nCollins, Gary S., Karel G. M. Moons, Paula Dhiman, Richard D. Riley, Andrew L. Beam, Ben Van Calster, Marzyeh Ghassemi, et al. 2024. “TRIPOD+AI Statement: Updated Guidance for Reporting Clinical Prediction Models That Use Regression or Machine Learning Methods.” BMJ 385 (April): e078378. https://doi.org/10.1136/bmj-2023-078378.\n\n\nShalit, Uri, Fredrik D. Johansson, and David Sontag. 2017. “Estimating Individual Treatment Effect: Generalization Bounds and Algorithms.” arXiv:1606.03976 [Cs, Stat], May. http://arxiv.org/abs/1606.03976."
  },
  {
    "objectID": "talks/251027-causalai-4cities-utrecht/index.html#todays-program",
    "href": "talks/251027-causalai-4cities-utrecht/index.html#todays-program",
    "title": "Causal Inference for AI meetup",
    "section": "Today’s program",
    "text": "Today’s program\n\n3 speakers\n17.00 ‘Borrel’"
  },
  {
    "objectID": "talks/251027-causalai-4cities-utrecht/index.html#next-meet-up",
    "href": "talks/251027-causalai-4cities-utrecht/index.html#next-meet-up",
    "title": "Causal Inference for AI meetup",
    "section": "Next Meet-up",
    "text": "Next Meet-up\nPrediction under Interventions seminar\n\n\n\nTuesday, December 2, 2025\nLocation: LUMC, Lecture Hall 1\n12:15: Walk-in & Lunch\n13.15: Welcome & Talks"
  },
  {
    "objectID": "talks/240922-causalai-4cities/index.html#causal-inference-groups",
    "href": "talks/240922-causalai-4cities/index.html#causal-inference-groups",
    "title": "Causal Inference for AI meetup",
    "section": "Causal Inference groups",
    "text": "Causal Inference groups\n\n\n\n\n\n\nCausal Inference in AI mailing-list\n\n\n\n\n\n\n\nUtrecht - Special Interest Group Causal Data Science"
  },
  {
    "objectID": "talks/240922-causalai-4cities/index.html#program",
    "href": "talks/240922-causalai-4cities/index.html#program",
    "title": "Causal Inference for AI meetup",
    "section": "Program",
    "text": "Program\n\n30 minutes + 10 minutes Q&A\nborrel afterwards\n\n\n\n\n\n\n\nCausal Inference in AI mailing-list\n\n\n\n\n\n\n\nUtrecht - Special Interest Group Causal Data Science"
  },
  {
    "objectID": "talks/250127-dagstuhl/index.html#ai-deployment-as-an-intervention",
    "href": "talks/250127-dagstuhl/index.html#ai-deployment-as-an-intervention",
    "title": "my priorities for AI in health",
    "section": "AI deployment as an intervention",
    "text": "AI deployment as an intervention"
  },
  {
    "objectID": "talks/250127-dagstuhl/index.html#when-accurate-prediction-models-yield-harmful-self-fulfilling-prophecies",
    "href": "talks/250127-dagstuhl/index.html#when-accurate-prediction-models-yield-harmful-self-fulfilling-prophecies",
    "title": "my priorities for AI in health",
    "section": "When accurate prediction models yield harmful self-fulfilling prophecies",
    "text": "When accurate prediction models yield harmful self-fulfilling prophecies\nHow this can go wrong if we misalign the AI evaluation metric and the patient oucome\nPatterns, 2025"
  },
  {
    "objectID": "talks/250127-dagstuhl/index.html#why-is-it-hard",
    "href": "talks/250127-dagstuhl/index.html#why-is-it-hard",
    "title": "my priorities for AI in health",
    "section": "why is it hard:",
    "text": "why is it hard:\n\nAI deployment is an intervention, knowing whether this improved outcomes for patients is causal inference (Joshi et al. 2025) \nbefore-after comparison plagued by potential time-trends\noptimal pre-deployment evidence: (cluster) RCT\nafter deployment: changes in the data\n\nby the deployment (that was what we wanted)\nand many other factors.\n\nmeasures of prediction accuracy do not automatically translate in patient benefit (Van Amsterdam et al. 2025)"
  },
  {
    "objectID": "talks/250127-dagstuhl/index.html#opportunities",
    "href": "talks/250127-dagstuhl/index.html#opportunities",
    "title": "my priorities for AI in health",
    "section": "opportunities",
    "text": "opportunities\n\nwhat to track after deployment?\n\naccuracy, outcomes\n\nhow to track after deployment?\n\nrandomization on center level: need many centers (possible in large health systems in the US?);\nrandomization on patient label: need consent\n\nethics in randomization; who provides consent?\ncombine AI + causal inference + trial design + ethics"
  },
  {
    "objectID": "talks/250127-dagstuhl/index.html#prediction-under-intervention-why-work-on-it",
    "href": "talks/250127-dagstuhl/index.html#prediction-under-intervention-why-work-on-it",
    "title": "my priorities for AI in health",
    "section": "Prediction-under-intervention, why work on it?",
    "text": "Prediction-under-intervention, why work on it?\nPrediction under intervention is estimating expected outcomes under hypothetical interventions, conditional on patient characteristics\n\n(aka counterfactual prediction)\n\n\n\\[E[Y|X,\\text{do}(T)]\\]\n\n\n\n\n\nthis is not the fast road from computer science experiment to impact, but may be the most rewarding\n\n\n\n\nwhy work on it? holy grail: know what to do"
  },
  {
    "objectID": "talks/250127-dagstuhl/index.html#what-is-not-prediction-under-intervention",
    "href": "talks/250127-dagstuhl/index.html#what-is-not-prediction-under-intervention",
    "title": "my priorities for AI in health",
    "section": "What is not prediction under intervention",
    "text": "What is not prediction under intervention\nUsing QRISK to decide on blood pressure medication (which it’s not intended for)"
  },
  {
    "objectID": "talks/250127-dagstuhl/index.html#is-qrisk-bad",
    "href": "talks/250127-dagstuhl/index.html#is-qrisk-bad",
    "title": "my priorities for AI in health",
    "section": "Is QRISK bad?",
    "text": "Is QRISK bad?\n\nis it inaccurate? no, it informs of the risk of an event given that the patient has blood pressure medication (post-decision model)\nthis is not the same as the risk if we were to give blood pressure medication or not\nthese are only the same when all factors going into the decision to given the blood pressure medication are accounted for (confounders, causal inference assumptions)"
  },
  {
    "objectID": "talks/250127-dagstuhl/index.html#what-is-qrisk",
    "href": "talks/250127-dagstuhl/index.html#what-is-qrisk",
    "title": "my priorities for AI in health",
    "section": "What is QRISK?",
    "text": "What is QRISK?\n\nintended for deciding on statin treatment, excludes patients who have statins ‘on baseline’\nis trained on patients of whom some recieced statins, reducing their risk of cardiovascular events\npredicts risk of cardiovascular events under current standard of care\n‘a treatment-naive model’"
  },
  {
    "objectID": "talks/250127-dagstuhl/index.html#counseling-with-and-without-prediction-under-intervention",
    "href": "talks/250127-dagstuhl/index.html#counseling-with-and-without-prediction-under-intervention",
    "title": "my priorities for AI in health",
    "section": "Counseling with and without prediction under intervention",
    "text": "Counseling with and without prediction under intervention\nImagine this dialogue between a patient who has just been diagnosed with cancer and their oncologist First, we’ll see a conversation informed by\n\nRCT data\n\naverage outcomes (or contrast) between treatment \\(A\\) and \\(B\\)\n\nnon-causal prediction models:\n\npredict outcome given features \\(X\\), ignoring effects of potential treatments (treatment-naive / average treatment policy)\npredict outcome given features \\(X\\) and treatment \\(T\\), ignoring confounding by \\(Z\\) (post-decision models)"
  },
  {
    "objectID": "talks/250127-dagstuhl/index.html#now-a-conversation-with-prediction-under-intervention-models",
    "href": "talks/250127-dagstuhl/index.html#now-a-conversation-with-prediction-under-intervention-models",
    "title": "my priorities for AI in health",
    "section": "Now a conversation with prediction-under-intervention models",
    "text": "Now a conversation with prediction-under-intervention models\n\n\n\nOncologist: Your work-up is done, we now know your cancer type and stage\n\n\n\n\n\n\nPatient: What is my prognosis?\n\n\n\n\n\n\n\nOncologist (prediction under intervention): That depends on the treatment we choose; patients like you would on average live … years on treatment A, versus … years on treatment B.\n\n\n\n\n\n\n\n\nPatient: Thank you for this information. I will discuss this with my family and friends to decide what we think is best for me."
  },
  {
    "objectID": "talks/250127-dagstuhl/index.html#prediction-under-intervention-why-is-it-hard",
    "href": "talks/250127-dagstuhl/index.html#prediction-under-intervention-why-is-it-hard",
    "title": "my priorities for AI in health",
    "section": "Prediction under intervention, why is it hard:",
    "text": "Prediction under intervention, why is it hard:\n\nanswer a causal question, often cannot do (big enough) experiment (RCT), need assumptions otherwise (confounding, positivity)\nassumptions undermine trust; is it rigorous?\nthis holds for development and evaluations, cannot simply evaluate on held-out data\nas with any AI deployment: a trial is best level of evidence\nother forms of off policy evaluation possible (especially attractive when you have RCTs that randomized the treatments) (Uehara, Shi, and Kallus 2022)"
  },
  {
    "objectID": "talks/250127-dagstuhl/index.html#opportunities-1",
    "href": "talks/250127-dagstuhl/index.html#opportunities-1",
    "title": "my priorities for AI in health",
    "section": "opportunities:",
    "text": "opportunities:\n\nkey pieces of puzzle for personalized treatment\nboom in causal inference interest, applications can improve"
  },
  {
    "objectID": "talks/250127-dagstuhl/index.html#references",
    "href": "talks/250127-dagstuhl/index.html#references",
    "title": "my priorities for AI in health",
    "section": "References",
    "text": "References\n\n\n\n\nJoshi, Shalmali, Iñigo Urteaga, Wouter A C van Amsterdam, George Hripcsak, Pierre Elias, Benjamin Recht, Noémie Elhadad, et al. 2025. “AI as an Intervention: Improving Clinical Outcomes Relies on a Causal Approach to AI Development and Validation.” Journal of the American Medical Informatics Association, January, ocae301. https://doi.org/10.1093/jamia/ocae301.\n\n\nUehara, Masatoshi, Chengchun Shi, and Nathan Kallus. 2022. “A Review of Off-Policy Evaluation in Reinforcement Learning.” December 13, 2022. https://doi.org/10.48550/arXiv.2212.06355.\n\n\nVan Amsterdam, Wouter A. C., Nan Van Geloven, Jesse H. Krijthe, Rajesh Ranganath, and Giovanni Cinà. 2025. “When Accurate Prediction Models Yield Harmful Self-Fulfilling Prophecies.” Patterns 6 (4): 101229. https://doi.org/10.1016/j.patter.2025.101229."
  },
  {
    "objectID": "talks/250814-mlhc-workshop/causality.html#predictive-performance-measures",
    "href": "talks/250814-mlhc-workshop/causality.html#predictive-performance-measures",
    "title": "Aligning development, deployment and monitoring for AI: a causal perspective",
    "section": "Predictive performance measures",
    "text": "Predictive performance measures\n\n\n\nsensitivity, specificity\nAUC\naccuracy\ncalibration"
  },
  {
    "objectID": "talks/250814-mlhc-workshop/causality.html#predict-presence-of-heart-failure-from-ecg-yaoartificialintelligenceenabled2021",
    "href": "talks/250814-mlhc-workshop/causality.html#predict-presence-of-heart-failure-from-ecg-yaoartificialintelligenceenabled2021",
    "title": "Aligning development, deployment and monitoring for AI: a causal perspective",
    "section": "Predict presence of heart failure from ECG (Yao et al. 2021)",
    "text": "Predict presence of heart failure from ECG (Yao et al. 2021)\n\nprediction: structural heart disease\nintervention: refer patient for cardiac echo\noutcome: diagnosis of heart failure on echo\noutcome (impact): reduce preventable early cardiac death / morbidity"
  },
  {
    "objectID": "talks/250814-mlhc-workshop/causality.html#year-heart-attack-risk-hippisley-coxdevelopmentvalidationnew2024",
    "href": "talks/250814-mlhc-workshop/causality.html#year-heart-attack-risk-hippisley-coxdevelopmentvalidationnew2024",
    "title": "Aligning development, deployment and monitoring for AI: a causal perspective",
    "section": "10 year heart attack risk (Hippisley-Cox et al. 2024)",
    "text": "10 year heart attack risk (Hippisley-Cox et al. 2024)\n\nprediction: heart attack in 10 years\nintervention: prescribe cholesterol lowering medication\noutcome: heart attack\noutcome (impact): reduce heart attacks"
  },
  {
    "objectID": "talks/250814-mlhc-workshop/causality.html#predictive-performance-vs-impact",
    "href": "talks/250814-mlhc-workshop/causality.html#predictive-performance-vs-impact",
    "title": "Aligning development, deployment and monitoring for AI: a causal perspective",
    "section": "Predictive performance vs impact",
    "text": "Predictive performance vs impact\n\n\npredictive performance\n\nsensitivity, specificity\nAUC\naccuracy\ncalibration\n\n\nhealthcare impact\n\ninterventions (medical decisions)\npatient outcomes\n\n\n\nthe hope is: better predictive performance \\(\\implies\\) better impact\nunfortunately, this is not automatically the case"
  },
  {
    "objectID": "talks/250814-mlhc-workshop/causality.html#what-happened-here-18",
    "href": "talks/250814-mlhc-workshop/causality.html#what-happened-here-18",
    "title": "Aligning development, deployment and monitoring for AI: a causal perspective",
    "section": "What happened here? 18",
    "text": "What happened here? 18\n\nhad a ‘good’ model, got a bad policy\nmodel predicted outcome (survival) under historic treatment policy (always radiation)\ndid not predict what outcomes would be under alternative policy (no radiation)\nin this case, unmodeled treatment effect heterogeneity (aka treatment effect modification, interation, differing conditional average treatment effects)"
  },
  {
    "objectID": "talks/250814-mlhc-workshop/causality.html#lets-monitor-the-ai-model-for-performance-over-time",
    "href": "talks/250814-mlhc-workshop/causality.html#lets-monitor-the-ai-model-for-performance-over-time",
    "title": "Aligning development, deployment and monitoring for AI: a causal perspective",
    "section": "Let’s monitor the AI model for performance over time",
    "text": "Let’s monitor the AI model for performance over time"
  },
  {
    "objectID": "talks/250814-mlhc-workshop/causality.html#what-happened-in-monitoring",
    "href": "talks/250814-mlhc-workshop/causality.html#what-happened-in-monitoring",
    "title": "Aligning development, deployment and monitoring for AI: a causal perspective",
    "section": "What happened in monitoring?",
    "text": "What happened in monitoring?\n\nthe model re-inforced its own predictions (self-fulfilling prophecy)\ntook a measure of predictive performance (AUC)\nmistook it for a measure of (good) impact\nmany potential examples (e.g. ICU stop treatment (Balcarcel et al. 2025), others (Center n.d.))"
  },
  {
    "objectID": "talks/250814-mlhc-workshop/causality.html#prediction-model-walking-stick",
    "href": "talks/250814-mlhc-workshop/causality.html#prediction-model-walking-stick",
    "title": "Aligning development, deployment and monitoring for AI: a causal perspective",
    "section": "Prediction model: walking stick",
    "text": "Prediction model: walking stick\nData Scientist are concerned with optimizing predictive performance"
  },
  {
    "objectID": "talks/250814-mlhc-workshop/causality.html#health-care-provider-stick-user",
    "href": "talks/250814-mlhc-workshop/causality.html#health-care-provider-stick-user",
    "title": "Aligning development, deployment and monitoring for AI: a causal perspective",
    "section": "Health care provider: stick user",
    "text": "Health care provider: stick user\nThe healthcare provider uses the prediction model for decision making"
  },
  {
    "objectID": "talks/250814-mlhc-workshop/causality.html#health-care-provider-stick-policy",
    "href": "talks/250814-mlhc-workshop/causality.html#health-care-provider-stick-policy",
    "title": "Aligning development, deployment and monitoring for AI: a causal perspective",
    "section": "Health care provider + stick = policy",
    "text": "Health care provider + stick = policy\nThis combination leads to a new policy, which may yield unexpected results"
  },
  {
    "objectID": "talks/250814-mlhc-workshop/causality.html#when-predicting-an-outcome-to-support-decisions-regarding-an-intervention",
    "href": "talks/250814-mlhc-workshop/causality.html#when-predicting-an-outcome-to-support-decisions-regarding-an-intervention",
    "title": "Aligning development, deployment and monitoring for AI: a causal perspective",
    "section": "When predicting an outcome to support decisions regarding an intervention,",
    "text": "When predicting an outcome to support decisions regarding an intervention,\nthis prediction needs a clear relationship with the targeted intervention (van Amsterdam et al. 2024)\n\n\n\nHilden and Habbema on prognosis (Hilden and Habbema 1987)\n\n\n“Prognosis cannot be divorced from contemplated medical action, nor from action to be taken by the patient in response to prognostication.”\n\n\n\n\nnot: what’s risk of heart attack given age and cholesterol,\nbut: what’s risk of heart attack given age and cholesterol, if we were not to give cholesterol lowering medication (vs. if we would)\nmay sound like \\(1+1=2\\) but often not done; e.g. in the development data of Qrisk3, many patients already underwent cholesterol lowering medication (Peek, Sperrin, and van Staa 2017)"
  },
  {
    "objectID": "talks/250814-mlhc-workshop/causality.html#prediction-under-hypothetical-intervention-incorporates-effects-of-treatment-in-its-predictions",
    "href": "talks/250814-mlhc-workshop/causality.html#prediction-under-hypothetical-intervention-incorporates-effects-of-treatment-in-its-predictions",
    "title": "Aligning development, deployment and monitoring for AI: a causal perspective",
    "section": "Prediction under hypothetical intervention incorporates effects of treatment in its predictions",
    "text": "Prediction under hypothetical intervention incorporates effects of treatment in its predictions\n\nestimates the expected outcome \\(Y\\)\n\nif we were to give treatment \\(T\\) to patient with features \\(X\\)\n\na.k.a. ‘counterfactual prediction’\ncan predict outcomes under multiple treatments, where one treatment may be ‘no (additional) treatment / standard treatment’"
  },
  {
    "objectID": "talks/250814-mlhc-workshop/causality.html#how-to-build-prediction-under-intervention-models",
    "href": "talks/250814-mlhc-workshop/causality.html#how-to-build-prediction-under-intervention-models",
    "title": "Aligning development, deployment and monitoring for AI: a causal perspective",
    "section": "How to build prediction under intervention models?",
    "text": "How to build prediction under intervention models?\n\nin its simplest form, can be just like fitting any other predictive model, as long as causal identifyability assumptions are fulfilled:\n\nunconfoundedness (no hidden variables causing both the intervention and the outcome)\npositivity, consistency\n\nthese hold by design in Randomized Controlled Trials (RCT)\nRCTs are in that sense ideal (e.g. Kent et al. 2020), but:\n\ntypically limited sample size\nmay not have measured right information (e.g. imaging markers, new biomarkers, full-EHR)\ntrial participants may not be representative of the target population of use (e.g. Lewis et al. 2003)\n\ncan emulate RCTs with non-experimental (observational) data using a causal inference framework, e.g. using target trial emulation"
  },
  {
    "objectID": "talks/250814-mlhc-workshop/causality.html#benefits-of-prediction-under-intervention",
    "href": "talks/250814-mlhc-workshop/causality.html#benefits-of-prediction-under-intervention",
    "title": "Aligning development, deployment and monitoring for AI: a causal perspective",
    "section": "Benefits of prediction under intervention",
    "text": "Benefits of prediction under intervention\n\npolicy rule: if expected outcome under treatment \\(A\\) is better than under treatment \\(B\\) (potentially by a certain margin), give treatment \\(A\\), otherwise \\(B\\)\nas opposed to other prediction models, this policy has foreseable positive impact on health outcomes"
  },
  {
    "objectID": "talks/250814-mlhc-workshop/causality.html#benefits-of-prediction-under-intervention-1",
    "href": "talks/250814-mlhc-workshop/causality.html#benefits-of-prediction-under-intervention-1",
    "title": "Aligning development, deployment and monitoring for AI: a causal perspective",
    "section": "Benefits of prediction under intervention",
    "text": "Benefits of prediction under intervention\n\npolicy rule: if expected outcome under treatment \\(A\\) is better than under treatment \\(B\\) (potentially by a certain margin), give treatment \\(A\\), otherwise \\(B\\)\nas opposed to other prediction models, this policy has foreseable positive impact on health outcomes\nas a ‘bonus’, these models have stable calibration under shifts in policy that depend on the models’ features (e.g. Feng et al. 2024)"
  },
  {
    "objectID": "talks/250814-mlhc-workshop/causality.html#measuring-pre--and-post-deployment",
    "href": "talks/250814-mlhc-workshop/causality.html#measuring-pre--and-post-deployment",
    "title": "Aligning development, deployment and monitoring for AI: a causal perspective",
    "section": "Measuring pre- and post-deployment",
    "text": "Measuring pre- and post-deployment\n\n\n\n\n\npre-deploy\ndeployment study\n\n\n\n\n\nmetric\n\n\n\n\nmodel\ndiscrimination (AUC)\n✅\n\n\n\n\ncalibration\n✅\n\n\n\nhealth system\ninterventions\n✅\n\n\n\n\npatient outcomes\n✅\n\n\n\n\nLegend\n🔁 changes ✅ stable 🔻 worsens"
  },
  {
    "objectID": "talks/250814-mlhc-workshop/causality.html#measuring-pre--and-post-deployment-1",
    "href": "talks/250814-mlhc-workshop/causality.html#measuring-pre--and-post-deployment-1",
    "title": "Aligning development, deployment and monitoring for AI: a causal perspective",
    "section": "Measuring pre- and post-deployment",
    "text": "Measuring pre- and post-deployment\n\n\n\n\n\npre-deploy\npost-deploy\n\n\n\n\n\nmetric\n\n\n\n\nmodel\ndiscrimination (AUC)\n✅\n🔁\n\n\n\ncalibration\n✅\n🔻\n\n\nhealth system\ninterventions\n✅\n🔁\n\n\n\npatient outcomes\n✅\n🔁\n\n\n\nLegend\n🔁 changes ✅ stable 🔻 worsens\n\nfor ‘non-causal’ prognosis prediction models that don’t factor in treatment decisions:\n\nAUC will change, calibration will worsen as distribution changes\ninterventions and patient outcomes may change in unforeseen ways"
  },
  {
    "objectID": "talks/250814-mlhc-workshop/causality.html#measuring-pre--and-post-deployment-2",
    "href": "talks/250814-mlhc-workshop/causality.html#measuring-pre--and-post-deployment-2",
    "title": "Aligning development, deployment and monitoring for AI: a causal perspective",
    "section": "Measuring pre- and post-deployment",
    "text": "Measuring pre- and post-deployment\n\n\n\n\n\n\n\n\n\n\n\n\npre-deploy\n‘non-causal’\n‘causal’\n\n\n\n\n\nmetric\n\n\n\n\n\nmodel\ndiscrimination (AUC)\n✅\n🔁\n🔁\n\n\n\ncalibration\n✅\n🔻\n✅\n\n\nhealth system\ninterventions\n✅\n🔁\n📈\n\n\n\npatient outcomes\n✅\n🔁\n📈\n\n\n\nLegend\n🔁 changes ✅ stable 🔻 worsens 📈 changes in expected way\n\nfor prediction under intervention model\n\ncalibration preserved under shifts in policy conditional on the model’s features\ninterventions and outcomes change in foreseeable ways (under assumption on policy)"
  },
  {
    "objectID": "talks/250814-mlhc-workshop/causality.html#current-status",
    "href": "talks/250814-mlhc-workshop/causality.html#current-status",
    "title": "Aligning development, deployment and monitoring for AI: a causal perspective",
    "section": "Current status",
    "text": "Current status\n\nreporting guidelines (e.g. TRIPOD+AI (Collins et al. 2024)) do not require a clear enoough description of relation between prediction and treatment (“Prognostic Models for Decision Support Need to Report Their Targeted Treatments and the Expected Changes in Treatment Decisions” 2024)\nsome acceptance criteria lists even allow for harmful self-fulfilling prophecies (Kattan et al. 2016)\nEMA and FDA are developing monitoring guidelines, mostly emphasis on predictive performance, but good performance \\(\\neq\\) postive impact"
  },
  {
    "objectID": "talks/250814-mlhc-workshop/causality.html#takeaways",
    "href": "talks/250814-mlhc-workshop/causality.html#takeaways",
    "title": "Aligning development, deployment and monitoring for AI: a causal perspective",
    "section": "Takeaways",
    "text": "Takeaways\n\nwhen predicting prognosis, need well defined relation between prediction and potential treatment decisions\nin particular, prediction under intervention has the advantages of:\n\nclear relationship between model performance and value for decision making\nstable calibration under shifts in treatment policy, conditional on the model’s features\n\nthese models need unconfoundedness, so either\n\ndevelop using RCT data\nuse observational causal inference\n\nevaluate and monitor AI based on what we care about: impact on healthcare"
  },
  {
    "objectID": "talks/250814-mlhc-workshop/causality.html#references",
    "href": "talks/250814-mlhc-workshop/causality.html#references",
    "title": "Aligning development, deployment and monitoring for AI: a causal perspective",
    "section": "References",
    "text": "References\n\n\n\n\nAmsterdam, W.A. C. van, Giovanni Cinà, Vanessa Didelez, Ruth H. Keogh, Niels Peek, Matthew Sperrin, Andrew J. Vickers, Nan van Geloven, and Uri Shalit. 2024. “Prognostic Models for Decision Support Need to Report Their Targeted Treatments and the Expected Changes in Treatment Decisions [Rapid Response].” BMJ, May. https://doi.org/10.1136/bmj-2023-078378/rr-1.\n\n\nBalcarcel, Daniel R, Sanjiv D Mehta, Celeste G Dixon, Charlotte Z Woods-Hill, Ewan C Goligher, Wouter A C Van Amsterdam, and Nadir Yehya. 2025. “Feedback Loops in Intensive Care Unit Prognostic Models: An Under-Recognised Threat to Clinical Validity.” The Lancet Digital Health, July, 100880. https://doi.org/10.1016/j.landig.2025.100880.\n\n\nCenter, Science Media. n.d. “Expert Reaction to Study Suggesting Potential Patient Harms Associated with Use of AI Medical Outcome-Prediction Models | Science Media Centre.” Accessed August 12, 2025. https://www.sciencemediacentre.org/expert-reaction-to-study-suggesting-potential-patient-harms-associated-with-use-of-ai-medical-outcome-prediction-models/.\n\n\nCollins, Gary S., Karel G. M. Moons, Paula Dhiman, Richard D. Riley, Andrew L. Beam, Ben Van Calster, Marzyeh Ghassemi, et al. 2024. “TRIPOD+AI Statement: Updated Guidance for Reporting Clinical Prediction Models That Use Regression or Machine Learning Methods.” BMJ 385 (April): e078378. https://doi.org/10.1136/bmj-2023-078378.\n\n\nFeng, Jean, Alexej Gossmann, Gene A. Pennello, Nicholas Petrick, Berkman Sahiner, and Romain Pirracchio. 2024. “Monitoring Machine Learning-Based Risk Prediction Algorithms in the Presence of Performativity.” In Proceedings of The 27th International Conference on Artificial Intelligence and Statistics, 919–27. PMLR. https://proceedings.mlr.press/v238/feng24b.html.\n\n\nHilden, Jørgen, and J. Dik F. Habbema. 1987. “Prognosis in Medicine: An Analysis of Its Meaning and Rôles.” Theoretical Medicine 8 (3): 349–65. https://doi.org/10.1007/BF00489469.\n\n\nHippisley-Cox, Julia, Carol A. C. Coupland, Mona Bafadhel, Richard E. K. Russell, Aziz Sheikh, Peter Brindle, and Keith M. Channon. 2024. “Development and Validation of a New Algorithm for Improved Cardiovascular Risk Prediction.” Nature Medicine, April. https://doi.org/10.1038/s41591-024-02905-y.\n\n\nKattan, Michael W., Kenneth R. Hess, Mahul B. Amin, Ying Lu, Karl G. M. Moons, Jeffrey E. Gershenwald, Phyllis A. Gimotty, et al. 2016. “American Joint Committee on Cancer Acceptance Criteria for Inclusion of Risk Models for Individualized Prognosis in the Practice of Precision Medicine.” CA: A Cancer Journal for Clinicians 66 (5): 370–74. https://doi.org/10.3322/caac.21339.\n\n\nKent, David M., Jessica K. Paulus, David van Klaveren, Ralph D’Agostino, Steve Goodman, Rodney Hayward, John P. A. Ioannidis, et al. 2020. “The Predictive Approaches to Treatment Effect Heterogeneity (PATH) Statement.” Annals of Internal Medicine 172 (1): 35–45. https://doi.org/10.7326/M18-3667.\n\n\nLewis, Joy H., Meredith L. Kilgore, Dana P. Goldman, Edward L. Trimble, Richard Kaplan, Michael J. Montello, Michael G. Housman, and José J. Escarce. 2003. “Participation of Patients 65 Years of Age or Older in Cancer Clinical Trials.” Journal of Clinical Oncology 21 (7): 1383–89. https://doi.org/10.1200/JCO.2003.08.010.\n\n\nPeek, Niels, Matthew Sperrin, and Tjeerd van Staa. 2017. “Hari Seldon, QRISK3, and the Prediction Paradox.” BMJ 2017;357:j2099, May. https://doi.org/10.1136/bmj.j2099.\n\n\n“Prognostic Models for Decision Support Need to Report Their Targeted Treatments and the Expected Changes in Treatment Decisions.” 2024, December. https://www.bmj.com/content/385/bmj-2023-078378/rr-1.\n\n\nVan Amsterdam, Wouter A. C., Nan Van Geloven, Jesse H. Krijthe, Rajesh Ranganath, and Giovanni Cinà. 2025. “When Accurate Prediction Models Yield Harmful Self-Fulfilling Prophecies.” Patterns 6 (4): 101229. https://doi.org/10.1016/j.patter.2025.101229.\n\n\nYao, Xiaoxi, David R. Rushlow, Jonathan W. Inselman, Rozalina G. McCoy, Thomas D. Thacher, Emma M. Behnken, Matthew E. Bernard, et al. 2021. “Artificial Intelligence–Enabled Electrocardiograms for Identification of Patients with Low Ejection Fraction: A Pragmatic, Randomized Clinical Trial.” Nature Medicine 27 (5): 815–19. https://doi.org/10.1038/s41591-021-01335-4."
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#todays-readings",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#todays-readings",
    "title": "Pearl Causal Hierarchy",
    "section": "Today’s readings:",
    "text": "Today’s readings:\n\nBareinboim’s paper / book chapter: Bareinboim et al. (2022)\nBook of why chapter 1: Pearl and Mackenzie (2018)\nPearl’s note on hierarchy: Pearl (n.d.)"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#the-ladder-is-a-hierarchy-of-questions",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#the-ladder-is-a-hierarchy-of-questions",
    "title": "Pearl Causal Hierarchy",
    "section": "The ladder is a hierarchy of questions",
    "text": "The ladder is a hierarchy of questions\n\ntable 1"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#notation",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#notation",
    "title": "Pearl Causal Hierarchy",
    "section": "Notation",
    "text": "Notation\n\n\\(X\\): treatment (binary, 0,1)\n\\(Y\\): outcome (binary)\n\\(Z\\): covariate (age, sex)\n\\(p(Y|Z)\\): conditional distribution of \\(Y\\) given \\(Z\\) (e.g. regression, ‘prediction’)\n\\(p(Y_x)\\): the causal effect of \\(X\\) on \\(Y\\), e.g.:\n\n\\(p(Y_{X=1}=1)\\): the probability that \\(Y\\) would take value 1 when we would set \\(X\\) to 1 by intervention\n\\(P(Y_1) - P(Y_0) = \\text{ATE}\\) (average treatment effect)"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#layer-1-association",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#layer-1-association",
    "title": "Pearl Causal Hierarchy",
    "section": "Layer 1: association",
    "text": "Layer 1: association\n\nWhat is the relationship between two or more variables?\nrequired:\n\ndata (observational / non-experimental): \\(p(X,Y,Z)\\)\n\nquestions:\n\nwhat is the expected survival for men, and for women? \\(p(Y|Z=1)\\), \\(p(Y|Z=0)\\)"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#layer-2-intervention",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#layer-2-intervention",
    "title": "Pearl Causal Hierarchy",
    "section": "Layer 2: intervention",
    "text": "Layer 2: intervention\n\nWhat happens if we intervene on a variable?\nby how much would survival change if we would treat every patient with a certain drug?\n\nthis can be made subgroup specific (the conditional average treatment effect: CATE), e.g. covariate \\(Z\\): \\(p(Y_{X=1}|Z) - p(Y_{X=0}|Z)\\)\nwhen covariate \\(Z\\) is continuous, every patient has a different CATE, but conceptually this is still the CATE (average over population with same / similar value of \\(Z\\)), not individual treatment effect\n\n\\(p(Y_{X=1}=1|Z=z)\\): the conditional probability that \\(Y\\) would take value 1 when we would set \\(X\\) to 1 by intervention, given that \\(Z=z\\)\n\naka ‘prediction under (hypothertical) intervention’\naka ‘potential outcome prediction’\naka ‘counterfactual prediction’"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#layer-2-intervention-what-is-required",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#layer-2-intervention-what-is-required",
    "title": "Pearl Causal Hierarchy",
    "section": "Layer 2: intervention, what is required?",
    "text": "Layer 2: intervention, what is required?\n\ndata where \\(X\\) is controlled by experimentation (randomized controlled trial)\nobservational data + sufficient assumptions, typically:\n\n\nthe directed acyclic graph (DAG) for the variables and no unobserved confounders\n\n\n\n\n\nDAG 1"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#layer-3-counterfactuals",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#layer-3-counterfactuals",
    "title": "Pearl Causal Hierarchy",
    "section": "Layer 3: counterfactuals",
    "text": "Layer 3: counterfactuals\n\nWhat would have happened if we had done something else?\nquestions:\n\ngiven that the ICU patient got vancomycin and developed acute kidney injury, would she have developed AKI if she had not received vancomycin?\n\\(P(Y_{X=0}=1|Y=1,X=1)\\)\n\ncounterfactuals have an element of:\n\nsomething occured in the world (a fact)\nwhat if we went back to the world and changed a thing, what would have occured then? (a counterfact)\n\nrequired:\n\nknowledge of functional relationships"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#the-hierarchy-what-are-the-worlds",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#the-hierarchy-what-are-the-worlds",
    "title": "Pearl Causal Hierarchy",
    "section": "The hierarchy, what are the worlds?",
    "text": "The hierarchy, what are the worlds?"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#layer-2-directed-acyclic-graph-dag",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#layer-2-directed-acyclic-graph-dag",
    "title": "Pearl Causal Hierarchy",
    "section": "Layer 2: directed acyclic graph (DAG)",
    "text": "Layer 2: directed acyclic graph (DAG)\n\nassociation: the world as it is\nintervention: the world as we could be under an intervention (as it would be / is in an experiment)\ncounterfactuals: the world as it was, and how it might have been if something had been different"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#the-hierarchy-what-are-the-worlds-1",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#the-hierarchy-what-are-the-worlds-1",
    "title": "Pearl Causal Hierarchy",
    "section": "The hierarchy, what are the worlds?",
    "text": "The hierarchy, what are the worlds?\n\none real world\none hypothetical world (or real in experiment)\none real world and a hypothetical world"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#what-are-the-layers-useful-for",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#what-are-the-layers-useful-for",
    "title": "Pearl Causal Hierarchy",
    "section": "What are the layers useful for?",
    "text": "What are the layers useful for?\n\nassociation: description, prediction (know what to expect when observing the world with hands on our backs)\nintervention: policy making, decision making (know what to expect when we change the world)\ncounterfactuals: explanation, understanding:\n\n\ndrug side effects\ndigital twins: a digital representation of a physical object or system: typically assumes counterfactual level knowledge, e.g. Sel et al. (2024)\nquestions of fairness"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#what-is-a-scm",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#what-is-a-scm",
    "title": "Pearl Causal Hierarchy",
    "section": "What is a SCM?",
    "text": "What is a SCM?\n\ndefinition of SCM\n\\(U\\) is a set of background variables, also called exogenous variables, that are determined by factors outside the model;\n\\(V\\) is a set \\(\\{V_1,V_2,...,V_n\\}\\) of variables, called endogenous, that are determined by other variables in the model - that is, variables in \\(U\\cup V\\);\n\\(F\\) is a set of functions \\(\\{ f_1, f_2,..., f_n\\}\\) such that each fiis a mapping from (the respective domains of) \\(U_i \\cup Pa_i \\to V_i\\), where \\(U_i \\subset U\\), \\(Pa_i \\subset V - Vi\\), and the entire set \\(F\\) forms a mapping from \\(U\\) to \\(V\\). That is, for \\(i = 1,...,n\\), each \\(f_i \\in F\\) is such that\n\n\n\\[v_i \\leftarrow f_i(pa_i, u_i)\\]\n\ni.e., it assigns a value to \\(V_i\\) that depends on (the values of) a select set of variables in \\(U \\cup V\\); and\n\\(P(U)\\) is a probability function defined over the domain of \\(U\\)."
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#how-are-scms-and-dags-related",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#how-are-scms-and-dags-related",
    "title": "Pearl Causal Hierarchy",
    "section": "How are SCMs and DAGs related?",
    "text": "How are SCMs and DAGs related?\nA recursive SCM implies a DAG, by following the order of arguments in the set of functions \\(F\\). E.G.:\n\n\n\n\\[\nF = \\begin{cases}\n      Z \\leftarrow f(U_Z)\n\\end{cases}\n\\]"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#how-are-scms-and-dags-related-1",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#how-are-scms-and-dags-related-1",
    "title": "Pearl Causal Hierarchy",
    "section": "How are SCMs and DAGs related?",
    "text": "How are SCMs and DAGs related?\nA recursive SCM implies a DAG, by following the order of arguments in the set of functions \\(F\\). E.G.:\n\n\n\n\\[\nF = \\begin{cases}\n      Z \\leftarrow f(U_Z) \\\\\n      X \\leftarrow f(Z, U_X)\n\\end{cases}\n\\]"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#how-are-scms-and-dags-related-2",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#how-are-scms-and-dags-related-2",
    "title": "Pearl Causal Hierarchy",
    "section": "How are SCMs and DAGs related?",
    "text": "How are SCMs and DAGs related?\nA recursive SCM implies a DAG, by following the order of arguments in the set of functions \\(F\\). E.G.:\n\n\n\n\\[\nF = \\begin{cases}\n      Z \\leftarrow f(U_Z) \\\\\n      X \\leftarrow f(Z, U_X) \\\\\n      Y \\leftarrow f(X, Z, U_Y)\n\\end{cases}\n\\]"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#how-are-scms-and-dags-related-3",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#how-are-scms-and-dags-related-3",
    "title": "Pearl Causal Hierarchy",
    "section": "How are SCMs and DAGs related?",
    "text": "How are SCMs and DAGs related?\n\nA (recursive) SCM implies a DAG,\nbut has strictly more information as not only the functional arguments are known,\nbut also the functions themselves"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#intervening-in-a-scm-a-submodel",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#intervening-in-a-scm-a-submodel",
    "title": "Pearl Causal Hierarchy",
    "section": "Intervening in a SCM: a submodel",
    "text": "Intervening in a SCM: a submodel\nA recursive SCM implies a DAG, by following the order of arguments in the set of functions \\(F\\). E.G.:\n\n\n\n\\[\nF = \\begin{cases}\n      Z \\leftarrow f(U_Z) \\\\\n      X \\leftarrow X' \\\\\n      Y \\leftarrow f(X, Z, U_Y)\n\\end{cases}\n\\]\n\n\n\n\nWe can compute the effect of an action by replacing one \\(f\\) with a constant, e.g. \\(X \\leftarrow X'\\), keep everything else the same, and evaluate the outcomes"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#intermezzo-critique-on-the-hierarchy",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#intermezzo-critique-on-the-hierarchy",
    "title": "Pearl Causal Hierarchy",
    "section": "Intermezzo: critique on the hierarchy",
    "text": "Intermezzo: critique on the hierarchy\n\nThe Pearl Causal Hierarchy is a hiearchy of questions\nSome (rightly) argue that the ‘higher’ we go, the more prior assumptions are needed, and the less we rely on experiments\nIn a sense of empirical science, the hierarchy is upside down"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#theorem-1",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#theorem-1",
    "title": "Pearl Causal Hierarchy",
    "section": "Theorem 1",
    "text": "Theorem 1\n\nTheorem 1"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#example-7a",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#example-7a",
    "title": "Pearl Causal Hierarchy",
    "section": "example 7a",
    "text": "example 7a\n\\(X\\): treatment, \\(Y\\): outcome, \\(U_1, U_2\\): exogenous noise variables; \\(p(U_1=1)=p(U_2=1)=0.5\\)\n\\[\nF = \\begin{cases}\n      X \\leftarrow U_1 \\\\\n      Y \\leftarrow U_2\n\\end{cases}\n\\]\n\ntreatment: coin flip\nsurvival: coin flip (not affected by \\(X\\))\n\n\n\\[\nF' = \\begin{cases}\n      X \\leftarrow 1_{U_1=U_2} \\\\\n      Y \\leftarrow U_1 + 1_{X=1,U+1=0,U_2=1}\n\\end{cases}\n\\]\n\nsurvival: affected by \\(X\\)"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#example-7a-1",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#example-7a-1",
    "title": "Pearl Causal Hierarchy",
    "section": "example 7a",
    "text": "example 7a\n\\[\nF = \\begin{cases}\n      X \\leftarrow U_1 \\\\\n      Y \\leftarrow U_2\n\\end{cases}\n\\]\n\\[\nF' = \\begin{cases}\n      X \\leftarrow 1_{U_1=U_2} \\\\\n      Y \\leftarrow U_1 + 1_{X=1,U+1=0,U_2=1}\n\\end{cases}\n\\]\n\nboth models: same level 1 (observational) distribution \\(p(X,Y)\\)\ndifferent level 2: \\(Y_{X}\\)\ncannot tell models apart from observatoinal data alone (i.e. causal effect not identified)"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#example-7b",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#example-7b",
    "title": "Pearl Causal Hierarchy",
    "section": "example 7b",
    "text": "example 7b\n\\(X\\): treatment, \\(Y\\): outcome, \\(U_1, U_2\\): exogenous noise variables; \\(p(U_1=1)=p(U_2=1)=0.5\\)\n\\[\nF = \\begin{cases}\n      X \\leftarrow U_1 \\\\\n      Y \\leftarrow U_2\n\\end{cases}\n\\]\n\n\\[\nF' = \\begin{cases}\n      X \\leftarrow U_1 \\\\\n      Y \\leftarrow X U_2 + (1-X)(1-U_2)\n\\end{cases}\n\\]\n\n‘the effect of treatment is determined by the coinflip’\n\n\n\n\nboth models: same level 2 (interventional) distributions\ndifferent level 3: \\(Y_{X=0}=1|X=1,Y=0)\\)\ncannot tell models apart from level 2 data alone"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#potential-outcomes-framwork",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#potential-outcomes-framwork",
    "title": "Pearl Causal Hierarchy",
    "section": "Potential outcomes framwork:",
    "text": "Potential outcomes framwork:\nImage two possible futures for a patient"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#potential-outcomes-vs-scms",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#potential-outcomes-vs-scms",
    "title": "Pearl Causal Hierarchy",
    "section": "Potential outcomes vs SCMs",
    "text": "Potential outcomes vs SCMs\n\nwhy I like the term potential outcomes: it has a clear sense of futures\ncounterfactual in the PO framework: has a clear definition and interpretation\nwhat I don’t like: using the term counterfactual outcomes when the potential outcomes are meant, and neither has occured yet\n\ne.g. counterfactual prediction\n\nin the SCM frawmwork, counterfactuals are closer to the word:\n\na fact has been observed (the real world)\na counter fact has been asked\nthis actually conditions on the observed factual data (often not the case in PO framework)\n\n“given that the ICU patient got vancomycin and developed acute kidney injury, would she have developed AKI if she had not received vancomycin?”"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#references",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#references",
    "title": "Pearl Causal Hierarchy",
    "section": "References",
    "text": "References\n\n\n\n\nBareinboim, Elias, Juan Correa, Duligur Ibeling, and Thomas Icard. 2022. “On Pearl’s Hierarchy and the Foundations of Causal Inference (1st Edition).” In Probabilistic and Causal Inference: The Works of Judea Pearl, edited by Hector Geffner, Rita Dechter, and Joseph Halpern, 507–56. ACM Books.\n\n\nPearl, Judea. n.d. “The Three Layer Causal Hierarchy.” Accessed November 4, 2024. https://web.cs.ucla.edu/~kaoru/3-layer-causal-hierarchy.pdf.\n\n\nPearl, Judea, and Dana Mackenzie. 2018. The Book of Why: The New Science of Cause and Effect. 1st edition. New York: Basic Books.\n\n\nSel, Kaan, Deen Osman, Fatemeh Zare, Sina Masoumi Shahrbabak, Laura Brattain, Jin‐Oh Hahn, Omer T. Inan, et al. 2024. “Building Digital Twins for Cardiovascular Health: From Principles to Clinical Impact.” Journal of the American Heart Association 13 (19): e031981. https://doi.org/10.1161/JAHA.123.031981."
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#ai-may-have-many-uses-in-health-care",
    "href": "talks/240530-weon-masterclass/index.html#ai-may-have-many-uses-in-health-care",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "AI may have many uses in health care",
    "text": "AI may have many uses in health care\nUse AI to make health care\n\n\nmore efficient or easier\n\nadministration / documentation\ntranslation\n\n\nbetter: change decisions\n\ndiagnosis (e.g. skin cancer from imaging)\nprognosis (e.g. survival given medical image)\ntreatment effect (e.g. genetic biomarker)"
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#section",
    "href": "talks/240530-weon-masterclass/index.html#section",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "",
    "text": "prognosis (e.g. survival given medical image)\ntreatment effect (e.g. genetic biomarker)\n\n\n\n\n\nTip\n\n\nWhereas treatment effect estimation is typically thought of as a causal task requiring causal approaches (e.g. randomized controllerd trials), prognosis models are often advertised for making treatment decisions."
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#the-in-between-using-prediction-models-for-medical-decision-making",
    "href": "talks/240530-weon-masterclass/index.html#the-in-between-using-prediction-models-for-medical-decision-making",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "The in-between: using prediction models for (medical) decision making",
    "text": "The in-between: using prediction models for (medical) decision making\n\nprognosis (e.g. survival given medical image)"
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#using-prediction-models-for-decision-making-is-often-thought-of-as-a-good-idea",
    "href": "talks/240530-weon-masterclass/index.html#using-prediction-models-for-decision-making-is-often-thought-of-as-a-good-idea",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "Using prediction models for decision making is often thought of as a good idea",
    "text": "Using prediction models for decision making is often thought of as a good idea\nFor example:\n\ngive chemotherapy to cancer patients with high predicted risk of recurrence\ngive statins to patients with a high risk of a heart attack\n\n\n\n\n\nTRIPOD+AI on prediction models (collinsTRIPODAIStatement2024?)\n\n\n“Their primary use is to support clinical decision making, such as … initiate treatment or lifestyle changes.”"
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#building-models-for-decision-support-without-regards-for-the-historic-treatment-policy-is-a-bad-idea",
    "href": "talks/240530-weon-masterclass/index.html#building-models-for-decision-support-without-regards-for-the-historic-treatment-policy-is-a-bad-idea",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "Building models for decision support without regards for the historic treatment policy is a bad idea",
    "text": "Building models for decision support without regards for the historic treatment policy is a bad idea"
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#treatment-naive-prediction-models",
    "href": "talks/240530-weon-masterclass/index.html#treatment-naive-prediction-models",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "Treatment-naive prediction models",
    "text": "Treatment-naive prediction models\n\n\n\n\n\\[\\begin{align}\n    E[Y|X] \\class{fragment}{= E[E_{t~\\sim \\pi_0(X)}[Y|X,t]]}\n\\end{align}\\]"
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#treatment-naive-prediction-models-1",
    "href": "talks/240530-weon-masterclass/index.html#treatment-naive-prediction-models-1",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "Treatment-naive prediction models",
    "text": "Treatment-naive prediction models\nResults from (vanamsterdamWhenAccuratePrediction2024a?)\n\ngood or bad discrimination post deployment may be a sign of a harmful or a beneficial policy change\nmodels that are perfectly calibrated before and after deployment are certainly not useful for decision making because they didn’t change the distribution"
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#prediction-modeling-is-very-popular-in-medical-research",
    "href": "talks/240530-weon-masterclass/index.html#prediction-modeling-is-very-popular-in-medical-research",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "Prediction modeling is very popular in medical research",
    "text": "Prediction modeling is very popular in medical research"
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#recommended-validation-practices-and-reporting-guidelines-do-not-protect-against-harm",
    "href": "talks/240530-weon-masterclass/index.html#recommended-validation-practices-and-reporting-guidelines-do-not-protect-against-harm",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "Recommended validation practices and reporting guidelines do not protect against harm",
    "text": "Recommended validation practices and reporting guidelines do not protect against harm\nbecause they do not evaluate the policy change"
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#bigger-data-does-not-protect-against-harmful-prediction-models",
    "href": "talks/240530-weon-masterclass/index.html#bigger-data-does-not-protect-against-harmful-prediction-models",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "Bigger data does not protect against harmful prediction models",
    "text": "Bigger data does not protect against harmful prediction models"
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#more-flexible-models-do-not-protect-against-harmful-prediction-models",
    "href": "talks/240530-weon-masterclass/index.html#more-flexible-models-do-not-protect-against-harmful-prediction-models",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "More flexible models do not protect against harmful prediction models",
    "text": "More flexible models do not protect against harmful prediction models"
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#gap-between-prediction-accuracy-and-value-for-decision-making",
    "href": "talks/240530-weon-masterclass/index.html#gap-between-prediction-accuracy-and-value-for-decision-making",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "Gap between prediction accuracy and value for decision making",
    "text": "Gap between prediction accuracy and value for decision making"
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#section-1",
    "href": "talks/240530-weon-masterclass/index.html#section-1",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "",
    "text": "What to do?"
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#section-2",
    "href": "talks/240530-weon-masterclass/index.html#section-2",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "",
    "text": "What to do?\n\n\nEvaluate policy change (cluster randomized controlled trial)\nBuild models that are likely to have value for decision making"
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#deploying-a-model-is-an-intervention-that-changes-the-way-treatment-decisions-are-made",
    "href": "talks/240530-weon-masterclass/index.html#deploying-a-model-is-an-intervention-that-changes-the-way-treatment-decisions-are-made",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "Deploying a model is an intervention that changes the way treatment decisions are made",
    "text": "Deploying a model is an intervention that changes the way treatment decisions are made"
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#how-do-we-learn-about-the-effect-of-an-intervention",
    "href": "talks/240530-weon-masterclass/index.html#how-do-we-learn-about-the-effect-of-an-intervention",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "How do we learn about the effect of an intervention?",
    "text": "How do we learn about the effect of an intervention?\nWith a randomized experiment\n\n\nfor using a decision support model, the unit of intervention is usually the doctor\nrandomly assign doctors to have access to the model or not\nmeasure differences in treatment decisions and patient outcomes\nthis called a cluster RCT\nif using model improves outcomes, use that one\n\n\n\n\n\nUsing cluster RCTs to evaluated models for decision making is not a new idea (Cooper et al. 1997)\n\n\n“As one possibility, suppose that a trial is performed in which clinicians are randomized either to have or not to have access to such a decision aid in making decisions about where to treat patients who present with pneumonia.”\n\n\n\n\n\n\n\n\n\n\n\nWhat we don’t learn\n\n\nwas the model predicting anything sensible?"
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#so-build-treatment-naive-prediction-models-and-trial-them-for-decision-support",
    "href": "talks/240530-weon-masterclass/index.html#so-build-treatment-naive-prediction-models-and-trial-them-for-decision-support",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "So build treatment-naive prediction models and trial them for decision support?",
    "text": "So build treatment-naive prediction models and trial them for decision support?\nNot a good idea\n\nbaking a cake without a recipe\nhoping it turns into something nice\nnot pleasant to people that need to taste result of the experiment\n\n(i.e. patients may have side-effects / die)"
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#we-should-build-models-that-are-likely-to-be-valuable-for-decision-making",
    "href": "talks/240530-weon-masterclass/index.html#we-should-build-models-that-are-likely-to-be-valuable-for-decision-making",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "We should build models that are likely to be valuable for decision making",
    "text": "We should build models that are likely to be valuable for decision making\n\nBuild models that predict expected outcomes under hypothetical interventions (prediction-under-intervention models)\ndoctor / patient can pick the treatment with best expected outcomes, depending on patient’s values\nwhereas treatment-naive prediction models average out over the historic treatment policy, prediction-under-intervention allows the user to select a treatment option\n\n\n\n\n\nHilden and Habbema on prognosis (Hilden and Habbema 1987)\n\n\n“Prognosis cannot be divorced from contemplated medical action, nor from action to be taken by the patient in response to prognostication.”\n\n\n\n\nprediction-under-intervention is not a new idea, but language and methods on causality have come a long way since (Hilden and Habbema 1987)."
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#estimand-for-prediction-under-intervention-models",
    "href": "talks/240530-weon-masterclass/index.html#estimand-for-prediction-under-intervention-models",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "Estimand for prediction-under-intervention models",
    "text": "Estimand for prediction-under-intervention models\nWhat is the estimand?\n\nprediction: \\(E[Y|X]\\)\ntreatment effect: \\(E[Y|\\text{do}(T=1)] - E[Y|\\text{do}(T=0)]\\)\nprediction-under-intervention: \\(E[Y|\\text{do}(T=t),X]\\)"
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#more-on-prediction-under-intervention-models",
    "href": "talks/240530-weon-masterclass/index.html#more-on-prediction-under-intervention-models",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "More on prediction-under-intervention models",
    "text": "More on prediction-under-intervention models\ndevelopment:\n\nideally estimated from RCTs, but these are often too small or don’t measure the right data\nalternatively can use observational data and causal inference methods\n\nthis approach relies on strong assumptions especially regarding confounding\n\nbut likely a better recipe than treatment-naive models\n\n\nevaluation:\n\nprediction accuracy can be tested in RCTs, or in observational data with specialized methods accounting for confounding (e.g. Keogh and Van Geloven 2024)\na new policy can be evaluated in historic RCTs (e.g. Karmali et al. 2018)\nultimate test is cluster RCT"
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#take-aways",
    "href": "talks/240530-weon-masterclass/index.html#take-aways",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "Take-aways",
    "text": "Take-aways\n\nwhen developing or evaluating (AI) prediction models for medical decisions, think about\n\nwhat is the effect of using this model on medical decisions?\nwhat is the effect of this policy change on patient outcomes?\n\ndeploying models for decision support is an intervention and should be evaluated as such\nprediction-under-intervention models have a foreseeable effect on patient oucomes when used for decision making\n\n\n\n\n\n\n\n\n\nFrom algorithms to action: improving patient care requires causality (amsterdamAlgorithmsActionImproving2024?)\n\n\n\n\n\n\nWhen accurate prediction models yield harmful sel-fulfilling prophecies (vanamsterdamWhenAccuratePrediction2024a?)"
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#new-summerschool-introduction-to-causal-inference-and-causal-data-science",
    "href": "talks/240530-weon-masterclass/index.html#new-summerschool-introduction-to-causal-inference-and-causal-data-science",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "New summerschool: Introduction to Causal Inference and Causal Data Science",
    "text": "New summerschool: Introduction to Causal Inference and Causal Data Science\nLearn more about causal data science\n\n\n\nDates: 5 Aug. - 9 Aug. 2024\nLocation: Utrecht\nInstructors:\n\nOisin Ryan\nBas Penning-de Vries\nWouter van Amsterdam\n\nSign up still possible\n\n\n\nCourse website"
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#references",
    "href": "talks/240530-weon-masterclass/index.html#references",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "References",
    "text": "References\n\n\n\n\nCooper, Gregory F., Constantin F. Aliferis, Richard Ambrosino, John Aronis, Bruce G. Buchanan, Richard Caruana, Michael J. Fine, et al. 1997. “An Evaluation of Machine-Learning Methods for Predicting Pneumonia Mortality.” Artificial Intelligence in Medicine 9 (2): 107–38. https://doi.org/10.1016/S0933-3657(96)00367-3.\n\n\nHilden, Jørgen, and J. Dik F. Habbema. 1987. “Prognosis in Medicine: An Analysis of Its Meaning and Rôles.” Theoretical Medicine 8 (3): 349–65. https://doi.org/10.1007/BF00489469.\n\n\nKarmali, Kunal N., Donald M. Lloyd-Jones, Joep van der Leeuw, David C. Goff Jr, Salim Yusuf, Alberto Zanchetti, Paul Glasziou, et al. 2018. “Blood Pressure-Lowering Treatment Strategies Based on Cardiovascular Risk Versus Blood Pressure: A Meta-Analysis of Individual Participant Data.” PLOS Medicine 15 (3): e1002538. https://doi.org/10.1371/journal.pmed.1002538.\n\n\nKeogh, Ruth H., and Nan Van Geloven. 2024. “Prediction Under Interventions: Evaluation of Counterfactual Performance Using Longitudinal Observational Data.” Epidemiology (Cambridge, Mass.) 35 (3): 329–39. https://doi.org/10.1097/EDE.0000000000001713."
  },
  {
    "objectID": "talks/241125-ccm-methodsmeeting/index.html#motivation",
    "href": "talks/241125-ccm-methodsmeeting/index.html#motivation",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Motivation",
    "text": "Motivation\n\n\nclinicians use prediction models for medical decisions, e.g.\n\nmaking a diagnosis\nestimating a patients prognosis\ntriaging\ntreatment decisions\n\nthese prediction models need reliable performance\nissue: potential substantive difference between last evaluation and current use"
  },
  {
    "objectID": "talks/241125-ccm-methodsmeeting/index.html#change-in-setting",
    "href": "talks/241125-ccm-methodsmeeting/index.html#change-in-setting",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Change in setting",
    "text": "Change in setting\nWhat can we expect from the model’s performance (if anything) in the new setting?\n\n\n\n\n\n\nmodel trained / evaluated in tertiary care hospital\n\n\n\n\n\n\n\nmodel used in GP setting"
  },
  {
    "objectID": "talks/241125-ccm-methodsmeeting/index.html#this-paper-talk",
    "href": "talks/241125-ccm-methodsmeeting/index.html#this-paper-talk",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "This paper / talk",
    "text": "This paper / talk\n\nrecap performance: discrimination, calibration\nlook at the causal direction of the prediction:\n\nare we predicting an effect based on its causes (e.g. heart attack, based on cholesterol and age)\nare we predicting a cause based on its effects (infer presence of CVA based on neurological symptoms)\n\ndefine shift in case-mix as a change in the marginal distribution of the cause variable\nconclude that in theory:\n\nfor prognosis models: expect stable calibration, not discrimination\nfor diagnosis models: expect stable discrimination, not calibration\n\nillustrate with simulation\nevaluate on 2030+ prediction model evaluations"
  },
  {
    "objectID": "talks/241125-ccm-methodsmeeting/index.html#discrimination-sensitivity-specificity-auc",
    "href": "talks/241125-ccm-methodsmeeting/index.html#discrimination-sensitivity-specificity-auc",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Discrimination: sensitivity, specificity, AUC",
    "text": "Discrimination: sensitivity, specificity, AUC\n\nprediction model \\(f: X \\to [0,1]\\) (i.e. predicted probability, e.g. logistic regression)\ntake a threshold \\(\\tau\\), such that \\(f(x) &gt; \\tau\\) is a positive prediction\ntabulate predictions vs outcomes\n\n\n\n\n\n\n\noutcome\n\n\n\n\n\n\n\n1\n0\n\n\nprediction\n1\ntrue positives\nfalse positives\n\n\n\n0\nfalse negatives\ntrue negatives"
  },
  {
    "objectID": "talks/241125-ccm-methodsmeeting/index.html#discrimination-sensitivity-specificity",
    "href": "talks/241125-ccm-methodsmeeting/index.html#discrimination-sensitivity-specificity",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Discrimination: sensitivity, specificity",
    "text": "Discrimination: sensitivity, specificity\n\n\n\n\n\n\n\n\n\n\n\n\noutcome\n\n\n\n\n\n\n\n1\n0\n\n\nprediction\n1\ntrue positives\nfalse positives\n\n\n\n0\nfalse negatives\ntrue negatives\n\n\n\n\nsensitivity: TP / (TP+FN)\nspecificity: TN / (TN+FP)\n\n\n\n\n\nsensitivity: \\(P(X=1 | Y=1)\\), specificity: \\(P(X=0 | Y=0)\\)\nnote: sensitivity only requires data from the column of postive cases (i.e. \\(Y=1\\)), and specificity on negatives\nevent-rate: fraction of \\(Y=1\\) of total cases\nin theory discrimination is event-rate independent (Hond 2023)"
  },
  {
    "objectID": "talks/241125-ccm-methodsmeeting/index.html#discrimination-roc-curve-and-auc",
    "href": "talks/241125-ccm-methodsmeeting/index.html#discrimination-roc-curve-and-auc",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Discrimination: ROC curve and AUC",
    "text": "Discrimination: ROC curve and AUC\nif we vary the threshold \\(0 \\leq \\tau \\leq 1\\), we get a ROC curve, and the AUC is the area under this curve"
  },
  {
    "objectID": "talks/241125-ccm-methodsmeeting/index.html#calibration",
    "href": "talks/241125-ccm-methodsmeeting/index.html#calibration",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Calibration",
    "text": "Calibration\n“A model is said to be well calibrated if for every 100 patients given a risk of x%, close to x have the event.” (Van Calster and Vickers 2015)\n\n\n\n\n\n\npopulation\n\n\n\n\n\n\n\nsubgroup where \\(f(x)=10\\)%\n\n\n\n\n\n\n\nevent rate in said subgroup is 10%: \\(p(Y=1|f(x)=10\\%) = 10\\%\\)"
  },
  {
    "objectID": "talks/241125-ccm-methodsmeeting/index.html#calibration-plot",
    "href": "talks/241125-ccm-methodsmeeting/index.html#calibration-plot",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Calibration plot",
    "text": "Calibration plot\n\n\n\n\\(p(Y=1|X)\\) versus \\(f(x)\\)\n\n\n\ncalibration\n\n\n\n\n\n\ncalibration-plot"
  },
  {
    "objectID": "talks/241125-ccm-methodsmeeting/index.html#performance-metrics-summary",
    "href": "talks/241125-ccm-methodsmeeting/index.html#performance-metrics-summary",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Performance metrics summary",
    "text": "Performance metrics summary\n\ndiscrimination: function of \\(P(X|Y)\\) (features given outcome)\ncalibration: function of \\(P(Y|X)\\) (outcome given features)"
  },
  {
    "objectID": "talks/241125-ccm-methodsmeeting/index.html#where-does-the-association-come-from",
    "href": "talks/241125-ccm-methodsmeeting/index.html#where-does-the-association-come-from",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Where does the association come from?",
    "text": "Where does the association come from?\nIn prediction, we have features \\(X\\) and outcome \\(Y\\) and model \\(Y|X\\)\n1. \\(X\\) causes \\(Y\\): often in prognosis (\\(Y\\): heart-attack, \\(X\\): cholesterol and age)\n2. \\(Y\\) causes \\(X\\): often in diagnosis (CVA, based on neurological symptoms)\n3. \\(Z\\) causes both \\(X\\) and \\(Y\\): confounding (yellow fingers predict lung cancer)"
  },
  {
    "objectID": "talks/241125-ccm-methodsmeeting/index.html#defining-a-shift-in-case-mix",
    "href": "talks/241125-ccm-methodsmeeting/index.html#defining-a-shift-in-case-mix",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Defining a shift in case-mix",
    "text": "Defining a shift in case-mix\nDefine a shift in case-mix a change in the marginal distribution of the cause variable, e.g.\n\nfilter on risk factors (pregancies with type 1 diabetes in hospital)\nfilter on outcome risk (send patients with neurological symptoms to CVA center)\ndenote environment as variable \\(E\\):"
  },
  {
    "objectID": "talks/241125-ccm-methodsmeeting/index.html#what-does-this-definition-imply",
    "href": "talks/241125-ccm-methodsmeeting/index.html#what-does-this-definition-imply",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "What does this definition imply?",
    "text": "What does this definition imply?\n\n\n\n\n\n\n\n\\(P(Y|X,E) = P(Y|X)\\)\n\nin words: \\(P(Y|X)\\) is transportable across environments\nbecause there is no arrow from \\(E\\) to \\(Y\\), \\(X\\) blocks effect of \\(E\\) on \\(Y\\)\n\n\\(P(X|Y,E) \\neq P(X|Y)\\)\n\nin words: \\(P(X|Y)\\) is not transportable across environments\n\nimplication for causal (prognosis) prediction:\n\ncalibration is functional of \\(P(Y|X)\\), thus stable\ndiscrimination is functional of \\(P(X|Y)\\), thus not stable\n\nfor anti-causal (diagnosis) prediction: the reverse\nmain result: discrimination or calibration may be preserved under changes in case-mix, but never both"
  },
  {
    "objectID": "talks/241125-ccm-methodsmeeting/index.html#why-define-a-shift-in-case-mix-this-way",
    "href": "talks/241125-ccm-methodsmeeting/index.html#why-define-a-shift-in-case-mix-this-way",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Why define a shift in case-mix this way?",
    "text": "Why define a shift in case-mix this way?\n\ncause is temporally prior to effect, filtering at least on cause may be likely in many settings\nfiltering on both: anything goes, cannot say anything about expected performance based on graphical information"
  },
  {
    "objectID": "talks/241125-ccm-methodsmeeting/index.html#simulation-setup",
    "href": "talks/241125-ccm-methodsmeeting/index.html#simulation-setup",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Simulation setup",
    "text": "Simulation setup\n\\[\\begin{align*}\n    \\label{eq:dgm-prognosis}\n    \\text{prognosis:} &                     & \\text{diagnosis:} & \\\\\n    P_y &\\sim \\text{Beta}(\\alpha_e,\\beta_e) & y &\\sim \\text{Bernouli}(P_e) \\\\\n    x   &= \\text{logit}(P_y)                 & x &\\sim N(y, 1) \\\\\n    y   &\\sim \\text{Bernoulli}(P_y)         &   &\n\\end{align*}\\]"
  },
  {
    "objectID": "talks/241125-ccm-methodsmeeting/index.html#empirical-validation",
    "href": "talks/241125-ccm-methodsmeeting/index.html#empirical-validation",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Empirical validation",
    "text": "Empirical validation\n\na study of 2030+ evaluations of 1300+ prediction models (Wessler et al. 2021)\n\n\n\nregistry: all data available with only 4000 clicks\nsolution: scrape the website"
  },
  {
    "objectID": "talks/241125-ccm-methodsmeeting/index.html#results",
    "href": "talks/241125-ccm-methodsmeeting/index.html#results",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Results",
    "text": "Results\n\nfor each study, extract AUC on internal validation and for each external validation (no calibration data available)\ncalculate scaled deviation from internal AUC (\\(\\delta\\))\ntheory implies:\n\nfor prognosis models: \\(\\delta \\neq 0\\)\nfor diagnostic models: \\(\\delta=0\\)\n\ntest: variance of \\(\\delta\\) between evaluations of diagnostic or prognostic models (F-test)\nresult: \\(\\text{VAR}(\\delta_{\\text{diagnostic}})=0.019 \\approx 0.122 * \\text{VAR}(\\delta_{\\text{prognostic}})\\), p-value\\(&lt;0.001\\)"
  },
  {
    "objectID": "talks/241125-ccm-methodsmeeting/index.html#conclusion",
    "href": "talks/241125-ccm-methodsmeeting/index.html#conclusion",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Conclusion",
    "text": "Conclusion\n\ndiscrimination: a function of features given outcome\ncalibration: a function of outcome given outcome\nare we predicting an effect based on its causes (e.g. heart attack, based on cholesterol and age)\nare we predicting a cause based on its effects (infer presence of CVA based on neurological symptoms)\ndefine shift in case-mix as a change in the marginal distribution of the cause variable\nconclude that in theory:\n\nfor prognosis models: expect stable calibration, not discrimination\nfor diagnosis models: expect stable discrimination, not calibration\n\nillustrated with simulation, evaluated on 2030+ prediction model evaluations, one direction of theory seems confirmed\nfuture work: more empirical validations"
  },
  {
    "objectID": "talks/241125-ccm-methodsmeeting/index.html#questions",
    "href": "talks/241125-ccm-methodsmeeting/index.html#questions",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Questions:",
    "text": "Questions:\n\nhow does this align with what you observed?\nwhere to publish this work?"
  },
  {
    "objectID": "talks/241125-ccm-methodsmeeting/index.html#references",
    "href": "talks/241125-ccm-methodsmeeting/index.html#references",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "References",
    "text": "References\n\n\n\n\nHond, A. A. H. de. 2023. “From Code to Clinic: Theory and Practice for Artificial Intelligence Prediction Algorithms.” Leiden University. https://hdl.handle.net/1887/3643729.\n\n\nVan Calster, Ben, and Andrew J. Vickers. 2015. “Calibration of Risk Prediction Models: Impact on Decision-Analytic Performance.” Medical Decision Making 35 (2): 162–69. https://doi.org/10.1177/0272989X14547233.\n\n\nWessler, Benjamin S., Jason Nelson, Jinny G. Park, Hannah McGinnes, Gaurav Gulati, Riley Brazil, Ben Van Calster, et al. 2021. “External Validations of Cardiovascular Clinical Prediction Models: A Large-Scale Review of the Literature.” Circulation: Cardiovascular Quality and Outcomes 14 (8): e007858. https://doi.org/10.1161/CIRCOUTCOMES.121.007858."
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Posts",
    "section": "",
    "text": "Flipping the sign of hazard ratios\n\n\n\nr\n\nsurvival analysis\n\ncausal inference\n\n\n\n\n\n\n\n\n\nJul 4, 2025\n\n\nWouter van Amsterdam\n\n\n\n\n\n\n\n\n\n\n\n\nWhat is stronger evidence of prediction model robustness?\n\n\n\nstatistics\n\nprediction\n\ncausal inference\n\n\n\n\n\n\n\n\n\nApr 25, 2025\n\n\nWouter van Amsterdam\n\n\n\n\n\n\n\n\n\n\n\n\nIs the JAMA opening up their language for causal effects?\n\n\n\ncausal inference\n\n\n\n\n\n\n\n\n\nJun 7, 2024\n\n\nWouter van Amsterdam\n\n\n\n\n\n\n\n\n\n\n\n\nPartial residual plots with multiply imputed data\n\n\n\nr\n\nlinear regression\n\ndata visualization\n\n\n\n\n\n\n\n\n\nMar 22, 2024\n\n\nWouter van Amsterdam\n\n\n\n\n\n\n\n\n\n\n\n\nThe need for speed, performing simulation studies in R, JAX and Julia\n\n\n\nr\n\njulia\n\njax\n\npython\n\nsimulation studies\n\n\n\n\n\n\n\n\n\nMar 8, 2024\n\n\nWouter van Amsterdam\n\n\n\n\n\n\n\n\n\n\n\n\nThe difference between intervention and counterfactuals\n\n\n\ncausal inference\n\nstatistics\n\n\n\n\n\n\n\n\n\nJul 25, 2021\n\n\nWouter van Amsterdam\n\n\n\n\n\n\n\n\n\n\n\n\nWhen good predictions lead to bad decisions\n\n\n\ncausal inference\n\npredictions\n\n\n\n\n\n\n\n\n\nJul 20, 2021\n\n\nWouter van Amsterdam\n\n\n\n\n\n\n\n\n\n\n\n\nFinding the functional form for multiple linear regression\n\n\n\nstatistics\n\nsimulations\n\nlinear regression\n\n\n\n\n\n\n\n\n\nAug 16, 2019\n\n\nWouter van Amsterdam\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/210725-counterfactualvsinterventional.html",
    "href": "posts/210725-counterfactualvsinterventional.html",
    "title": "The difference between intervention and counterfactuals",
    "section": "",
    "text": "Sometimes there is confusion about the difference between counterfactual predictions and interventional predictions. According to the ladder of causation introduced by Pearl and presented in the ‘Book of Why’, interventional is rung 2 and counterfactuals are rung 3 (associations are rung 1). Models that predict the treatment effect for a new patient based on some covariates \\(X\\) require interventional models, not counterfactual. The difference between interventional and counterfactual models is relevant as counterfactual models require more assumptions, they require knowledge of the structural mechanisms. In words, the interventional question is “What is the expected outcome under treatment \\(t\\) given that we know \\(X\\)”, or “What is the expected difference in outcomes between treatment \\(t\\) and \\(t'\\) given that we know \\(X\\)”. The counterfactual question is “What would have been the outcome if we had given treatment \\(t'\\) given that we gave \\(t\\) and observed outcome \\(y\\)”."
  },
  {
    "objectID": "posts/210725-counterfactualvsinterventional.html#intro",
    "href": "posts/210725-counterfactualvsinterventional.html#intro",
    "title": "The difference between intervention and counterfactuals",
    "section": "",
    "text": "Sometimes there is confusion about the difference between counterfactual predictions and interventional predictions. According to the ladder of causation introduced by Pearl and presented in the ‘Book of Why’, interventional is rung 2 and counterfactuals are rung 3 (associations are rung 1). Models that predict the treatment effect for a new patient based on some covariates \\(X\\) require interventional models, not counterfactual. The difference between interventional and counterfactual models is relevant as counterfactual models require more assumptions, they require knowledge of the structural mechanisms. In words, the interventional question is “What is the expected outcome under treatment \\(t\\) given that we know \\(X\\)”, or “What is the expected difference in outcomes between treatment \\(t\\) and \\(t'\\) given that we know \\(X\\)”. The counterfactual question is “What would have been the outcome if we had given treatment \\(t'\\) given that we gave \\(t\\) and observed outcome \\(y\\)”."
  },
  {
    "objectID": "posts/210725-counterfactualvsinterventional.html#example",
    "href": "posts/210725-counterfactualvsinterventional.html#example",
    "title": "The difference between intervention and counterfactuals",
    "section": "Example",
    "text": "Example\nTo illustrate the difference between a counterfactual prediction and an interventional prediction (or conditional average treatment effect estimates), consider this very simple setup.\nYou have data from a randomized trial with two treatment arms \\(t \\in \\{0,1\\}\\) and an outcome \\(Y\\) on a continuous scale. Denote \\(Y_0\\) the potential outcome under intervening on treatment \\(t=0\\) and \\(Y_1\\) the potential outcome under intervening on treatment \\(t=1\\). As we are dealing with data from a randomized trial, we can easily estimate the average treatment effect as \\(E[Y_1 - Y_0] = E[Y|t=0] - E[Y|t=1]\\), assuming consistency (ignorability and overlap are satisfied due to the study design).\nA counterfactual question is: what would have been the outcome \\(Y_0\\) under treatment \\(t=1\\), given that we observed the outcome \\(y_1\\) under treamtent \\(t=1\\), so it is \\(E[Y_0|Y=y_1, t=1]\\).\nNow assume that the data come from a mixture of Gaussians such that\n\\[y|t \\sim (1 - t) \\mathcal{N}(1,0.1^2) + t \\mathcal{N}(10,2.5^2)\\]\nAnd \\(p(t=1)=0.5\\) so both arms are equally large. Treatment \\(t=1\\) leads to higher outcome but also more spread. The relevant interventional expectations are easily calculated by just calculating group means \\(E[Y_0] = E[Y|t=0] = 1\\), \\(E[Y_1] = E[Y|t=1] = 10\\).\n\nCalculating the counterfactuals\nTo see that calculating counterfactuals requires more knowledge, namely of the structural equations, we now calculate the counterfactual prediction for a patient with \\(Y=Y_1=15\\). This is a patient with a relatively large ‘residual’, the outcome is 2 standard deviations above the mean for treatment group \\(t=1\\).\nFirst we calculate the counterfactual outcome under a wrong outcome model. Researchers tried to model the outcomes using linear regression, and failed to appreciate the difference in variances between the two treatment arms (heteroscedasticity). Assuming a large sample, they will arrive at a model:\n\\[\\hat{y}_{\\text{wrong}} = 1 + t * 9 + \\mathcal{N}(0,\\sigma^2)\\]\nWhere \\(\\sigma = \\sqrt{\\frac{0.1^2 + 2.5^2}{2}} \\approx 1.77\\) (standard devation of mixture of Gaussians with (conditional) mean of 0 and standard deviations 0.1 and 2.5, with 50 / 50 mixing). Note that the estimate of the treatment effect is correct, and so are \\(E[Y_0]\\) and \\(E[Y_1]\\). If there was a binary pre-treatment covariate, the conditional average treatment effect could be estimated by repeating this exercise for both levels of the covariate. To calculate the counterfactual outcome of our patient, we first need to determine the value of their noise variable for the outcome. According to \\(\\hat{y}_{\\text{wrong}}\\), the residual for a patient with \\(Y_1=15\\) is \\(5\\), which is \\(5/\\sigma \\approx 2.82\\) standard deviations away from the expected value for \\(t=1\\). Given this residual we can now calculate the counterfactual:\n\\[\\widehat{E_{\\text{wrong}}}[Y_0|Y=15,t=1] \\approx E[Y_0] + 2.82 \\sigma =6\\]\nGiven that we know the data generating mechanism, we know that this counterfactual prediction is 50 standard deviations from the conditional mean of \\(t=0\\) in the data generating mechanism, clearly this counterfactual prediction is wrong.\nIf we did model the data correctly with a mixture of Gaussians indexed by the treatment group, we would instead say that \\(Y_1=15\\) is 2 standard deviations above the conditional mean, and we would calculate:\n\\[\\widehat{E^*}[Y_0|Y=15,t=1] = E[Y_0] + 2 * 0.1 =1.2\\]\nWhich is correct."
  },
  {
    "objectID": "posts/210725-counterfactualvsinterventional.html#conclusion",
    "href": "posts/210725-counterfactualvsinterventional.html#conclusion",
    "title": "The difference between intervention and counterfactuals",
    "section": "Conclusion",
    "text": "Conclusion\nTo calculate counterfactual predictions, you need to correctly specify the structural equations. For treatment recommendations for future patients, these are not needed, interventional estimates (conditional average treatment effect) are sufficient, and obviously the factual outcome is not observed yet so it is impossible to calculate counterfactuals (the factual is not yet known).\nPost-script: for ‘real’ patient counsellling the expected values under the treatments would generally not suffice, some measure of spread / uncertainty would be required. Ideally, one would learn the distribution of the potential outcomes."
  },
  {
    "objectID": "posts/250704-hr-sign-flip.html",
    "href": "posts/250704-hr-sign-flip.html",
    "title": "Flipping the sign of hazard ratios",
    "section": "",
    "text": "Hazard ratios are problematic summary measures for survival analysis (Dumas and Stensrud 2025; Post, Van Den Heuvel, and Putter 2024; Stensrud et al. 2019; Aalen, Cook, and Røysland 2015); even in well-conducted randomized trials, hazard ratios fail to capture a measure of causal effect, unless we make the (ludicrous) assumption that in the control group, every individual has the exact same hazard function.\nDumas and Stensrud recently summarized three main problems with hazard ratios (Dumas and Stensrud 2025): built-in selection bias, non-collapsibility, and violations of the proportional hazards assumption."
  },
  {
    "objectID": "posts/250704-hr-sign-flip.html#non-collapsibility",
    "href": "posts/250704-hr-sign-flip.html#non-collapsibility",
    "title": "Flipping the sign of hazard ratios",
    "section": "Non-collapsibility",
    "text": "Non-collapsibility\nSay we have two subgroups defined by a feature \\(X\\), for example, men and women. Let’s assume that some measure of causal effect (e.g. a hazard ratio, odds ratio, risk difference or risk ratio) is \\(1.4\\) in the first subgroup and \\(1.8\\) in the second subgroup, what is then the measure of effect in the combined population? Intuitively, we would want this to be somewhere in between \\(1.4\\) and \\(1.8\\), meaning some (potentially weighted) average of the two subgroup effects. This is only true for measures of effect that are collapsible, such as risk difference or risk ratio. The hazard ratio and odds ratio are not collapsible, which means that the effect in the combined population can be below \\(1.4\\) or above \\(1.8\\).\nAn important question is: say the hazard ratio is above (or below) 1 in both subgroups, can it ever be below (or above) 1 in the combined population?\nIt turns out that, yes, it can, as shown below in a simulation adapted from Post (Post, Van Den Heuvel, and Putter 2024)."
  },
  {
    "objectID": "posts/250704-hr-sign-flip.html#simulation",
    "href": "posts/250704-hr-sign-flip.html#simulation",
    "title": "Flipping the sign of hazard ratios",
    "section": "Simulation",
    "text": "Simulation\nWe’ll simulate 1000000 observations of a hypothetical two-arm randomized trial, with a feature \\(X\\) that follows a compound Poisson-Gamma distribution, a baseline hazard function quadratic in time, and a treatment effect that is multiplicative on the baseline hazard.\nThe treatment effect is constant and the same for all values of \\(X\\), meaning that there is heterogeneity in the hazard of the control group depending on \\(X\\), but the causal hazard ratio (as defined in Post (Post, Van Den Heuvel, and Putter 2024)) is constant across all values of \\(X\\). In practice, the hazard ratio estimated in trials is the Survivor Marginalized Causal Hazard Ratio, meaning that it is estimated from the patients who are still alive at a given time point, which is not the same as the causal hazard ratio.\nThe example that Post provides shows that the (time-varying) Survivor Marginalized Causal Hazard Ratio can start above 1, but over time drop below 1 because of the depletion of susceptibles in one trial arm (i.e. the hazard ratio’s built-in selection bias).\n\n# simulate from compound poisson\nlibrary(data.table)\nlibrary(survival)\n\nn = 1e6\n\nsimulate_cp_gamma &lt;- function(rho, eta, nu, n = 1) {\n  # Simulate n independent draws from CPoi(rho, eta, nu)\n  replicate(n, {\n    N &lt;- rpois(1, rho)\n    if (N == 0) {\n      return(0)\n    } else {\n      sum(rgamma(N, shape = eta, scale = nu))\n    }\n  })\n}\n\nset.seed(421)\n\n# Parameters\ntheta0 = 2 # variance\nrho &lt;- 3/theta0    # Poisson rate (theta0)\neta &lt;- .5     # Gamma shape\nnu  &lt;- theta0 * 2 /3     # Gamma scale\n\n# Simulate 10000 values\nsamples &lt;- simulate_cp_gamma(rho, eta, nu, n = 10000)\n\n# Empirical mean and variance\nemp_mean &lt;- mean(samples)\nemp_var  &lt;- var(samples)\n\n# Theoretical mean and variance\ntheo_mean &lt;- rho * eta * nu\ntheo_var  &lt;- rho * eta * nu^2 * (1 + eta)\n\n# cat(\"Empirical mean:\", emp_mean, \"\\n\")\n# cat(\"Theoretical mean:\", theo_mean, \"\\n\")\n# cat(\"Empirical variance:\", emp_var, \"\\n\")\n# cat(\"Theoretical variance:\", theo_var, \"\\n\")\n\n# Histogram\nhist(samples, breaks = 50, col = \"skyblue\", main = \"Compound Poisson-Gamma Samples\", xlab = \"X\")\n\n\n\n\n\n\n\n\nWe now define the hazard and cumulative hazard functions used for the simulation.\n\n# add baseline hazard\nl0_t &lt;- function(t) (t^2) / 20\n# treatment effect \nmu = 3\n# hazard function\n\nl0 = function(t, a) {\n  l0_t(t) * mu^a\n}\n\n# cumulative hazard function\nL0 = function(t, a, x) {\n  x * ((t^3) / 60) * mu^a\n}\n\n# inverse of cum hazard fn\nL0_inv &lt;- function(u, a, x) {\n  # Solve for t in L0(t, a, x) = u\n  # u = x * ((t^3) / 60) * mu^a\n  # Rearranging gives t = (60 * u / (x * mu^a))^(1/3)\n  (60 * u / (x * mu^a))^(1/3)\n}\n\n# setup data table\ndf &lt;- data.table(x=samples, a=rep(c(0,1), each=n/2))\n# simulate u\ndf[, u := runif(.N)]\n# find the survival time\ndf[, time := L0_inv(-log(u), a, x)]\n# censor at maxtime\nmaxtime &lt;- 20\ndf[, event:= time&lt;= maxtime]\ndf[time&gt;maxtime, `:=`(time=maxtime, event=0)]\n# plot survfit per a with colors\nsf &lt;- survfit(Surv(time,event)~a, data=df)\nplot(sf, col=1:2)\nlegend(\"topright\", legend=c(\"a=0\", \"a=1\"), col=1:2, lty=1)\n\n\n\n\n\n\n\n# fit cox model\ncox_model &lt;- coxph(Surv(time,event)~a, data=df)\nprint(summary(cox_model))\n\nCall:\ncoxph(formula = Surv(time, event) ~ a, data = df)\n\n  n= 1000000, number of events= 757625 \n\n    coef exp(coef) se(coef)  z Pr(&gt;|z|)    \na 0.2231    1.2500   0.0023 97   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n  exp(coef) exp(-coef) lower .95 upper .95\na      1.25        0.8     1.244     1.256\n\nConcordance= 0.549  (se = 0 )\nLikelihood ratio test= 9394  on 1 df,   p=&lt;2e-16\nWald test            = 9409  on 1 df,   p=&lt;2e-16\nScore (logrank) test = 9447  on 1 df,   p=&lt;2e-16\n\n\n\nSign-flip over time\nThe marginal cox model estimate has the correct sign for the treatment effect, but we will see that over time the hazard ratio changes sign\n\n## check time-varying hazard\nzph &lt;- cox.zph(cox_model)\nplot(zph, var = \"a\")  # Plots log(HR) over time with smoothing\nabline(h = 0, col = \"red\", lty = 2)  # Add a horizontal line at 0 for reference\n\n\n\n\n\n\n\n\n\n\nMarginal sign-flip with Delayed Entry\nCan this ever mean we estimate a marginal hazard ratio of the wrong sign in an RCT? It is possible in the context of delayed entry. Delayed entry means that some patients enter the study at a later time point. An example would be if we randomize patients to a certain treatment from \\(t=0\\), but are only able to include their information after some (random) lead time. For example, if we randomize regions in a country to add chloride to the drinking water at a fixed time point \\(t=0\\) (like in Tofail et al. 2018), but for logistical reasons, we can only start collecting follow-up data on individuals in those regions in a staggered fashion, with some regions starting data collection at \\(t=0\\), some at \\(t=1\\), and so on.\nBecause the hazard ratio changes sign over time, if we include patients who enter the study at a later time point, we can end up with a hazard ratio that is below 1, even though the causal hazard ratio is above 1 for all patients at all time points.\n\n# fit model with delayed entry\ndf[, entry_time:=runif(.N, 0, maxtime)]\ncox_model_delayed &lt;- coxph(Surv(entry_time, time, event) ~ a, data = df[time&gt;entry_time])\nsummary(cox_model_delayed)\n\nCall:\ncoxph(formula = Surv(entry_time, time, event) ~ a, data = df[time &gt; \n    entry_time])\n\n  n= 393157, number of events= 150782 \n\n      coef exp(coef) se(coef)      z Pr(&gt;|z|)    \na -0.08297   0.92037  0.00521 -15.93   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n  exp(coef) exp(-coef) lower .95 upper .95\na    0.9204      1.087     0.911    0.9298\n\nConcordance= 0.524  (se = 0.001 )\nLikelihood ratio test= 254.6  on 1 df,   p=&lt;2e-16\nWald test            = 253.7  on 1 df,   p=&lt;2e-16\nScore (logrank) test = 253.8  on 1 df,   p=&lt;2e-16"
  },
  {
    "objectID": "posts/250704-hr-sign-flip.html#conclusion",
    "href": "posts/250704-hr-sign-flip.html#conclusion",
    "title": "Flipping the sign of hazard ratios",
    "section": "Conclusion",
    "text": "Conclusion\nCan the marginal hazard ratio estimated in a randomized controlled trial have the wrong sign? Yes, it can—even when the causal hazard ratio is constant—if we allow for delayed entry. Is this likely to happen in practice? Probably not. But that doesn’t mean we should continue using the hazard ratio as a default summary measure. Better alternatives exist that can be directly derived from survival curves, such as absolute risk differences, risk ratios, and differences in restricted mean survival time."
  },
  {
    "objectID": "posts/190816-lm-functional-form.html",
    "href": "posts/190816-lm-functional-form.html",
    "title": "Finding the functional form for multiple linear regression",
    "section": "",
    "text": "A frequent question that comes up when modeling continuous outcomes with multiple linear regression is what the correct functional form for the relationship between the independent variables is. TLDR: the answer is a partial residual plot. Here I will generate some data to illustrate this"
  },
  {
    "objectID": "posts/190816-lm-functional-form.html#functional-relationship-in-linear-regression",
    "href": "posts/190816-lm-functional-form.html#functional-relationship-in-linear-regression",
    "title": "Finding the functional form for multiple linear regression",
    "section": "",
    "text": "A frequent question that comes up when modeling continuous outcomes with multiple linear regression is what the correct functional form for the relationship between the independent variables is. TLDR: the answer is a partial residual plot. Here I will generate some data to illustrate this"
  },
  {
    "objectID": "posts/190816-lm-functional-form.html#data",
    "href": "posts/190816-lm-functional-form.html#data",
    "title": "Finding the functional form for multiple linear regression",
    "section": "Data",
    "text": "Data\n\nsuppressMessages({require(ggplot2); theme_set(theme_bw())})\nset.seed(12345)\nN = 1000\nx &lt;- runif(N, min = 0, max=2*pi)\nw &lt;- .5*x + sin(x) + rnorm(N, sd=.25)\nsy &lt;- rnorm(N, sd=.1)\ny &lt;- x + w + sy\ndf = data.frame(x,w,y)\n\nThe data consists of two real-valued ‘independent’ variables \\(x,w\\), where\n\\[\n\\begin{align}\nx &\\sim U(0, 2 \\pi) \\\\\n\\epsilon_w &\\sim N(0, 0.25) \\\\\n\\epsilon_y &\\sim N(0, 0.1) \\\\\nw &:= \\frac{x}{2} + \\sin(x) \\\\\ny &:= x + w + \\epsilon_y\n\\end{align}\n\\]\nClearly \\(y\\) is linear in both \\(x\\) and \\(w\\). A plot of the data:\n\nggplot(df, aes(x=x, y=w,col=y, size=y)) + \n  geom_point() + theme_minimal()\n\n\n\n\njoint distribution of x, w, y"
  },
  {
    "objectID": "posts/190816-lm-functional-form.html#plots",
    "href": "posts/190816-lm-functional-form.html#plots",
    "title": "Finding the functional form for multiple linear regression",
    "section": "Plots",
    "text": "Plots\n\nIncorrect: marginal association\nLet’s say we’re particularly interested in the relationship between \\(y\\) and \\(x\\), both conditional on \\(w\\). Looking at the marginal association between \\(y\\) and \\(x\\) with a scatterplot will set us on the wrong foot, because of the association between \\(x\\) and \\(w\\).\n\nggplot(df, aes(x=x,y=y)) + \n  geom_point()\n\n\n\n\nmarginal association between x and y\n\n\n\n\n\n\nCorrect: partial residual plot\nTo construct the correct plot, we can generate a partial residual plot, which is created with resid(lm(y~x+w))+b_x x ~ x.\nWhere b_x is the regression coefficient found through linear regression of \\(y\\) on \\(x\\) and \\(w\\). In a plot:\n\nlmfit &lt;- lm(y~x+w)\nyresid &lt;- resid(lmfit)\nb_x &lt;- coef(lmfit)['x']\nplotdata &lt;- data.frame(x, y=yresid + b_x * x)\n\nggplot(plotdata, aes(x=x,y=y)) + \n  geom_point() + \n  ylab(\"resid(lm(y~x+w)) + b_x x\")\n\n\n\n\n\n\n\nFigure 1: partial residual plot\n\n\n\n\n\n\n\nPartial residual plot when y is not linear in x\nWhat if \\(y\\) were not linear in \\(x\\)?\n\ny2 &lt;- x^2 + w + sy\nlmfit2 &lt;- lm(y2 ~ x + w)\nb_x2 &lt;- coef(lmfit2)['x']\nplotdata2 &lt;- data.frame(x, y=resid(lmfit2) + b_x2 * x)\n\nggplot(plotdata2, aes(x=x,y=y)) + \n  geom_point() + \n  ylab(\"resid(lm(y~x+w)) + b_x x\")\n\n\n\n\npartial residual plot when y not linear in x"
  },
  {
    "objectID": "posts/190816-lm-functional-form.html#conclusion",
    "href": "posts/190816-lm-functional-form.html#conclusion",
    "title": "Finding the functional form for multiple linear regression",
    "section": "Conclusion",
    "text": "Conclusion\nThe functional relationship between an outcome and a covariate in a linear regression conditional on other covariates is visualized with a partial residual plot, or:\n\nlmfit &lt;- lm(y~x+w)\nplot(resid(lmfit) + coef(lmfit)['x'] * x ~ x)"
  },
  {
    "objectID": "posts/240308-jaxopt-vs-r-vs-julia/index.html",
    "href": "posts/240308-jaxopt-vs-r-vs-julia/index.html",
    "title": "The need for speed, performing simulation studies in R, JAX and Julia",
    "section": "",
    "text": "Simulation experiments are important when evaluating methods but also for applied work in for example power analyses (e.g. Amsterdam, Harlianto, et al. 2022) or sensitivity analyses (e.g. Amsterdam, Verhoeff, et al. 2022). When using simulations to support scientific claims, the more experiments the better. Being able to perform simulation experiments faster allows researchers to:\nThe R language has been a popular language among many biostatisticians for a long time, but it is not generally considered the top performing language in terms of speed.  In recent years, JAX (developed by Google) and Julia have arisen as general scientific computation frameworks. JAX and Julia have grown in popularity both in the neural network community as in other scientific communities (e.g. “DifferentiableUniverseInitiative/Jax_cosmo” 2024; “SciML: Open Source Software for Scientific Machine Learning” n.d.). In this blog post I’ll compare R with JAX and Julia for a simple simulation study setup with logistic regression.\nWe’ll look at the following comparisons:"
  },
  {
    "objectID": "posts/240308-jaxopt-vs-r-vs-julia/index.html#jax-and-julia-vs-r-a-high-level-overview",
    "href": "posts/240308-jaxopt-vs-r-vs-julia/index.html#jax-and-julia-vs-r-a-high-level-overview",
    "title": "The need for speed, performing simulation studies in R, JAX and Julia",
    "section": "JAX and Julia vs R: a high level overview",
    "text": "JAX and Julia vs R: a high level overview\nJAX is a rising star in computer science and natural sciences. Without going in too much details, JAX works by translating python code into an intermediate language that can be run very efficiently on different hardware backends (CPU, GPU, TPU), possibly with just-in-time compilation (JIT). JAX prides itself on providing composable transformations for vectorization (vmap), paralellization (pmap) and automatic differentiation (grad), all compatible with jit. In R, most of the heavy lifting in terms of computation (such as fitting a logistic regression model) is implemented in high-speed languages such as C++ or Fortran. The usual R-code merely provides an interface to these languages and allows the user to feed in data and analyze results. Whereas using JAX and R means working with two languages (one language to write accessible code, another to do fast computation), Julia is a just-in-time compiled language where such translation is not needed."
  },
  {
    "objectID": "posts/240308-jaxopt-vs-r-vs-julia/index.html#the-basic-setup",
    "href": "posts/240308-jaxopt-vs-r-vs-julia/index.html#the-basic-setup",
    "title": "The need for speed, performing simulation studies in R, JAX and Julia",
    "section": "The basic setup",
    "text": "The basic setup\nWe’ll use a simple logistic regression simulation setup, where for each observation:\n\\[\n\\begin{align}\n\\mathbf{x}_{\\text{full}} &\\sim \\mathcal{N}(0,I) \\in \\mathbb{R}^{10} \\\\\ny &= ||\\mathbf{x}||_0 &gt; 0 \\\\\n\\mathbf{x}_{\\text{obs}} &= [x_0\\ x_i \\ldots x_9]\n\\end{align}\n\\]\nSo \\(y\\) is the sum of elements of \\(\\mathbf{x}_{\\text{full}}\\) and the observed \\(\\mathbf{x}_{\\text{obs}}\\) contains only the first 9 out of 10 elements of \\(\\mathbf{x}_{\\text{full}}\\).\nWe will model this data with logistic regression:\n\\[\n\\begin{align}\n    \\text{logit}(y) &= \\mathbf{x}_{\\text{obs}} \\boldsymbol{\\beta}'\\\\\n    y &\\sim \\text{Bernoulli} (\\sigma (\\mathbf{x}_{\\text{obs}} \\boldsymbol{\\beta}'))\n\\end{align}\n\\]\nwhere \\(\\boldsymbol{\\beta} = [\\beta_1,\\ldots,\\beta_9]\\) is a 9-dimensional parameter vector that is to be estimated (we’re excluding the usual intercept term). We’ll generate nrep independent datasets and estimate \\(\\boldsymbol{\\beta}\\) in each one, and finally calculate the average parameter estimates \\(\\frac{1}{\\text{nrep}}\\sum_{i=1}^{\\text{nrep}}\\boldsymbol{\\beta}^i\\).\n\nHardware\nThe hardware I had available for this comparison is:\n\nmacm1: 2020 macbook air M1, 8Gb RAM, 8 threads\nlinux: linux machine, 64Gb RAM, 12 threads (Intel(R) Xeon(R) W-2135 CPU @ 3.70GH )"
  },
  {
    "objectID": "posts/240308-jaxopt-vs-r-vs-julia/index.html#the-code",
    "href": "posts/240308-jaxopt-vs-r-vs-julia/index.html#the-code",
    "title": "The need for speed, performing simulation studies in R, JAX and Julia",
    "section": "The code",
    "text": "The code\n\nMaking data\nMaking the data is pretty similar in all cases, except that JAX requires an explicit random key.\n\nRPythonJulia\n\n\nmake_data &lt;- function(n=1e3L) {\n    x_vec = rnorm(n*10)\n    X_full = matrix(x_vec, ncol=10)\n    eta = rowSums(X_full)\n    y = eta &gt; 0\n    # return only first 9 column to have some noise\n    X = X_full[,1:9]\n    return(list(X=X,y=y))\n}\n\n\ndef make_data(k, n=int(1e3)):\n    X_full = random.normal(k, (n,10)) # JAX needs explicit keys for psuedo random number generation\n    eta = jnp.sum(X_full, axis=-1)\n    y = eta &gt; 0\n    # return only first 9 column to have some noise\n    X = X_full[:,:9]\n    return (X, y)\n\n\nfunction make_data(n::Integer=1000)\n    X_full = randn(n,10)\n    eta = vec(sum(X_full, dims=2))\n    y = eta .&gt; 0 # vectorized greater than 0 comparison\n    X = X_full[:,1:9]\n    return X, y\nend\n\n\n\n\n\nRun single experiment\nNow we’ll write the code for a single analysis step, generating data and fitting the logistic regression. For R and Julia we will use the glm function to estimate the logistic regression model. The Julia code looks much like the R code. As far as I know there is no equivalent glm function implemented in JAX. Instead, we need to specify an objective function and will use a general purpose optimizer. JaxOpt provides both binary_logreg as an objective function and LBFGS, a popular general purpose optimizer, which we’ll use here.\n\nRPythonJulia\n\n\nsolve &lt;- function(...) {\n  data = make_data()\n  fit = glm(data$y~data$X-1, family='binomial')\n  coefs = coef(fit)\n  return(coefs)\n}\n\n\n# initialize a generic solver with the correct objective function\nsolver = LBFGS(binary_logreg)\nw_init = jnp.zeros((9,))\n\n@jit # jit toggles just-in-time compilation, one of the main features of JAX\ndef solve(k):\n    data = make_data(k)\n    param, state = solver.run(w_init, data)\n    return param\n\n\nfunction solve(i::Int64=1)\n    X, y = make_data()\n    fit = glm(X, y, Bernoulli())\n    coefs = coef(fit)\n    return coefs\nend\n\n\n\n\n\nIterate over runs / settings\nFinally we run the experiments nrep times and calculate the average coefficient vector.\n\nJAX primitive: map versus vmap\nNote that in JAX there are multiple ways to do this, most notably map and vmap. Whereas map may offer speedups compared to R due to jit-compiliation, for most purposes vmap is recommended as it allows JAX to find ways of making the computation more efficient. For example, a vector-vector multiplication vectorized over an input of vectors is equivalent to a single matrix-vector multiplication. JAX’s intermediate language finds these possible optimizations and swaps in the more efficient approach. Vectorized code runs in parallel and can be much faster. Note that in our case, vectorization may not be too beneficial as running LBFGS on different datasets may not lend itself to vectorizations (compared e.g. to neural network computations on batches of data). A downside of vectorization is that it requires more memory: all the datasets and optimization steps happen in parallel, whereas with loop-based execution, only the coefficients of each time step need to be stored.\n\nRPythonJulia\n\n\nif (nthreads == 1) {\n    set.seed(240316)\n    params &lt;- lapply(1:nreps, solve)\n} else {\n    params &lt;- future_map(1:nreps, solve, .options=furrr_options(seed=240316))\n}\noutmat &lt;- do.call(rbind, params)\nmeans &lt;- colMeans(outmat)\nprint(means[1])\n\n\nk0 = random.PRNGKey(240316)\nks = random.split(k0, args.nreps)\nif args.primitive == 'map':\n    params = lax.map(solve, ks)\nelif args.primitive == 'vmap':\n    params = vmap(solve)(ks)\nelse:\n    raise ValueError(f\"unrecognized primitive: {args.primitive}, choose map or vmap\")\n\nmeans = jnp.mean(params, axis=0)\nprint(means[0])\n\n\nRandom.seed!(240316)\noutmat = zeros(nreps, 9)\n\n@threads for i in 1:nreps # use @threads for multi-threading\n    solution = solve()\n    outmat[i,:] = solution\nend\n\nmeans = mean(outmat, dims=1)\nprint(means[1])\n\n\n\n\n\n\nBash scripts for speed comparisons\nI benchmarked each run with an external time command in Bash or ZSH and wrote the results to a file.\n\nBash (linux)ZSH (macos)\n\n\n\n\nCode\n#!/bin/bash\n\nfor nreps in 1000 10000 100000 1000000 10000000\ndo\n    echo $nreps\n    { time python scripts/jaxspeed.py $nreps map; } 2&gt;&1 | grep real &gt;&gt; bashtimings.txt\n    sed -i '$s/$/ jax '\"${nreps}\"' nreps 12 nthreads map primitive/' bashtimings.txt\n    { time python scripts/jaxspeed.py $nreps vmap; } 2&gt;&1 | grep real &gt;&gt; bashtimings.txt\n    sed -i '$s/$/ jax '\"${nreps}\"' nreps 12 nthreads vmap primitive/' bashtimings.txt\n\n    for nthreads in 1 6 12\n    do\n        echo $nthreads\n        { time julia -t $nthreads scripts/jlspeed.jl $nreps ; } 2&gt;&1 | grep real &gt;&gt; bashtimings.txt\n        sed -i '$s/$/ julia '\"${nreps}\"' nreps '\"${nthreads}\"' nthreads/' bashtimings.txt\n        { time Rscript scripts/rspeed.R $nreps $nthreads ; } 2&gt;&1 | grep real &gt;&gt; bashtimings.txt\n        sed -i '$s/$/ r '\"${nreps}\"' nreps '\"${nthreads}\"' nthreads/' bashtimings.txt\n    done\ndone\n\n\n\n\n\n\nCode\n#!/bin/zsh\n\nfor nreps in 1000 10000 100000 1000000 10000000\ndo\n    echo $nreps\n    { time python scripts/jaxspeed.py $nreps map ; } 2&gt;&gt; timings.txt\n    sed -i '' '$s/$/ '\"${nreps}\"' nreps 8 threads map primitive/' timings.txt\n    { time python scripts/jaxspeed.py $nreps vmap ; } 2&gt;&gt; timings.txt\n    sed -i '' '$s/$/ '\"${nreps}\"' nreps 8 threads vmap primitive/' timings.txt\n\n    for nthreads in 1 8\n    do\n        echo $nthreads\n        { time julia -t $nthreads scripts/jlspeed.jl $nreps ; } 2&gt;&gt; timings.txt\n        sed -i '' '$s/$/ '\"${nreps}\"' nreps '\"${nthreads}\"' nthreads/' timings.txt\n        { time Rscript scripts/rspeed.R $nreps $nthreads ; } 2&gt;&gt; timings.txt\n        sed -i '' '$s/$/ '\"${nreps}\"' nreps '\"${nthreads}\"' nthreads/' timings.txt\n    done\ndone"
  },
  {
    "objectID": "posts/240308-jaxopt-vs-r-vs-julia/index.html#the-speed",
    "href": "posts/240308-jaxopt-vs-r-vs-julia/index.html#the-speed",
    "title": "The need for speed, performing simulation studies in R, JAX and Julia",
    "section": "The speed",
    "text": "The speed\n\nRunning time\nFirst, let’s see how running time increases with the number of experiments, using all available threads. You cannot easily set number of threads in JAX (see e.g. this issue on github), so all JAX computations use all threads.\n\n\nCode\nsuppressMessages({\n    library(dplyr)\n    library(data.table)\n    library(purrr)\n    library(stringr)\n    library(ggplot2); theme_set(theme_bw())\n    library(knitr)\n    library(kableExtra)\n})\n\n# get timings from mac\nlns &lt;- readr::read_lines('timings.txt')\n# get timings from linux machine\nblns &lt;- readr::read_lines('bashtimings.txt')\n\n# remove lines with warnings / errors printed to txt file\nlns &lt;- str_subset(lns, \"^Rscript|julia|python\")\nmtimings &lt;- data.table(raw_string=lns)\nbtimings &lt;- data.table(raw_string=blns)\n\n# remove white space and first word (for linux)\ntimings &lt;- rbindlist(list(macm1=mtimings, linux=btimings), idcol='machine')\ntimings[, string:=str_trim(raw_string)] # remove white space\ntimings[, string:=str_replace(string, \"^real\\t\", \"\")] # remove first word linux\n\n# find the language from the string\ntimings[machine=='macm1', command:=word(string)]\ntimings[command=='Rscript', language:='r']\ntimings[command=='python', language:='jax']\ntimings[command=='julia', language:='julia']\ntimings[machine=='linux', language:=str_extract(string, \"(?&lt;=s )[a-z]+\")]\n\n# grab number of threads and reps\ntimings[, nthreads:=as.integer(str_extract(string, \"(\\\\d+)(?= nthreads)\"))]\ntimings[, max_threads:=max(nthreads, na.rm=T), by='machine']\ntimings[is.na(nthreads) & language == 'jax', nthreads:=max_threads]\ntimings[is.na(nthreads) & language %in% c('r', 'julia'), nthreads:=1L]\ntimings[, nreps:=as.integer(str_extract(string, \"(\\\\d+)(?= nreps)\"))]\ntimings[, max_threads:=max(nthreads), by='machine']\n\n# find jax primitive\ntimings[, primitive:=str_extract(string, \"(\\\\w+)(?= primitive)\")]\ntimings[machine=='macm1'&language=='jax'&is.na(primitive), primitive:='map']\n#timings &lt;- timings[!(language=='jax' & primitive!='map')]\n# timings[language=='jax', language:=paste0(language, '-', primitive)]\ntimings[language!='jax', primitive:='map']\ntimings &lt;- timings[!str_ends(primitive, 'nojit')]\n\n# grab the time \ntimings[machine=='macm1', time_str:=str_extract(string, \"(?&lt;=cpu\\\\ )(.*)(?= total)\")]\ntimings[, milliseconds:=as.integer(str_extract(time_str, \"(\\\\d+)$\"))]\ntimings[, seconds     :=as.integer(str_extract(time_str, \"(\\\\d+)(?=.)\"))]\ntimings[, minutes     :=as.integer(str_extract(time_str, \"(\\\\d+)(?=:)\"))]\ntimings[, hours       :=as.integer(str_extract(time_str, \"(\\\\d+)(?=:(\\\\d+:))\"))]\ntimings[machine=='linux', minutes:=as.integer(str_extract(string, \"^(\\\\d+)\"))]\ntimings[machine=='linux', seconds:=as.integer(str_extract(string, \"(?&lt;=m)(\\\\d+)\"))]\ntimings[machine=='linux', milliseconds:=as.integer(str_extract(string, \"(\\\\d+)(?=s)\"))]\ntimings[is.na(minutes), minutes:=0]\ntimings[is.na(hours), hours:=0]\n\n\ntimings[, sec_total:=60*60*hours + 60*minutes + seconds + milliseconds / 1000]\ntimings[, min_total:=sec_total / 60]\n\n# add some vars\ntimings[, n_per_min:=nreps / min_total]\ntimings[, n_per_min3:=n_per_min/1000]\n\n# remove a couple of failed runs where time went down for more experiments (= out of memory)\n#timings &lt;- timings[n_per_min &lt; 1.5e6]\n\n\nfwrite(timings, 'allresults.csv', row.names=F)\n\nggplot(timings[nthreads==max_threads], aes(x=nreps, y=min_total, col=language)) +\n  geom_point() + geom_line(aes(linetype=primitive)) + \n  scale_x_log10() + scale_y_log10() + \n  # facet_grid(machine+nthreads~primitive, labeller='label_both')\n  facet_grid(machine+nthreads~., labeller='label_both')\n\n\n\n\n\n\n\n\nFigure 1: Time to run experiments on the maximum number of threads\n\n\n\n\n\nNote that for JAX vmap the clock time actually goes down when the number of experiment increases. This is not some magic speedup but the machine running out of memory and thus not completing the experiment, a downside of vectorization. We’ll exclude these runs of the further comparisons. For map this is not the case.\n\n\nSpeed\nLet’s look at the speeds.\n\n\n\n\n\n\n\n\nFigure 2: Speed: number of repetitions per minute versus of number of experiments\n\n\n\n\n\nWhy is the speed going down for Julia on the macm1 machine after 1e6 experiments? Turns out there is not enough RAM to fit the experiments and the system switches to swap memory which is much slower than using RAM (even on a mac arm64). The speed of R stopped increasing after 1e6 experiments so I didn’t run more experiments.\n\n\nThreads vs Speed\nNow let’s check how much extra speed we get from using more threads in R and Julia.\n\n\n\n\n\n\n\n\nFigure 3: Scaling of speed with number of threads\n\n\n\n\n\n\n\n\nScaling of speed with number of threads, number of experiments per minute (1000s)\n\n\nlanguage\nnreps\nlinux_1\nlinux_6\nspeedup6\nlinux_12\nspeedup12\nmacm1_1\nmacm1_8\nspeedup8\n\n\n\n\njulia\n1e+03\n10.7\n11.8\n1.1\n11.0\n1.0\n16.2\n16.3\n1.0\n\n\njulia\n1e+04\n69.5\n108.1\n1.6\n101.0\n1.5\n96.9\n147.6\n1.5\n\n\njulia\n1e+05\n146.0\n514.8\n3.5\n567.1\n3.9\n151.3\n494.4\n3.3\n\n\njulia\n1e+06\n162.8\n857.3\n5.3\n1001.3\n6.2\n163.9\n983.6\n6.0\n\n\njulia\n1e+07\n168.6\n875.7\n5.2\n1059.3\n6.3\n163.9\n245.9\n1.5\n\n\nr\n1e+03\n14.8\n14.5\n1.0\n9.2\n0.6\n20.8\n23.7\n1.1\n\n\nr\n1e+04\n15.3\n53.0\n3.5\n52.4\n3.4\n22.5\n72.7\n3.2\n\n\nr\n1e+05\n14.6\n74.1\n5.1\n89.8\n6.2\n24.6\n98.2\n4.0\n\n\nr\n1e+06\n13.9\n70.8\n5.1\n91.0\n6.6\n20.9\n82.0\n3.9\n\n\n\n\n\nSpeed increases with increasing number of threads, though not with a simple linear scaling in the number of threads. The speed increase is similar for R and Julia.\n\n\nTop speeds per language\nLet’s see the top speeds per language, also compered to the top R speed on that machine.\n\n\n\n\nTable 1: Best speeds per language and machine\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nn experiments\nn threads\nrunning time (minutes)\nexperiments per minute (x1000)\nspeed-up vs best R\nlanguage\nprimitive\nmachine\n\n\n\n\n1e+05\n12\n0.6\n161.9\n1.8\njax\nvmap\nlinux\n\n\n1e+07\n12\n9.4\n1059.3\n11.6\njulia\nmap\nlinux\n\n\n1e+06\n12\n11.0\n91.0\n1.0\nr\nmap\nlinux\n\n\n1e+06\n8\n6.1\n163.9\n1.7\njax\nmap\nmacm1\n\n\n1e+06\n8\n1.0\n983.6\n10.0\njulia\nmap\nmacm1\n\n\n1e+05\n8\n1.0\n98.2\n1.0\nr\nmap\nmacm1\n\n\n\n\n\n\n\n\n\n\nTop speeds overall\nTop 10 speeds overall\n\n\n\n\nTable 2: top 10 speeds overall\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nn experiments\nn threads\nrunning time (minutes)\nexperiments per minute (x1000)\nspeed-up vs best R\nlanguage\nprimitive\nmachine\n\n\n\n\n1e+07\n12\n9.4\n1059.3\n11.6\njulia\nmap\nlinux\n\n\n1e+06\n12\n1.0\n1001.3\n11.0\njulia\nmap\nlinux\n\n\n1e+06\n8\n1.0\n983.6\n10.0\njulia\nmap\nmacm1\n\n\n1e+07\n6\n11.4\n875.7\n9.6\njulia\nmap\nlinux\n\n\n1e+06\n6\n1.2\n857.3\n9.4\njulia\nmap\nlinux\n\n\n1e+05\n12\n0.2\n567.1\n6.2\njulia\nmap\nlinux\n\n\n1e+05\n6\n0.2\n514.8\n5.7\njulia\nmap\nlinux\n\n\n1e+05\n8\n0.2\n494.4\n5.0\njulia\nmap\nmacm1\n\n\n1e+07\n8\n40.7\n245.9\n2.5\njulia\nmap\nmacm1\n\n\n1e+07\n1\n59.3\n168.6\n1.9\njulia\nmap\nlinux\n\n\n\n\n\n\n\n\nAll results are available in a csv file here"
  },
  {
    "objectID": "posts/240308-jaxopt-vs-r-vs-julia/index.html#takeaways",
    "href": "posts/240308-jaxopt-vs-r-vs-julia/index.html#takeaways",
    "title": "The need for speed, performing simulation studies in R, JAX and Julia",
    "section": "Takeaways",
    "text": "Takeaways\n\nSpeed\nIn this setup, both on a Mac M1 and a Linux machine,\n\nJulia was 10-11 times faster than R\nJAX was 1.7 times faster than R\n\n\n\nCode\n\nJulia code seems quite close to R code.\nIn this simple example, the JAX code doesn’t seem too dounting. However, JAX comes with some sharp bits and may be harder to program efficiently.1\n\n\n\nCaveats\n\nJAX needs to recompile when the size of the data changes. When running experiments with e.g. different sizes of data, JAX will become slower because it needs to recompile, or you’ll need to find other solutions like padding smaller data with dummy data and giving these dummy data 0 weights in the objective functions.\nI didn’t have a CUDA-enabled GPU machine for this comparison, vmap may be come (much) more performant on a GPU\nJAX gives bare bones results. If you want to do e.g. significance testing of coefficients, or model comparisons, you will need to find implementations for this or implement this yourself. R and Julia (specifically the GLM package provide a much wider suite of methods\nIn JAX I used general purpose optimizer. There may be more efficient ways of estimating a logistic regression model, whose optimizations are implemented in R and Julia but not JAX. In this sense it may not be a fair comparison, though these optimizations would need to be sought or implemented in JAX.\nJAX has autograd. When writing custom objective functions JAX can automatically calculate gradients and hessians, making it possible to use general purpose first or second order optimizers (e.g. Amsterdam and Ranganath 2023).\n\n\n\nExtensions\n\nOptimizing memory usage\nSince in this case we only need the avarage of the coefficients we need not store all intermediate results. All languages may beccome much more efficient if we can program this in.\n\nThe julia domumentation states that certain operations to atomic data structures can be done in a safe-way while multithreading. Instead of returning all coefficients of all datasets, we could calculate the average value of the coefficients (and e.g. the avareage of the squares of the values) with less memory overhead by:\n\ninstantiate an atomic vector of 9 coefficients\nlet every experiment (which may be in different threads) add its value to this shared atomic vector with atomic_add!\nat the end, calculate the mean by dividing by nreps.\n\nR functions can also overwrite global variables, but a question is whether this can be done in a multi-threading safe way\nIn JAX we may use scan to keep track of a running sum of coefficients and then vmap a bunch of scan computations\n\nIn future posts I plan to dive in to dive in to these optimizations to squeeze more out of these languages."
  },
  {
    "objectID": "posts/240308-jaxopt-vs-r-vs-julia/index.html#conclusion",
    "href": "posts/240308-jaxopt-vs-r-vs-julia/index.html#conclusion",
    "title": "The need for speed, performing simulation studies in R, JAX and Julia",
    "section": "Conclusion",
    "text": "Conclusion\n\n\n\n\n\n\nTipWhat should you use for glm-like simulation studies?\n\n\n\nProbably, Julia"
  },
  {
    "objectID": "posts/240308-jaxopt-vs-r-vs-julia/index.html#session-info",
    "href": "posts/240308-jaxopt-vs-r-vs-julia/index.html#session-info",
    "title": "The need for speed, performing simulation studies in R, JAX and Julia",
    "section": "Session Info",
    "text": "Session Info\n\nRPythonJulia\n\n\n#| echo: false\n#| eval: false\nlibrary(sessioninfo)\nsession_info(pkgs = \"attached\", to_file=\"_rsession.txt\")\n\n─ Session info ────────────────────────────────────────────────────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.3.2 (2023-10-31)\n os       macOS Sonoma 14.3\n system   aarch64, darwin23.0.0\n ui       RStudio\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/Amsterdam\n date     2024-03-21\n rstudio  2023.12.1+402 Ocean Storm (desktop)\n pandoc   3.1.12.2 @ /opt/homebrew/bin/ (via rmarkdown)\n\n─ Packages ────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n data.table  * 1.14.8  2023-02-17 [1] CRAN (R 4.3.1)\n dplyr       * 1.1.2   2023-04-20 [1] CRAN (R 4.3.1)\n ggplot2     * 3.4.2   2023-04-03 [1] CRAN (R 4.3.1)\n kableExtra  * 1.4.0   2024-01-24 [1] CRAN (R 4.3.2)\n knitr       * 1.43    2023-05-25 [1] CRAN (R 4.3.1)\n purrr       * 1.0.1   2023-01-10 [1] CRAN (R 4.3.1)\n sessioninfo * 1.2.2   2021-12-06 [1] CRAN (R 4.3.2)\n stringr     * 1.5.0   2022-12-02 [1] CRAN (R 4.3.1)\n\n [1] /opt/homebrew/lib/R/4.3/site-library\n [2] /opt/homebrew/Cellar/r/4.3.2/lib/R/library\n\n───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n\n\njax==0.4.25\njaxlib==0.4.25\njaxopt==0.8.3\nml-dtypes==0.3.2\nnumpy==1.26.4\nopt-einsum==3.3.0\nscipy==1.12.0\n\n\nname = \"jlspeed\"\nuuid = \"a8cd5241-1987-4548-90e5-ac0f39e812f2\"\nauthors = [\"Wouter van Amsterdam\"]\nversion = \"0.1.0\"\n\n[deps]\nArgParse = \"c7e460c6-2fb9-53a9-8c5b-16f535851c63\"\nGLM = \"38e38edf-8417-5370-95a0-9cbb8c7f171a\"\nRandom = \"9a3f8284-a2c9-5f02-9a11-845980a1fd5c\"\nStatsBase = \"2913bbd2-ae8a-5f71-8c99-4fb6c76f3a91\""
  },
  {
    "objectID": "posts/240308-jaxopt-vs-r-vs-julia/index.html#full-scripts",
    "href": "posts/240308-jaxopt-vs-r-vs-julia/index.html#full-scripts",
    "title": "The need for speed, performing simulation studies in R, JAX and Julia",
    "section": "Full scripts",
    "text": "Full scripts\n\nRPythonJulia\n\n\n# rspeed\nargs = commandArgs(trailingOnly = T)\nif (length(args) == 0) {\n  nreps = 100\n  nthreads = 1\n} else if (length(args) == 1) {\n  nreps = as.integer(args[1])\n  nthreads = 1\n} else {\n  nreps = as.integer(args[1])\n  nthreads = as.integer(args[2])\n  suppressMessages(library(furrr))\n  plan(multisession, workers=nthreads)\n}\n\nmake_data &lt;- function(n=1e3L) {\n    x_vec = rnorm(n*10)\n    X_full = matrix(x_vec, ncol=10)\n    eta = rowSums(X_full)\n    y = eta &gt; 0\n    # return only first 9 column to have some noise\n    X = X_full[,1:9]\n    return(list(X=X,y=y))\n}\n\nsolve &lt;- function(...) {\n  data = make_data()\n  fit = glm(data$y~data$X-1, family='binomial')\n  coefs = coef(fit)\n  return(coefs)\n}\n\nif (nthreads == 1) {\n    set.seed(240316)\n    params &lt;- lapply(1:nreps, solve)\n} else {\n    params &lt;- future_map(1:nreps, solve, .options=furrr_options(seed=240316))\n}\noutmat &lt;- do.call(rbind, params)\nmeans &lt;- colMeans(outmat)\nprint(means[1])\n\n\n\nimport jax, jaxopt jax.config.update(‘jax_platform_name’, ‘cpu’) # make sure jax doesnt use a gpu if it’s available from jax import numpy as jnp, random, vmap, jit, lax from jaxopt import LBFGS from jaxopt.objective import binary_logreg from argparse import ArgumentParser\nparser = ArgumentParser() parser.add_argument(‘nreps’, nargs=“?”, type=int, default=int(10)) parser.add_argument(‘primitive’, nargs=“?”, type=str, default=“vmap”)\ndef make_data(k, n=int(1e3)): X_full = random.normal(k, (n,10)) # JAX needs explicit keys for psuedo random number generation eta = jnp.sum(X_full, axis=-1) y = eta &gt; 0 # return only first 9 column to have some noise X = X_full[:,:9] return (X, y)\n\ninitialize a generic solver with the correct objective function\nsolver = LBFGS(binary_logreg) # need to specify parameter initialization values w_init = jnp.zeros((9,))\n(jit?) # jit toggles just-in-time compilation, one of the main features of JAX def solve(k): data = make_data(k) param, state = solver.run(w_init, data) return param\nif name == ‘main’: args = parser.parse_args() k0 = random.PRNGKey(240316) ks = random.split(k0, args.nreps) if args.primitive == ‘map’: params = lax.map(solve, ks) elif args.primitive == ‘vmap’: params = vmap(solve)(ks) else: raise ValueError(f”unrecognized primitive: {args.primitive}, choose map or vmap”)\nmeans = jnp.mean(params, axis=0)\nprint(means[0])\n\n\n\nusing Random, GLM, StatsBase, ArgParse\nimport Base.Threads.@threads\n\nfunction parse_cmdline()\n    parser = ArgParseSettings()\n\n    @add_arg_table parser begin\n        \"nreps\"\n          help = \"number of repetitions\"\n          required = false\n          arg_type = Int\n          default = 10\n    end\n\n    return parse_args(parser)\nend\n\nfunction make_data(n::Integer=1000)\n    X_full = randn(n,10)\n    eta = vec(sum(X_full, dims=2))\n    y = eta .&gt; 0 # vectorized greater than 0 comparison\n    X = X_full[:,1:9]\n    return X, y\nend\n\nfunction solve(i::Int64=1)\n    X, y = make_data()\n    fit = glm(X, y, Bernoulli())\n    coefs = coef(fit)\n    return coefs\nend\n\nfunction main()\n    args = parse_cmdline()\n    nreps = get(args, \"nreps\", 10)\n\n    Random.seed!(240316)\n    outmat = zeros(nreps, 9)\n\n    @threads for i in 1:nreps # use @threads for multi-threading\n        solution = solve()\n        outmat[i,:] = solution\n    end\n\n    means = mean(outmat, dims=1)\n    print(means[1])\nend\n\nmain()"
  },
  {
    "objectID": "posts/240308-jaxopt-vs-r-vs-julia/index.html#references",
    "href": "posts/240308-jaxopt-vs-r-vs-julia/index.html#references",
    "title": "The need for speed, performing simulation studies in R, JAX and Julia",
    "section": "References",
    "text": "References\n\n\nAmsterdam, Wouter A. C. van, Netanja I. Harlianto, Joost J. C. Verhoeff, Pim Moeskops, Pim A. de Jong, and Tim Leiner. 2022. “The Association Between Muscle Quantity and Overall Survival Depends on Muscle Radiodensity: A Cohort Study in Non-Small-Cell Lung Cancer Patients.” Journal of Personalized Medicine 12 (7): 1191. https://doi.org/10.3390/jpm12071191.\n\n\nAmsterdam, Wouter A. C. van, and Rajesh Ranganath. 2023. “Conditional Average Treatment Effect Estimation with Marginally Constrained Models.” Journal of Causal Inference 11 (1): 20220027. https://doi.org/10.1515/jci-2022-0027.\n\n\nAmsterdam, Wouter A. C. van, Joost J. C. Verhoeff, Netanja I. Harlianto, Gijs A. Bartholomeus, Aahlad Manas Puli, Pim A. de Jong, Tim Leiner, Anne S. R. van Lindert, Marinus J. C. Eijkemans, and Rajesh Ranganath. 2022. “Individual Treatment Effect Estimation in the Presence of Unobserved Confounding Using Proxies: A Cohort Study in Stage III Non-Small Cell Lung Cancer.” Scientific Reports 12 (1): 5848. https://doi.org/10.1038/s41598-022-09775-9.\n\n\n“DifferentiableUniverseInitiative/Jax_cosmo.” 2024. Differentiable Universe Initiative. https://github.com/DifferentiableUniverseInitiative/jax_cosmo.\n\n\n“SciML: Open Source Software for Scientific Machine Learning.” n.d. Accessed March 14, 2024. https://sciml.ai."
  },
  {
    "objectID": "posts/240308-jaxopt-vs-r-vs-julia/index.html#footnotes",
    "href": "posts/240308-jaxopt-vs-r-vs-julia/index.html#footnotes",
    "title": "The need for speed, performing simulation studies in R, JAX and Julia",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nOne concrete example with my own previous simulation studies (Amsterdam and Ranganath 2023) is that I used first used jax.numpy arrays for different parameters and then a scipy function to create all combinations of these parameters. Creating this grid of parameters this way forced copying of jax.numpy arrays from the GPU back to CPU and then copying the grid back to GPU. This made the entire process orders of magnitude slower (it was a large grid O(1e12)). Gotchas like these can bite you. Also, JAX relies on pure functions that cannot depend on global variables.↩︎"
  },
  {
    "objectID": "talks.html",
    "href": "talks.html",
    "title": "Talks",
    "section": "",
    "text": "Here is a selection of my talks.\n\n\n   \n    \n    \n      Order By\n      Default\n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Title\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\n\nTitle\n\n\n\nSubtitle\n\n\n\n\n\n\n\n\nDec 2, 2025\n\n\nSelf-fulfilling prophecies: But is the prophet heard?\n\n\nSeminar on Prediction Under Intervention(s), Leiden\n\n\n\n\n\n\nAug 25, 2025\n\n\nFrom prediction to treatment decision: aligning development, evaluation and monitoring\n\n\nISCB session ‘Prediction modelling meets causal inference for clinical decision making’\n\n\n\n\n\n\nMay 22, 2025\n\n\nA causal viewpoint on prediction model performance under changes in case-mix\n\n\nHuman Data Science ‘Content Meeting’\n\n\n\n\n\n\nApr 17, 2025\n\n\nCausal Data Science in Utrecht: causality for prediction model generalization\n\n\nApplied Data Science event Utrecht University\n\n\n\n\n\n\nJan 27, 2025\n\n\nmy priorities for AI in health\n\n\nDagstuhl Seminar 2025\n\n\n\n\n\n\nNov 25, 2024\n\n\nA causal viewpoint on prediction model performance under changes in case-mix\n\n\nMethods meeting at the Julius Center, UMC Utrecht\n\n\n\n\n\n\nNov 6, 2024\n\n\nPearl Causal Hierarchy\n\n\nCausal Inference at Julius reading group\n\n\n\n\n\n\nSep 26, 2024\n\n\nAn introduction to AI for biostatisticians\n\n\nBMS-Aned seminar\n\n\n\n\n\n\nJul 8, 2024\n\n\nMedical imaging and AI for decision support\n\n\nMedical Imaging AI lab meeting\n\n\n\n\n\n\nMay 30, 2024\n\n\nUses and pitfalls with AI for decision support - harmful self-fulfilling prophecies\n\n\nWEON masterclass 2024 - AI-based prediction models in healthcare: from development to implementation\n\n\n\n\n\n\nMay 16, 2024\n\n\nCausality and prediction: developing and validating models for decision making\n\n\nCausal Data Science Special Interest Group - Utrecht\n\n\n\n\n\n\nMay 15, 2024\n\n\nDecision support based on AI in medical imaging\n\n\nAI in medical imaging (AIBIA) parallel session\n\n\n\n\n\n\nMay 7, 2024\n\n\nAn intro to causal inference and its uses in radiotherapy\n\n\nESTRO - Understanding dose-effects: Can we go beyond association - symposium\n\n\n\n\n\n\nApr 18, 2024\n\n\nAI and its (mis)uses in medical research and practice\n\n\nInfection and Immunity spring meeting\n\n\n\n\n\n\nAug 10, 2023\n\n\nThe value of observational causal inference for medical decision making\n\n\nMLHC causality pre-conference workshop\n\n\n\n\n\n\nJun 24, 2023\n\n\nMy risk model is super accurate so it will be useful for treatment decision making, right? Wrong!\n\n\nCHIL 2023 - lightning talk\n\n\n\n\n\n\nMar 1, 2023\n\n\nIndividual treatment effect estimation in the presence of unobserved confounding using proxies\n\n\nSeminar at Manchester University\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Wouter van Amsterdam, MD, PhD",
    "section": "",
    "text": "Twitter\n  \n  \n    \n     Linkedin\n  \n  \n    \n     ORCID\n  \n  \n    \n     github\n  \n  \n    \n     pubmed\n  \n  \n    \n     google-scholar\n  \n\n  \n  \nLearning from Historical data to make better decisions in the future\nI work on the intersection of machine learning (for flexible data analysis) and causal inference (to learn to make better decisions).\nI am an assistant professor at the University Medical Center Utrecht, working on methods and applications of machine learning and causal inference for health care. I have degrees in Physics (BSc), Medicine (MD), epidemiology (MSc) and a PhD on machine learning for healthcare, advised by Rajesh Ranganath from NYU and Joost Verhoeff, Tim Leiner and Pim de Jong from the UMC Utrecht.\n\n\n\n\nUMC Utrecht| Assistant Professor | 2023 - now\nBabylon Health | Senior Research Scientist | 2021 - 2023\nCV (pdf, jul 2025)"
  },
  {
    "objectID": "index.html#news",
    "href": "index.html#news",
    "title": "Wouter van Amsterdam, MD, PhD",
    "section": "News",
    "text": "News\nI’m a guest editor for a special issue in BMC diagnostic and prognostic research titled “Validation and transparency for AI-based diagnosis and prognosis in healthcare”, together with Maarten van Smeden and Anne de Hond. Submission is open until Jan 31st 2025."
  },
  {
    "objectID": "index.html#selected-papers",
    "href": "index.html#selected-papers",
    "title": "Wouter van Amsterdam, MD, PhD",
    "section": "Selected papers",
    "text": "Selected papers\nA causal viewpoint on prediction model performance under changes in case-mix: Discrimination and calibration respond differently for prognosis and diagnosis predictions.\nvan Amsterdam, W. A. C. (2024). arXiv preprint\nurl pdf\nAI as an intervention: improving clinical outcomes relies on a causal approach to AI development and validation\nShalmali Joshi, Inigo Urteaga, Wouter A. C. van Amsterdam et al. JAMIA 2025.\nurl\nWhen accurate prediction models yield harmful self-fulfilling prophecies.\nvan Amsterdam, W. A. C., van Geloven, N., Krijthe, J. H., Ranganath, R., & Ciná, G. Patterns. 2025 Apr;6(4):101229. url pdf\nCausal Inference in Oncology: Why, What, How and When.\nvan Amsterdam, W. A. C., Elias, S., & Ranganath, R. (2024). Clinical Oncology.\nurl pdf\nPrognostic models for decision support need to report their targeted treatments and the expected changes in treatment decisions.\nvan Amsterdam, W. A. C. and Cinà, Giovanni and Didelez, Vanessa and Keogh, Ruth H. and Peek, Niels and Sperrin, Matthew and Vickers, Andrew J. and van Geloven, Nan and Shalit, Uri (2024). BMJ Rapid-response\nurl\nFrom algorithms to action: improving patient care requires causality.\nvan Amsterdam, W. A. C., de Jong, P. A., Verhoeff, J. J. C., Leiner, T., & Ranganath, R. (2024). BMC Medical Informatics and Decision Making\nurl pdf\nIndividual treatment effect estimation in the presence of unobserved confounding using proxies: A cohort study in stage III non-small cell lung cancer.  van Amsterdam, W. A. C., Verhoeff, J. J. C., Harlianto, N. I., Bartholomeus, G. A., Puli, A. M., de Jong, P. A., Leiner, T., van Lindert, A. S. R., Eijkemans, M. J. C., & Ranganath, R. (2022). Scientific Reports\nurl pdf\nConditional average treatment effect estimation with marginally constrained models.\nvan Amsterdam, W. A. C., & Ranganath, R. (2023). Journal of Causal Inference\nurl pdf\nEliminating biasing signals in lung cancer images for prognosis predictions with deep learning.\nvan Amsterdam, W. A. C., Verhoeff, J. J. C., de Jong, P. A., Leiner, T., & Eijkemans, M. J. C. (2019). Npj Digital Medicine\nurl pdf\nMore papers on google scholar"
  },
  {
    "objectID": "index.html#talks",
    "href": "index.html#talks",
    "title": "Wouter van Amsterdam, MD, PhD",
    "section": "Talks",
    "text": "Talks\n\n\n   \n    \n    \n      Order By\n      Default\n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Title\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\n\nTitle\n\n\n\nSubtitle\n\n\n\n\n\n\n\n\nDec 2, 2025\n\n\nSelf-fulfilling prophecies: But is the prophet heard?\n\n\nSeminar on Prediction Under Intervention(s), Leiden\n\n\n\n\n\n\nAug 25, 2025\n\n\nFrom prediction to treatment decision: aligning development, evaluation and monitoring\n\n\nISCB session ‘Prediction modelling meets causal inference for clinical decision making’\n\n\n\n\n\n\nMay 22, 2025\n\n\nA causal viewpoint on prediction model performance under changes in case-mix\n\n\nHuman Data Science ‘Content Meeting’\n\n\n\n\n\n\nApr 17, 2025\n\n\nCausal Data Science in Utrecht: causality for prediction model generalization\n\n\nApplied Data Science event Utrecht University\n\n\n\n\n\n\nJan 27, 2025\n\n\nmy priorities for AI in health\n\n\nDagstuhl Seminar 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#teaching",
    "href": "index.html#teaching",
    "title": "Wouter van Amsterdam, MD, PhD",
    "section": "Teaching",
    "text": "Teaching\n\n2025 Introduction to Causal Inference and Causal Data Science summer school; course description and registration; course materials\n2025 Causal Data Science summer school (see last years materials below)\n2025 European Medicines Agency course “Big Data”, module: Target Trial Emulation\n2024 Introduction to Causal Inference and Causal Data Science summer school\n2023 Big Data summer school"
  },
  {
    "objectID": "index.html#posts",
    "href": "index.html#posts",
    "title": "Wouter van Amsterdam, MD, PhD",
    "section": "Posts",
    "text": "Posts\n\n\n\n\n\n\n\n\nFlipping the sign of hazard ratios\n\n\n\n\n\n\nWouter van Amsterdam\n\n\nJul 4, 2025\n\n\n\n\n\n\n\n\n\n\n\nWhat is stronger evidence of prediction model robustness?\n\n\n\n\n\n\nWouter van Amsterdam\n\n\nApr 25, 2025\n\n\n\n\n\n\n\n\n\n\n\nIs the JAMA opening up their language for causal effects?\n\n\n\n\n\n\nWouter van Amsterdam\n\n\nJun 7, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#students",
    "href": "index.html#students",
    "title": "Wouter van Amsterdam, MD, PhD",
    "section": "Students",
    "text": "Students\n\nJames Hesp (SciML4Medicine project) - PhD student\nBenedetta Dionisi Ferrera (INT Milan, remote) - PhD student\nSu Li (Methodology and Statistics) - MSc. student\nFlorian Metwaly (Methodology and Statistics) - MSc. student\nRodrigue Ndabashinze (Epidemiology, University of Antwerp) - MSc. student\n\n\nFormer\n\nSamil Kilinc (Applied Data Science, 2024)\nKiara Peek (Applied Data Science, 2024)\nMyra van Laar (Biomedical Sciences)\nGijs Bartholomeus (Medicine)\nNetanja Harlianto (Medicine)"
  },
  {
    "objectID": "index.html#in-the-news",
    "href": "index.html#in-the-news",
    "title": "Wouter van Amsterdam, MD, PhD",
    "section": "In the News",
    "text": "In the News\n\nOur work on harmful-selfulfilling prophecies got covered in The Independent, Pharmophorum, and 6 independent experts at an SMC-roundup\nI gave an interview for BiotechNEWs on my vision for the future of AI in healthcare pdf"
  },
  {
    "objectID": "index.html#activities",
    "href": "index.html#activities",
    "title": "Wouter van Amsterdam, MD, PhD",
    "section": "Activities",
    "text": "Activities\n\nprogram chair Workshop, MLHC 2025\nboard member BMS-ANed (Dutch biometrics society)\ncoordinator of UMC Utrecht AI methods lab\nambassador for Applied Data Science of Utrecht University\nco-coordinator of Causal Data Science Special Interest Group of Utrecht University"
  },
  {
    "objectID": "index.html#contact",
    "href": "index.html#contact",
    "title": "Wouter van Amsterdam, MD, PhD",
    "section": "Contact",
    "text": "Contact\nwamster3 at umcutrecht dot nl"
  },
  {
    "objectID": "outline.html",
    "href": "outline.html",
    "title": "Much of AI is predict - predict - predict",
    "section": "",
    "text": "using ECG, predict presence of structural heart disease, typically diagnosed with cardiac echo\npredict 10-year heart attack risk using basic medical information"
  },
  {
    "objectID": "outline.html#ecg-to-shd-yaoartificialintelligenceenabled2021",
    "href": "outline.html#ecg-to-shd-yaoartificialintelligenceenabled2021",
    "title": "Much of AI is predict - predict - predict",
    "section": "ECG to SHD [@yaoArtificialIntelligenceEnabled2021]",
    "text": "ECG to SHD [@yaoArtificialIntelligenceEnabled2021]\n\nprediction: structural heart disease\nintervention: refer patient for cardiac echo\noutcome: diagnosis of structural heart disease\noutcome (impact): reduce preventable early cardiac death"
  },
  {
    "objectID": "outline.html#year-heart-attack-risk-hippisley-coxdevelopmentvalidationnew2024",
    "href": "outline.html#year-heart-attack-risk-hippisley-coxdevelopmentvalidationnew2024",
    "title": "Much of AI is predict - predict - predict",
    "section": "10 year heart attack risk [@hippisley-coxDevelopmentValidationNew2024]",
    "text": "10 year heart attack risk [@hippisley-coxDevelopmentValidationNew2024]\n\nprediction: heart attack in 10 years\nintervention: prescribe cholesterol lowering medication\noutcome: heart attack\noutcome (impact): reduce heart attacks"
  },
  {
    "objectID": "outline.html#process",
    "href": "outline.html#process",
    "title": "Much of AI is predict - predict - predict",
    "section": "Process",
    "text": "Process\n\ndata scientists optimize for predictive accuracy, which entails modeling statistical associations in the ‘healthcare system’\nthe hope is: better prediction \\(\\imply\\) better impact\nunfortunately, this is not automatically the case"
  },
  {
    "objectID": "posts/250425-robustness/index.html",
    "href": "posts/250425-robustness/index.html",
    "title": "What is stronger evidence of prediction model robustness?",
    "section": "",
    "text": "We’re evaluating a prediction model \\(f\\) that takes features \\(X\\) to predict binary outcome \\(Y\\). We’d like the model to be robust, meaning that it’s predictive performance is stable in different environments. To test this, the model has been evaluated in multiple testing environments (e.g. different hospitals, populations, regions, health-care settings, etc.). In each environment, we measure predictive performance with:\n\ndiscrimination: area under the ROC curve (integration of sensitivity and specificity for varying threshold \\(0 \\leq \\tau \\leq 1\\))\ncalibration: alignement between predicted probabilities and observed outcome rates\n\n\n\n\n\n\n\nTipWhich result would provide stronger evidence of robustness?\n\n\n\nA. observe stable discrimination and calibration across all environments\nB. observe stable discrimination but poor calibration in some environments"
  },
  {
    "objectID": "posts/250425-robustness/index.html#question",
    "href": "posts/250425-robustness/index.html#question",
    "title": "What is stronger evidence of prediction model robustness?",
    "section": "",
    "text": "We’re evaluating a prediction model \\(f\\) that takes features \\(X\\) to predict binary outcome \\(Y\\). We’d like the model to be robust, meaning that it’s predictive performance is stable in different environments. To test this, the model has been evaluated in multiple testing environments (e.g. different hospitals, populations, regions, health-care settings, etc.). In each environment, we measure predictive performance with:\n\ndiscrimination: area under the ROC curve (integration of sensitivity and specificity for varying threshold \\(0 \\leq \\tau \\leq 1\\))\ncalibration: alignement between predicted probabilities and observed outcome rates\n\n\n\n\n\n\n\nTipWhich result would provide stronger evidence of robustness?\n\n\n\nA. observe stable discrimination and calibration across all environments\nB. observe stable discrimination but poor calibration in some environments"
  },
  {
    "objectID": "posts/250425-robustness/index.html#answer",
    "href": "posts/250425-robustness/index.html#answer",
    "title": "What is stronger evidence of prediction model robustness?",
    "section": "Answer",
    "text": "Answer\nWe’ll answer this in three steps:\n\nwhere do differences between environments come from?\nhow are discrimination and calibration calculated?\nputting 1 and 2 together, answer the question\n\n\nWhere do differences between environments come from?\n\nTo evaluate the question we’ll first layout how exactly environments may be different. In probability statements, how the joint distribution of \\(X\\) and \\(Y\\) depends on the environment \\(E\\). Without making any assumptions, we can decompose the joint distriution in two ways using the chain rule (or general product rule):\n\\[\\begin{align*}\n  P_E(X,Y) &= P_E(Y|X)P_E(X) \\\\\n           &= P_E(X|Y)P_E(Y)\n\\end{align*}\\]\nHow can environments differ? Clearly, one or more of the four terms needs to depend on environment \\(E\\). For discrimination and or calibration to be stable, we need at least some parts of the distribution to remain the same across environments, i.e. transportable. Let’s consider the minimal differences that would lead to a change in distribution between environments. These are minimal in the sence that only one of the four terms depends on \\(E\\), and the others are transportable across environments. The options are:\n\n\n\nTable 1: Enumeration of possibilities for minimal differences across environments\n\n\n\n\n\ncase\ndecomposition\ndepends on E\ntransportable\n\n\n\n\n1\n\\(P(Y|X)P(X)\\)\n\\(P(X)\\)\n\\(P(Y|X)\\)\n\n\n2\n\n\\(P(Y|X)\\)\n\\(P(X)\\)\n\n\n3\n\\(P(X|Y)P(Y)\\)\n\\(P(Y)\\)\n\\(P(X|Y)\\)\n\n\n4\n\n\\(P(X|Y)\\)\n\\(P(Y)\\)\n\n\n\n\n\n\n\n\nHow are discrimination and calibration calculated?\nDiscrimination measures how well a model can separate positive from neagtive cases and is typically measured with sensitivity, specificity and the AUC. Given a threshold \\(0 \\leq \\tau \\leq 1\\),\n\nSensitivity is the ratio of positive predictions in the positive cases: \\(P(f(X) &gt; \\tau | Y=1)\\)\nSpecificity is the ratio of negative predictions in the negative cases: \\(P(f(X) \\leq \\tau | Y=0)\\)\n\nThe AUC is obtained by varying \\(\\tau\\) between 0 and 1, plotting the sensitivity and specificity for every value of \\(\\tau\\) and calculating the area under the curve.\n\n\n\n\n\n\nTipCrucial insight:\n\n\n\nDiscrimination is a function of the distribution of features given the outcome. This means that when \\(P(X|Y)\\) is the same across environments, so is the model’s AUC (i.e. in case 3)\n\n\nCalibration measures how well predicted probabilities align with even rates. A model \\(f\\) is perfectly calibrated if for all values \\(0 \\leq \\alpha \\leq 1\\) that \\(f\\) obtains, we have that:\n\\[\n  E_{X,Y \\sim P(X,Y)}[Y|f(X)=\\alpha]=\\alpha.\n\\]\n\n\n\n\n\n\nTipCrucial insight:\n\n\n\nCalibration is a function of the distribution of the outcome given the features. This means that when \\(P(Y|X)\\) is the same across environments, so is the model’s calibration (i.e. in case 1)\n\n\nSo discrimination is stable when \\(P(X|Y)\\) is transportable and calibration is stable when \\(P(Y|X)\\) is transportable. Are they ever both? Using Bayes’ Theorem we have that:\n\\[\nP(Y|X) = P(X|Y) \\frac{P(Y)}{P(X)} \\equiv P(X|Y) = P(Y|X) \\frac{P(X)}{P(Y)}\n\\]\nClearly, if any of the right-hand sides is not transportable, then neither is the left-hand side.\n\n\n\n\n\n\nTipCrucial insight:\n\n\n\nCalibration and discrimination are never both stable across environments.1\n\n\nExcept for well-engineered counter examples.\n\n\nPutting it all together\nArmed with this knowledge, let’s go back to Table 1 with minimal changes in the joint distribution of \\(X\\) and \\(Y\\) across environments, and fill in what will happen with discrimination and calibration.\n\n\n\nTable 2: Discrimination and calibration under different changes in environment\n\n\n\n\n\ncase\ntransportable\ndiscrimination\ncalibration\n\n\n\n\n1\n\\(P(Y|X)\\)\n\nstable\n\n\n2\n\\(P(X)\\)\n\n\n\n\n3\n\\(P(X|Y)\\)\nstable\n\n\n\n4\n\\(P(Y)\\)\n\n\n\n\n\n\n\n\nNotice a pattern? Even under minimal changes between environments, at least diescrimination or calibration will change. So what happened in setting A? Given that both calibration and discrimination are stable, we can conclude that \\(P(X|Y)\\) and \\(P(Y|X)\\) are both transportable across the tested environments. The only logical conclusion is not that the model is robust against changes in environment, but that the testing environments were meaningfully different. In contrast, in setting B we have that discrimination is stable but calibration is not. We can deduce that \\(P(X|Y)\\) was transportable across environments, and \\(P(Y)\\) was not. The observed stable discrimination of the model gives confidence that even under meaningfully different environments, the model retains discrimination."
  },
  {
    "objectID": "posts/250425-robustness/index.html#roundup-tldr",
    "href": "posts/250425-robustness/index.html#roundup-tldr",
    "title": "What is stronger evidence of prediction model robustness?",
    "section": "Roundup / TLDR",
    "text": "Roundup / TLDR\nEnvironments must differ with respect to something. If the distribution of features given outcome remains the same (\\(X|Y\\)), discrimination is preserved, if the distribution of outcome given features remains the same (\\(Y|X\\)), calibration is preserved. If both are the same, the environments were not meaningfully different to begin with.\nA question that remains is how these differences in environments may come about, and what to with all this in practice. On this, I wrote a paper titled A causal viewpoint on prediction model performance under changes in case-mix: discrimination and calibration respond differently for prognosis and diagnosis predictions which you can find on ArXiv"
  },
  {
    "objectID": "posts/250425-robustness/index.html#footnotes",
    "href": "posts/250425-robustness/index.html#footnotes",
    "title": "What is stronger evidence of prediction model robustness?",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nCounter examples may be constructed. For example, say \\(P(Y|X)\\) follows a mixture of beta distributions with their modes at \\(\\mu_1 = 0.25\\) and \\(\\mu_2 = 0.75\\) in one environment. We’re shifting \\(P(X)\\) across environments, so \\(P(Y|X)\\) is transportable and calibration is stable. If in another environment we shift \\(\\mu_1\\) to 0, then AUC will go up; if we shift \\(\\mu_2\\) to 0.5 the AUC will go down. We can set \\(\\mu_1\\) and \\(\\mu_2\\) to carefully choose values so that the AUC remanins the same in the second environment.↩︎"
  },
  {
    "objectID": "posts/240322-mice-partial-residual-plot.html",
    "href": "posts/240322-mice-partial-residual-plot.html",
    "title": "Partial residual plots with multiply imputed data",
    "section": "",
    "text": "In an earlier blog post I show how to plot the dependence of a response variable on covariate, both conditional on other covariates with a partial residual plot In this post I investigate how to do this when there are missing values using package mice.\nThis post will rely in Hanne Oberman’s vignette on ggmice, a plotting package for mice::mids objects."
  },
  {
    "objectID": "posts/240322-mice-partial-residual-plot.html#data-and-imputation",
    "href": "posts/240322-mice-partial-residual-plot.html#data-and-imputation",
    "title": "Partial residual plots with multiply imputed data",
    "section": "Data and imputation",
    "text": "Data and imputation\nIn this post we’ll use the boys dataset which is provided in the mice package. The mice package implements multiple imputation through chained equations1.\n\nlibrary(mice)\nlibrary(ggplot2); theme_set(theme_bw())\n\ndf &lt;- boys\n\nnimps &lt;- 5\nimp &lt;- mice(df, m = nimps, method = \"pmm\")"
  },
  {
    "objectID": "posts/240322-mice-partial-residual-plot.html#partial-residual-plot-with-complete-data",
    "href": "posts/240322-mice-partial-residual-plot.html#partial-residual-plot-with-complete-data",
    "title": "Partial residual plots with multiply imputed data",
    "section": "Partial residual plot with complete data",
    "text": "Partial residual plot with complete data\nWe’ll assume we’re interested in how weight (wgt) depends on height (hgt), corrected for all other variables. Both have missing values in the dataset.\nWe can use one of the imputed datasets to show how partial residual plots are made with complete data. With complete data, partial residual plots can be created like so:\n\ndf1 &lt;- complete(imp, 1)\n\nget_partial_resid &lt;- function(data) {\n  fit &lt;- lm(wgt~., data=data)\n  yresid &lt;- resid(fit)\n  return(yresid + coef(fit)['hgt'] * data$hgt)\n}\n\nplotdata1 &lt;- data.frame(hgt=df1$hgt, y=get_partial_resid(df1))\n\nggplot(plotdata1, aes(x=hgt, y=y)) + geom_point()\n\n\n\n\n\n\n\nFigure 1: Partial residual plot on complete data\n\n\n\n\n\nNote how this differs from the marginal association between hgt and wgt. The difference between the plots is explained by other covariates that are correlated both with hgt and wgt.\n\nggplot(df1, aes(x=hgt, y=wgt)) + geom_point()\n\n\n\n\n\n\n\nFigure 2: marginal association between age and height"
  },
  {
    "objectID": "posts/240322-mice-partial-residual-plot.html#putting-them-together",
    "href": "posts/240322-mice-partial-residual-plot.html#putting-them-together",
    "title": "Partial residual plots with multiply imputed data",
    "section": "Putting them together",
    "text": "Putting them together\nThe issue with the partial residual plot Figure 1 is that the residuals depend on the imputed values for all variables. How to go about this? We can treat the residuals as we would ‘coefficients’ in imputation and use Rubin’s rules on them. Let’s see how to do this with mice.\n\nimpdfs &lt;- complete(imp, \"all\")\nimpdfs &lt;- lapply(impdfs, function(data) data.frame(data, partial_resid=get_partial_resid(data)))\nimpdfs &lt;- lapply(1:nimps, function(i) data.frame(impdfs[[i]], impidx=i))\nimpdf_long &lt;- do.call(rbind, impdfs)\n\nNote that we cannot directly pool the residuals because they may be correlated with the imputed values for hgt. Pooling imputed values for hgt and the partial residual removes this correlation. Instead we could just plot all the values.\n\nggplot(impdf_long, aes(x=hgt, y=partial_resid)) + geom_point(aes(shape=factor(impidx)), alpha=0.5)\n\n\n\n\n\n\n\nFigure 3: partial residual plot with imputed datasets\n\n\n\n\n\nIn the future I’d like to learn how to make good bivariate estimates of these points (e.g. fitting a bivariate normal distribution). This should for example also come up in calculating sensitivity and specificity on multiply imputed datasets, as these are clearly correlated. Fully bayesian imputation is another possibility obviously."
  },
  {
    "objectID": "posts/240322-mice-partial-residual-plot.html#footnotes",
    "href": "posts/240322-mice-partial-residual-plot.html#footnotes",
    "title": "Partial residual plots with multiply imputed data",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nmultiple imputation with chained equations sequentially imputes values for all variables with missing values by building prediction models for each variable based on other variables. This imputation is done multiple times with multiple random seeds and thus results in a number of different imputed datasets. A typical analysis workflow is to do these imputations and on each imputed dataset fit a model of interest. The coefficients of these models can then be pooled using Rubin’s rules.↩︎"
  },
  {
    "objectID": "posts/240607-jama-causal-language/index.html",
    "href": "posts/240607-jama-causal-language/index.html",
    "title": "Is the JAMA opening up their language for causal effects?",
    "section": "",
    "text": "Randomized controlled trials (RCTs) measure the causal effect of interventions, but results from observational studies should be interpreted as mere associations, right? In a great piece in the JAMA, Issa Dehabreh and Kirsten Bibbins-Domingo describe a framework with a more balanced view.\nBlack-and-white thinking about causal effects dictated medical research for a long time. But then, some not-so-well conducted RCTs (e.g. no blinding of outcome assessment, selective loss to follow-up, …) do not provide valid estimates of treatment effects. How can we distinguish the good ‘causal’ RCTs from the bad ones if the criterion for causality is whether a study is an RCT or not?\nIn the past decades the field of causal inference produced several principled definitions of causal effects and established requirements for a study to yield valid causal estimates (e.g. Pearl and Mackenzie 2018; Pearl 2009; Miguel A. Hernán and Robins 2020). According to these approaches, RCTs are clearly preferable for treatment effect estimation as in RCTs the requirements for estimating causal effects can be controlled experimentally. Unfortunately, some relevant questions are very hard to answer using RCTs because of logistical or ethical limitations. At the same time, the definitions of causal effects from causal inference imply that causal effects can be estimated outside of RCTs with observational data as well. Though for observational studies, causal estimates are only valid when specific assumptions are met and unfortunately these assumptions cannot be checked with the data, so caution is required. But clearly, the black-and-white RCT=causation and observational=association must be replaced with a more nuanced view.\nFor a long time, prestigious journals such as the Journal of the American Medical Association (JAMA) restricted the use of causal language (e.g. effect or efficacy) to reporting the primary results of RCTs (“Instructions for Authors | JAMA | JAMA Network” n.d.), further entrenching the black-and-white mindset and evoking criticism from causal inference researchers (e.g. Miguel A. Hernán 2018). Recently, the JAMA opened itself up for discussion on this topic with a very thoughtful publication by Issa Dehabreh and Kirsten Bibbins-Domingo (Dahabreh and Bibbins-Domingo 2024), accompanied by an editorial (Flanagin et al. 2024).\nAs a researcher in causal inference and machine learning for healthcare I think this a great step towards a more rational and balanced approach to distinghuising causal effects from assocations. This is much needed because causal effects teach us what to do, i.e. what interventions will lead to better patient outcomes. Opening up the language to better express causal research questions and analysis approaches combined with the ability to incorporate both well conducted RCTs and observational studies (mentioning the assumptions required for their estimates to have a causal interpretation) when evaluating interventions will lead to better evidence accumulation and ultimately better outcomes for patients.\n\n\n\n\n\n\n\n\n\nReferences\n\nDahabreh, Issa J., and Kirsten Bibbins-Domingo. 2024. “Causal Inference About the Effects of Interventions From Observational Studies in Medical Journals.” JAMA 331 (21): 1845–53. https://doi.org/10.1001/jama.2024.7741.\n\n\nFlanagin, Annette, Roger J. Lewis, Christopher C. Muth, and Gregory Curfman. 2024. “What Does the Proposed Causal Inference Framework for Observational Studies Mean for JAMA and the JAMA Network Journals?” JAMA 331 (21): 1812–13. https://doi.org/10.1001/jama.2024.8107.\n\n\nHernán, Miguel A. 2018. “The C-Word: Scientific Euphemisms Do Not Improve Causal Inference From Observational Data.” American Journal of Public Health 108 (5): 616–19. https://doi.org/10.2105/AJPH.2018.304337.\n\n\nHernán, Miguel A, and James M Robins. 2020. Causal Inference: What If. Boca Raton: Champan & Hall/CRC.\n\n\n“Instructions for Authors | JAMA | JAMA Network.” n.d. Accessed August 3, 2021. https://jamanetwork.com/journals/jama/pages/instructions-for-authors.\n\n\nPearl, Judea. 2009. Causality. Cambridge University Press.\n\n\nPearl, Judea, and Dana Mackenzie. 2018. The Book of Why: The New Science of Cause and Effect. 1st edition. New York: Basic Books.\n\nCitationBibTeX citation:@online{van_amsterdam2024,\n  author = {van Amsterdam, Wouter},\n  title = {Is the {JAMA} Opening up Their Language for Causal Effects?},\n  date = {2024-06-07},\n  url = {https://vanamsterdam.github.io/posts/240607-jama-causal-language/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nAmsterdam, Wouter van. 2024. “Is the JAMA Opening up Their\nLanguage for Causal Effects?” June 7, 2024. https://vanamsterdam.github.io/posts/240607-jama-causal-language/."
  },
  {
    "objectID": "posts/210720-good_predictions_bad_decisions.html",
    "href": "posts/210720-good_predictions_bad_decisions.html",
    "title": "When good predictions lead to bad decisions",
    "section": "",
    "text": "A common premise in prediction research for clinical outcomes is that better predictions lead to better (informed) decisions. This causal statement, that the intervention of introducing a new prediction rule leads to better decisions and thus better outcomes, is generally not substantiated with sufficient causal arguments. We now present an example where naively introducing a validated new prediction rule can lead to worse clinical decisions.\nFor a certain cancer type there are two treatment options: treatment A and treatment B. From randomized trials, it is known that treatment A is more effective in treating the tumor than treatment B. There is no known variation of treatment effect among subgroups defined by clinical patient characteristics. However, not all patients respond well to treatment. Treatment A is a longer and more intensive treatment regimen than treatment B and leads to more side-effects. The consensus is that it is unethical to give treatment A to patients with a lower than 10% chance of surviving one year, due to the higher risk of side-effects and the lengthy treatment regimen associated with treatment A. In current clinical practice, the probability of 1-year survival is estimated using clinical characteristics. A new research group tries to improve the 1-year survival predictions using a new biomarker. The research endeavor is a success as it turns out that predicting survival with the clinical characteristics and the new biomarker is significantly more accurate than using only the clinical characteristics. A high value for the biomarker is associated with worse overall survival. Having conducted a predictive study, it is not discovered that the treatment effect of treatment A versus B is actually more in favor of treatment A for patients with higher levels of the biomarker. If the new prediction rule would be implemented naively with the same 10% cut-off for 1-year overall survival, this would lead to worse treatment decisions than without using the new prediction model. Some patients with high biomarker values will fall under the 10% cut-off based on the new biomarker, while without the biomarker they would have had a higher than 10% survival probability. This erroneously leads to not recommending treatment A, even though these patients have a high benefit of treatment A.\nNote that this is not an unreasonable example for cancer, as aggressive / fast-growing cancers tend to respond better to treatments like chemotherapy and radiotherapy. One example is non-seminoma versus seminoma testicular cancer."
  },
  {
    "objectID": "posts/210720-good_predictions_bad_decisions.html#defining-the-policies",
    "href": "posts/210720-good_predictions_bad_decisions.html#defining-the-policies",
    "title": "When good predictions lead to bad decisions",
    "section": "Defining the policies",
    "text": "Defining the policies\nThe current clinical policy is:\n\\[\\pi_0(x) = \\mathbf{I}_{E[y|x] &gt; 0}\\]\nSo we should give treatment \\(t=1\\) whenever the expected outcome exceeds the reference cut-off. Let the true data generating mechanism be as following:\n\\[y = \\beta z t + x - z\\]\nAs \\(y\\) is a deterministic function of \\(t,x,z\\), we drop the expectation symbol in the following discussion. Let \\(x,z \\sim \\mathbf{U}(-1,1)\\) be independent variables following a uniform distribution between -1 and 1. We can new express the baseline policy as \\[\\pi_0(x) = \\mathbf{I}_{y|x &gt; 0} = \\mathbf{I}_{E_{z}[y|x,z]&gt;0} \\iff \\mathbf{I}_{x &gt; 0}\\]\nA naive implementation of the new prediction rule incorporating \\(z\\) would lead to the policy \\(\\pi_z(x,z) = \\mathbf{I}_{y|x,z &gt; 0}\\). Plugging in the data generating mechanism we can identify\n\\[\\begin{aligned}\n  y|x,z &= E_{t \\sim \\pi_0(x)}[y|t,x,z] \\\\\n    &= E_{t \\sim \\pi_0(x)}[\\beta z t + x - z] \\\\\n    &= \\beta z E_{t \\sim \\pi_0(x)} [t] + x - z \\\\\n    &= \\beta z E_x [\\mathbf{I}_{x &gt; 0}] + x - z \\\\\n    &= 0.5 \\beta z  + x - z \\\\\n    &= x - (1 - 0.5 \\beta)z\\end{aligned}\\]\nThus \\(\\pi_z(x,z) = \\mathbf{I}_{x + (0.5 \\beta - 1)z &gt; 0}\\).\nFrom the data generating mechanism it is clear that the conditional average treatment effect reduces to\n\\[\\begin{aligned}\n  \\text{CATE(x,z)} &= E[y|\\text{do}(t=1),x,z] - E[y|\\text{do}(t=0),x,z] \\\\\n                   &= \\beta z - 0\\end{aligned}\\]\nThe policy that maximizes the outcome \\(y\\) is \\(\\pi_{\\text{max}(y)}(z) = \\mathbf{I}_{z &gt; 0}\\) as \\(\\text{do}(t=1)\\) leads to better outcomes if and only if \\(z&gt;0\\). To conform with the ethical consensus that the intensive treatment is justified when \\(y|\\text{do}(t),x,z&gt;0\\), we set\n\\[\\begin{aligned}\n    \\pi^*(x,z) &= \\mathbf{I}_{y|\\text{do}(t=1),x,z &gt; 0} \\\\\n           &= \\mathbf{I}_{\\beta z * 1 + x - z &gt; 0} \\\\\n           &= \\mathbf{I}_{x + (\\beta - 1) z &gt; 0}\\end{aligned}\\]"
  },
  {
    "objectID": "posts/210720-good_predictions_bad_decisions.html#expected-utility-of-different-policies",
    "href": "posts/210720-good_predictions_bad_decisions.html#expected-utility-of-different-policies",
    "title": "When good predictions lead to bad decisions",
    "section": "Expected utility of different policies",
    "text": "Expected utility of different policies\nWe can now calculate the expected utility of the different policies \\(\\pi \\in \\{\\pi_0,\\pi_z,\\pi_{\\text{max}(y)},\\pi^*\\}\\) as the expected outcome, \\(U(\\pi) = E_{x,z}E_{t\\sim \\pi(x,z)}y|t,x,z = E_{x,z}\\beta z \\pi(x,z) + x - z\\). The calculation of these expected utilities depends on the treatment effect, which will we assume to be \\(\\beta = 1.5\\). We will use the marginal indepence of \\(x\\) and \\(z\\) to equate \\(E_{x,z}[.] = E_z E_x [.]\\).\n\\[\\begin{aligned}\n    U(\\pi_0) &= E_z E_x [\\beta z \\mathbf{I}_{x &gt; 0} + x - z] \\\\\n         &= \\beta E_z z E_x \\mathbf{I}_{x&gt;0} \\\\\n         &= \\beta E_z z 0.5 \\\\\n         &= 0\\end{aligned}\\]\nWe have \\(\\pi_z(x,z) = \\mathbf{I}_{x - (1 - 0.5 \\beta)z &gt; 0} = \\mathbf{I}_{x &gt; 0.25z}\\)\n\\[\\begin{aligned}\n    U(\\pi_z) &= E_z E_x [\\beta z \\mathbf{I}_{x &gt; 0.25z} + x - z] \\\\\n         &= \\beta E_z z E_x \\mathbf{I}_{x &gt; 0.25z} \\\\\n         &= \\beta E_z z \\text{Pr}(x &gt; 0.25z) \\\\\n         &=^1 \\frac{\\beta}{2} \\int_{-1}^{1} z \\text{Pr}(x &gt; 0.25z) dz\\\\\n         &=^2 \\frac{\\beta}{2} \\int_{-1}^{1} z (1 - \\frac{0.25z+1}{2}) dz\\\\\n         &= \\frac{\\beta}{4} \\int_{-1}^{1} z (1 - 0.25z)dz \\\\\n         &= \\frac{\\beta}{4} \\left[ \\frac{1}{2} z^2 - \\frac{0.25}{3}z^3 + C \\right]_{-1}^1 \\\\\n         &= \\frac{\\beta}{4} \\left( ( \\frac{1}{2} - \\frac{0.25}{3}) - ( \\frac{1}{2} + \\frac{0.25}{3}) \\right) \\\\\n         &= - \\frac{\\beta}{2} \\frac{0.25}{3} \\\\\n         &= - 0.075\\end{aligned}\\]\nWhere in \\(^1\\) we used the \\(U(-1,1)\\) distribution of \\(z\\) and in \\(^2\\) we used the probability density function of \\(x\\) and the fact that \\(-1 &lt; 0.25z &lt; 1\\). This demonstrates that the policy following the (accurate!) prediction model \\(y|x,z\\) leads to worse clinical outcomes than the previous situation that relied on \\(x\\) only.\nThe reader may verify that \\[\\begin{aligned}\n    U(\\pi_{\\text{max}(y)}) &= 0.375 \\\\\n    U(\\pi^*) &= 0.125\\end{aligned}\\]"
  },
  {
    "objectID": "unlisted.html",
    "href": "unlisted.html",
    "title": "Unlisted pages",
    "section": "",
    "text": "Order By\n      Default\n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Title\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\n\nTitle\n\n\n\nSubtitle\n\n\n\n\n\n\n\n\nDec 1, 2025\n\n\nCausality in Prediction Research & Target Trial Emulation\n\n\nAI methods lab seminar\n\n\n\n\n\n\nOct 27, 2025\n\n\nCausal Inference for AI meetup\n\n\nRotterdam / Leiden / Delft / Utrecht\n\n\n\n\n\n\nAug 14, 2025\n\n\nBuilding and evaluating AI for deployment: evidence before and after\n\n\nMLHC pre-conference workshop 2025\n\n\n\n\n\n\nAug 14, 2025\n\n\nAligning development, deployment and monitoring for AI: a causal perspective\n\n\nMLHC pre-conference workshop 2025\n\n\n\n\n\n\nJul 13, 2025\n\n\nPROTECT update\n\n\nManchester / Rajesh\n\n\n\n\n\n\nMay 7, 2025\n\n\nEffect Measure Stability\n\n\n \n\n\n\n\n\n\nSep 23, 2022\n\n\nCausal Inference for AI meetup\n\n\nRotterdam / Leiden / Delft / Utrecht\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "talks/250417-ads-sigs/index.html#what-is-causality",
    "href": "talks/250417-ads-sigs/index.html#what-is-causality",
    "title": "Causal Data Science in Utrecht: causality for prediction model generalization",
    "section": "What is causality?",
    "text": "What is causality?\n\n\n\n\nPrediction:\n“What to expect when we passively observe the world”\n\n\nCausality:\n“What to expect when we actively intervene”"
  },
  {
    "objectID": "talks/250825-iscb-causal-prediction/index.html#using-medical-information-predict-10-year-heart-attack-risk",
    "href": "talks/250825-iscb-causal-prediction/index.html#using-medical-information-predict-10-year-heart-attack-risk",
    "title": "From prediction to treatment decision: aligning development, evaluation and monitoring",
    "section": "Using medical information, predict 10-year heart attack risk",
    "text": "Using medical information, predict 10-year heart attack risk"
  },
  {
    "objectID": "talks/250825-iscb-causal-prediction/index.html#from-an-ecg-predict-presence-of-heart-failure-typically-diagnosed-with-cardiac-echo",
    "href": "talks/250825-iscb-causal-prediction/index.html#from-an-ecg-predict-presence-of-heart-failure-typically-diagnosed-with-cardiac-echo",
    "title": "From prediction to treatment decision: aligning development, evaluation and monitoring",
    "section": "from an ECG, predict presence of heart failure (typically diagnosed with cardiac echo)",
    "text": "from an ECG, predict presence of heart failure (typically diagnosed with cardiac echo)"
  },
  {
    "objectID": "talks/250825-iscb-causal-prediction/index.html#predictive-performance-measures",
    "href": "talks/250825-iscb-causal-prediction/index.html#predictive-performance-measures",
    "title": "From prediction to treatment decision: aligning development, evaluation and monitoring",
    "section": "Predictive performance measures",
    "text": "Predictive performance measures\n\n\n\nsensitivity, specificity\nAUC\naccuracy\ncalibration"
  },
  {
    "objectID": "talks/250825-iscb-causal-prediction/index.html#year-heart-attack-risk-hippisley-coxdevelopmentvalidationnew2024",
    "href": "talks/250825-iscb-causal-prediction/index.html#year-heart-attack-risk-hippisley-coxdevelopmentvalidationnew2024",
    "title": "From prediction to treatment decision: aligning development, evaluation and monitoring",
    "section": "10 year heart attack risk (Hippisley-Cox et al. 2024)",
    "text": "10 year heart attack risk (Hippisley-Cox et al. 2024)\n\nprediction: heart attack in 10 years\nintervention: prescribe cholesterol lowering medication\noutcome: heart attack\noutcome (impact): reduce heart attacks"
  },
  {
    "objectID": "talks/250825-iscb-causal-prediction/index.html#predict-presence-of-heart-failure-from-ecg-yaoartificialintelligenceenabled2021",
    "href": "talks/250825-iscb-causal-prediction/index.html#predict-presence-of-heart-failure-from-ecg-yaoartificialintelligenceenabled2021",
    "title": "From prediction to treatment decision: aligning development, evaluation and monitoring",
    "section": "Predict presence of heart failure from ECG (Yao et al. 2021)",
    "text": "Predict presence of heart failure from ECG (Yao et al. 2021)\n\nprediction: heart failure\nintervention: refer patient for cardiac echo\noutcome: diagnosis of heart failure on echo\noutcome (impact): reduce preventable early cardiac death / morbidity"
  },
  {
    "objectID": "talks/250825-iscb-causal-prediction/index.html#predictive-performance-vs-impact",
    "href": "talks/250825-iscb-causal-prediction/index.html#predictive-performance-vs-impact",
    "title": "From prediction to treatment decision: aligning development, evaluation and monitoring",
    "section": "Predictive performance vs impact",
    "text": "Predictive performance vs impact\n\n\npredictive performance\n\nsensitivity, specificity\nAUC\naccuracy\ncalibration\n\n\nhealthcare impact\n\ninterventions (medical decisions)\npatient outcomes\n\n\n\nthe hope is: better predictive performance \\(\\implies\\) better impact\nunfortunately, this is not automatically the case"
  },
  {
    "objectID": "talks/250825-iscb-causal-prediction/index.html#what-happened-here",
    "href": "talks/250825-iscb-causal-prediction/index.html#what-happened-here",
    "title": "From prediction to treatment decision: aligning development, evaluation and monitoring",
    "section": "What happened here?",
    "text": "What happened here?\n\nhad a ‘good’ model, got a bad policy\nmodel predicted outcome (survival) under historic treatment policy (always radiation)\ndid not predict what outcomes would be under alternative policy (no radiation)\nin this case, unmodeled treatment effect heterogeneity (aka treatment effect modification, interation, differing conditional average treatment effects)"
  },
  {
    "objectID": "talks/250825-iscb-causal-prediction/index.html#regulation-to-the-rescue-we-need-to-monitor-ai-models",
    "href": "talks/250825-iscb-causal-prediction/index.html#regulation-to-the-rescue-we-need-to-monitor-ai-models",
    "title": "From prediction to treatment decision: aligning development, evaluation and monitoring",
    "section": "Regulation to the rescue: we need to monitor (AI) models",
    "text": "Regulation to the rescue: we need to monitor (AI) models"
  },
  {
    "objectID": "talks/250825-iscb-causal-prediction/index.html#lets-monitor-the-model-performance-over-time",
    "href": "talks/250825-iscb-causal-prediction/index.html#lets-monitor-the-model-performance-over-time",
    "title": "From prediction to treatment decision: aligning development, evaluation and monitoring",
    "section": "Let’s monitor the model performance over time",
    "text": "Let’s monitor the model performance over time"
  },
  {
    "objectID": "talks/250825-iscb-causal-prediction/index.html#what-happened-in-monitoring",
    "href": "talks/250825-iscb-causal-prediction/index.html#what-happened-in-monitoring",
    "title": "From prediction to treatment decision: aligning development, evaluation and monitoring",
    "section": "What happened in monitoring?",
    "text": "What happened in monitoring?\n\nthe model re-inforced its own predictions (self-fulfilling prophecy)\ntook a measure of predictive performance (AUC)\nmistook it for a measure of (good) impact\nmany potential examples (e.g. ICU stop treatment (Balcarcel et al. 2025), others (Center n.d.))"
  },
  {
    "objectID": "talks/250825-iscb-causal-prediction/index.html#when-predicting-an-outcome-to-support-decisions-regarding-an-intervention",
    "href": "talks/250825-iscb-causal-prediction/index.html#when-predicting-an-outcome-to-support-decisions-regarding-an-intervention",
    "title": "From prediction to treatment decision: aligning development, evaluation and monitoring",
    "section": "When predicting an outcome to support decisions regarding an intervention,",
    "text": "When predicting an outcome to support decisions regarding an intervention,\nthis prediction needs a clear relationship with the targeted intervention (van Amsterdam et al. 2024)\n\n\n\nHilden and Habbema on prognosis (Hilden and Habbema 1987)\n\n\n“Prognosis cannot be divorced from contemplated medical action, nor from action to be taken by the patient in response to prognostication.”\n\n\n\n\nnot: what’s risk of heart attack given age and cholesterol,\nbut: what’s risk of heart attack given age and cholesterol, if we were not to give cholesterol lowering medication (vs. if we would)\nmay sound like \\(1+1=2\\) but often not done; e.g. in the development data of Qrisk3, many patients already underwent cholesterol lowering medication (Peek, Sperrin, and van Staa 2017)"
  },
  {
    "objectID": "talks/250825-iscb-causal-prediction/index.html#prediction-under-hypothetical-intervention-incorporates-effects-of-treatment-in-its-predictions",
    "href": "talks/250825-iscb-causal-prediction/index.html#prediction-under-hypothetical-intervention-incorporates-effects-of-treatment-in-its-predictions",
    "title": "From prediction to treatment decision: aligning development, evaluation and monitoring",
    "section": "Prediction under hypothetical intervention incorporates effects of treatment in its predictions",
    "text": "Prediction under hypothetical intervention incorporates effects of treatment in its predictions\n\nestimates the expected outcome \\(Y\\)\n\nif we were to give treatment \\(T\\) to patient with features \\(X\\)\n\na.k.a. ‘counterfactual prediction’\ncan predict outcomes under multiple treatments, where one treatment may be ‘no (additional) treatment / standard treatment’"
  },
  {
    "objectID": "talks/250825-iscb-causal-prediction/index.html#how-to-build-prediction-under-intervention-models",
    "href": "talks/250825-iscb-causal-prediction/index.html#how-to-build-prediction-under-intervention-models",
    "title": "From prediction to treatment decision: aligning development, evaluation and monitoring",
    "section": "How to build prediction under intervention models?",
    "text": "How to build prediction under intervention models?\n\nin its simplest form, can be just like fitting any other predictive model, as long as causal identifyability assumptions are fulfilled:\n\nunconfoundedness (no hidden variables causing both the intervention and the outcome)\npositivity, consistency\n\nthese hold by design in Randomized Controlled Trials (RCT)\nRCTs are in that sense ideal (e.g. Kent et al. 2020), but:\n\ntypically limited sample size\nmay not have measured right information (e.g. imaging markers, new biomarkers, full-EHR)\ntrial participants may not be representative of the target population of use (e.g. Lewis et al. 2003)\n\ncan emulate RCTs with non-experimental (observational) data using a causal inference framework, e.g. using target trial emulation"
  },
  {
    "objectID": "talks/250825-iscb-causal-prediction/index.html#benefits-of-prediction-under-intervention",
    "href": "talks/250825-iscb-causal-prediction/index.html#benefits-of-prediction-under-intervention",
    "title": "From prediction to treatment decision: aligning development, evaluation and monitoring",
    "section": "Benefits of prediction under intervention",
    "text": "Benefits of prediction under intervention\n\npolicy rule: if expected outcome under treatment \\(A\\) is better than under treatment \\(B\\) (potentially by a certain margin), give treatment \\(A\\), otherwise \\(B\\)\nas opposed to other prediction models, this policy has foreseable positive impact on health outcomes"
  },
  {
    "objectID": "talks/250825-iscb-causal-prediction/index.html#benefits-of-prediction-under-intervention-1",
    "href": "talks/250825-iscb-causal-prediction/index.html#benefits-of-prediction-under-intervention-1",
    "title": "From prediction to treatment decision: aligning development, evaluation and monitoring",
    "section": "Benefits of prediction under intervention",
    "text": "Benefits of prediction under intervention\n\npolicy rule: if expected outcome under treatment \\(A\\) is better than under treatment \\(B\\) (potentially by a certain margin), give treatment \\(A\\), otherwise \\(B\\)\nas opposed to other prediction models, this policy has foreseable positive impact on health outcomes\nas a ‘bonus’, these models have stable calibration under shifts in policy that depend on the models’ features (e.g. Feng et al. 2024)"
  },
  {
    "objectID": "talks/250825-iscb-causal-prediction/index.html#measuring-pre--and-post-deployment",
    "href": "talks/250825-iscb-causal-prediction/index.html#measuring-pre--and-post-deployment",
    "title": "From prediction to treatment decision: aligning development, evaluation and monitoring",
    "section": "Measuring pre- and post-deployment",
    "text": "Measuring pre- and post-deployment\n\n\n\n\n\npre-deploy\ndeployment study\n\n\n\n\n\nmetric\n\n\n\n\nmodel\ndiscrimination (AUC)\n✅\n\n\n\n\ncalibration\n✅\n\n\n\nhealth system\ninterventions\n✅\n\n\n\n\npatient outcomes\n✅\n\n\n\n\nLegend\n🔁 changes ✅ stable 🔻 worsens"
  },
  {
    "objectID": "talks/250825-iscb-causal-prediction/index.html#measuring-pre--and-post-deployment-1",
    "href": "talks/250825-iscb-causal-prediction/index.html#measuring-pre--and-post-deployment-1",
    "title": "From prediction to treatment decision: aligning development, evaluation and monitoring",
    "section": "Measuring pre- and post-deployment",
    "text": "Measuring pre- and post-deployment\n\n\n\n\n\npre-deploy\npost-deploy\n\n\n\n\n\nmetric\n\n\n\n\nmodel\ndiscrimination (AUC)\n✅\n🔁\n\n\n\ncalibration\n✅\n🔻\n\n\nhealth system\ninterventions\n✅\n🔁\n\n\n\npatient outcomes\n✅\n🔁\n\n\n\nLegend\n🔁 changes ✅ stable 🔻 worsens\n\nfor ‘non-causal’ prognosis prediction models that don’t factor in treatment decisions:\n\nAUC will change, calibration will worsen as distribution changes\ninterventions and patient outcomes may change in unforeseen ways"
  },
  {
    "objectID": "talks/250825-iscb-causal-prediction/index.html#measuring-pre--and-post-deployment-2",
    "href": "talks/250825-iscb-causal-prediction/index.html#measuring-pre--and-post-deployment-2",
    "title": "From prediction to treatment decision: aligning development, evaluation and monitoring",
    "section": "Measuring pre- and post-deployment",
    "text": "Measuring pre- and post-deployment\n\n\n\n\n\n\n\n\n\n\n\n\npre-deploy\n‘non-causal’\n‘causal’\n\n\n\n\n\nmetric\n\n\n\n\n\nmodel\ndiscrimination (AUC)\n✅\n🔁\n🔁\n\n\n\ncalibration\n✅\n🔻\n✅\n\n\nhealth system\ninterventions\n✅\n🔁\n📈\n\n\n\npatient outcomes\n✅\n🔁\n📈\n\n\n\nLegend\n🔁 changes ✅ stable 🔻 worsens 📈 changes in expected way\n\nfor prediction under intervention model\n\ncalibration preserved under shifts in policy conditional on the model’s features\ninterventions and outcomes change in foreseeable ways (under assumption on policy)"
  },
  {
    "objectID": "talks/250825-iscb-causal-prediction/index.html#current-status",
    "href": "talks/250825-iscb-causal-prediction/index.html#current-status",
    "title": "From prediction to treatment decision: aligning development, evaluation and monitoring",
    "section": "Current status",
    "text": "Current status\n\nreporting guidelines (e.g. TRIPOD+AI / PROBAST+AI (Collins et al. 2024; Moons et al. 2025)) do not require a clear enoough description of relation between prediction and treatment (“Prognostic Models for Decision Support Need to Report Their Targeted Treatments and the Expected Changes in Treatment Decisions” 2024)\nsome acceptance criteria lists (AJCC) even allow for harmful self-fulfilling prophecies (Kattan et al. 2016)\nEMA and FDA are developing monitoring guidelines, mostly emphasis on predictive performance, but good performance \\(\\neq\\) postive impact"
  },
  {
    "objectID": "talks/250825-iscb-causal-prediction/index.html#takeaways",
    "href": "talks/250825-iscb-causal-prediction/index.html#takeaways",
    "title": "From prediction to treatment decision: aligning development, evaluation and monitoring",
    "section": "Takeaways",
    "text": "Takeaways\n\nwhen predicting prognosis, need well defined relation between prediction and potential treatment decisions\nin particular, prediction under intervention has the advantages of:\n\nclear relationship between model performance and value for decision making\nstable calibration under shifts in treatment policy, conditional on the model’s features\n\nthese models need unconfoundedness, so either\n\ndevelop using RCT data\nuse observational causal inference\n\nevaluate and monitor prediction models based on what we care about: impact on healthcare"
  },
  {
    "objectID": "talks/250825-iscb-causal-prediction/index.html#references",
    "href": "talks/250825-iscb-causal-prediction/index.html#references",
    "title": "From prediction to treatment decision: aligning development, evaluation and monitoring",
    "section": "References",
    "text": "References\n\n\n\n\nAmsterdam, W.A. C. van, Giovanni Cinà, Vanessa Didelez, Ruth H. Keogh, Niels Peek, Matthew Sperrin, Andrew J. Vickers, Nan van Geloven, and Uri Shalit. 2024. “Prognostic Models for Decision Support Need to Report Their Targeted Treatments and the Expected Changes in Treatment Decisions [Rapid Response].” BMJ, May. https://doi.org/10.1136/bmj-2023-078378/rr-1.\n\n\nBalcarcel, Daniel R, Sanjiv D Mehta, Celeste G Dixon, Charlotte Z Woods-Hill, Ewan C Goligher, Wouter A C Van Amsterdam, and Nadir Yehya. 2025. “Feedback Loops in Intensive Care Unit Prognostic Models: An Under-Recognised Threat to Clinical Validity.” The Lancet Digital Health, July, 100880. https://doi.org/10.1016/j.landig.2025.100880.\n\n\nCenter, Science Media. n.d. “Expert Reaction to Study Suggesting Potential Patient Harms Associated with Use of AI Medical Outcome-Prediction Models | Science Media Centre.” Accessed August 12, 2025. https://www.sciencemediacentre.org/expert-reaction-to-study-suggesting-potential-patient-harms-associated-with-use-of-ai-medical-outcome-prediction-models/.\n\n\nCollins, Gary S., Karel G. M. Moons, Paula Dhiman, Richard D. Riley, Andrew L. Beam, Ben Van Calster, Marzyeh Ghassemi, et al. 2024. “TRIPOD+AI Statement: Updated Guidance for Reporting Clinical Prediction Models That Use Regression or Machine Learning Methods.” BMJ 385 (April): e078378. https://doi.org/10.1136/bmj-2023-078378.\n\n\nFeng, Jean, Alexej Gossmann, Gene A. Pennello, Nicholas Petrick, Berkman Sahiner, and Romain Pirracchio. 2024. “Monitoring Machine Learning-Based Risk Prediction Algorithms in the Presence of Performativity.” In Proceedings of The 27th International Conference on Artificial Intelligence and Statistics, 919–27. PMLR. https://proceedings.mlr.press/v238/feng24b.html.\n\n\nHilden, Jørgen, and J. Dik F. Habbema. 1987. “Prognosis in Medicine: An Analysis of Its Meaning and Rôles.” Theoretical Medicine 8 (3): 349–65. https://doi.org/10.1007/BF00489469.\n\n\nHippisley-Cox, Julia, Carol A. C. Coupland, Mona Bafadhel, Richard E. K. Russell, Aziz Sheikh, Peter Brindle, and Keith M. Channon. 2024. “Development and Validation of a New Algorithm for Improved Cardiovascular Risk Prediction.” Nature Medicine, April. https://doi.org/10.1038/s41591-024-02905-y.\n\n\nKattan, Michael W., Kenneth R. Hess, Mahul B. Amin, Ying Lu, Karl G. M. Moons, Jeffrey E. Gershenwald, Phyllis A. Gimotty, et al. 2016. “American Joint Committee on Cancer Acceptance Criteria for Inclusion of Risk Models for Individualized Prognosis in the Practice of Precision Medicine.” CA: A Cancer Journal for Clinicians 66 (5): 370–74. https://doi.org/10.3322/caac.21339.\n\n\nKent, David M., Jessica K. Paulus, David van Klaveren, Ralph D’Agostino, Steve Goodman, Rodney Hayward, John P. A. Ioannidis, et al. 2020. “The Predictive Approaches to Treatment Effect Heterogeneity (PATH) Statement.” Annals of Internal Medicine 172 (1): 35–45. https://doi.org/10.7326/M18-3667.\n\n\nLewis, Joy H., Meredith L. Kilgore, Dana P. Goldman, Edward L. Trimble, Richard Kaplan, Michael J. Montello, Michael G. Housman, and José J. Escarce. 2003. “Participation of Patients 65 Years of Age or Older in Cancer Clinical Trials.” Journal of Clinical Oncology 21 (7): 1383–89. https://doi.org/10.1200/JCO.2003.08.010.\n\n\nMoons, Karel G. M., Johanna A. A. Damen, Tabea Kaul, Lotty Hooft, Constanza Andaur Navarro, Paula Dhiman, Andrew L. Beam, et al. 2025. “PROBAST+AI: An Updated Quality, Risk of Bias, and Applicability Assessment Tool for Prediction Models Using Regression or Artificial Intelligence Methods.” BMJ 388 (March): e082505. https://doi.org/10.1136/bmj-2024-082505.\n\n\nPeek, Niels, Matthew Sperrin, and Tjeerd van Staa. 2017. “Hari Seldon, QRISK3, and the Prediction Paradox.” BMJ 2017;357:j2099, May. https://doi.org/10.1136/bmj.j2099.\n\n\n“Prognostic Models for Decision Support Need to Report Their Targeted Treatments and the Expected Changes in Treatment Decisions.” 2024, December. https://www.bmj.com/content/385/bmj-2023-078378/rr-1.\n\n\nVan Amsterdam, Wouter A. C., Nan Van Geloven, Jesse H. Krijthe, Rajesh Ranganath, and Giovanni Cinà. 2025. “When Accurate Prediction Models Yield Harmful Self-Fulfilling Prophecies.” Patterns 6 (4): 101229. https://doi.org/10.1016/j.patter.2025.101229.\n\n\nYao, Xiaoxi, David R. Rushlow, Jonathan W. Inselman, Rozalina G. McCoy, Thomas D. Thacher, Emma M. Behnken, Matthew E. Bernard, et al. 2021. “Artificial Intelligence–Enabled Electrocardiograms for Identification of Patients with Low Ejection Fraction: A Pragmatic, Randomized Clinical Trial.” Nature Medicine 27 (5): 815–19. https://doi.org/10.1038/s41591-021-01335-4."
  },
  {
    "objectID": "talks/250814-mlhc-workshop/index.html#welcome-to-the-workshop",
    "href": "talks/250814-mlhc-workshop/index.html#welcome-to-the-workshop",
    "title": "Building and evaluating AI for deployment: evidence before and after",
    "section": "Welcome to the workshop!",
    "text": "Welcome to the workshop!\nOrganizers - Workshop Chairs MLHC 2025\n\n\n\n\n\n\nUri Shalit\n\n\nVisiting Researcher, Google DeepMind\nAssociate Professor, Tel Aviv University\n\n\n\n\nWouter van Amsterdam\n\n\nAssistant Professor, University Medical Center Utrecht, Netherlands"
  },
  {
    "objectID": "talks/250814-mlhc-workshop/index.html#why-are-we-here",
    "href": "talks/250814-mlhc-workshop/index.html#why-are-we-here",
    "title": "Building and evaluating AI for deployment: evidence before and after",
    "section": "Why are we here?",
    "text": "Why are we here?\n\nAI is changing healthcare\npre deployment, need the right evidence to know AI will improve healthcare\npost deployment, ‘things will change’, how do we know the AI is still performing (in terms of impact on healthcare) as expected?\nFDA and EMA (and others) are developing regulations\nnot all questions resolved, maybe we can help"
  },
  {
    "objectID": "talks/250814-mlhc-workshop/index.html#morning-schedule",
    "href": "talks/250814-mlhc-workshop/index.html#morning-schedule",
    "title": "Building and evaluating AI for deployment: evidence before and after",
    "section": "Morning schedule",
    "text": "Morning schedule\n9-12am: focus talks, 30 minutes each\n\nWouter van Amsterdam - Aligning development, deployment and monitoring for AI: a causal perspective\nDavid Kent - Evaluating prediction models in practice\nAnna Goldenberg - to Trial or not to Trial?\n\n10.30-11.00: coffee break\n\nMohammad Mamdani - Application and Evaluation of AI in Healthcare\nJean Feng - Monitoring clinical AI: Where are we now and where do we want to be?\n\n12.00-12.30: Plenary Discussion\n12.30 - 13.30: Lunch"
  },
  {
    "objectID": "talks/250814-mlhc-workshop/index.html#afternoon-schedule",
    "href": "talks/250814-mlhc-workshop/index.html#afternoon-schedule",
    "title": "Building and evaluating AI for deployment: evidence before and after",
    "section": "Afternoon schedule",
    "text": "Afternoon schedule\n\n13:30: group work; work on questions, draft manuscripts\n16:00-16:45: groups present ideas\n16:45-17:00: wrap-up\n\n\nGoal of workshop:\n\nidentify pressing questions that we can answer / work on, potentially start drafting follow-up work"
  },
  {
    "objectID": "talks/250814-mlhc-workshop/index.html#references",
    "href": "talks/250814-mlhc-workshop/index.html#references",
    "title": "Building and evaluating AI for deployment: evidence before and after",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#use-ai-for-medical-imaging",
    "href": "talks/240708-imaging-ailab/index.html#use-ai-for-medical-imaging",
    "title": "Medical imaging and AI for decision support",
    "section": "Use AI for medical imaging",
    "text": "Use AI for medical imaging\nto make healthcare easier or more efficient\n\nAcquisition (\\(S \\to X\\))\n\n\nk-space to MRI image\nraw projection data to CT image\n\n\ndetection / segmentation (\\(X \\to X\\))\n\n\nsegmenting organs at risk in radiotherapy\n\n\ninference / diagnosis (\\(X \\to D\\), both at prediction time)\n\n\nmedical diagnosis\npsuedo CT from MRI"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#use-ai-for-medical-imaging-1",
    "href": "talks/240708-imaging-ailab/index.html#use-ai-for-medical-imaging-1",
    "title": "Medical imaging and AI for decision support",
    "section": "Use AI for medical imaging",
    "text": "Use AI for medical imaging\nto make healthcare better (improve decisions)\n\nprognosis (\\(X \\to Y\\), \\(Y\\) in the future)\n\n\nexpected survival time given CT-scan\n\n\ntreatment effect (\\(X\\) determines effect of a treatment \\(T\\) on outcome \\(Y\\) in the future)"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#ai-treatment-effect",
    "href": "talks/240708-imaging-ailab/index.html#ai-treatment-effect",
    "title": "Medical imaging and AI for decision support",
    "section": "Why would you estimate treatment effects based on images?",
    "text": "Why would you estimate treatment effects based on images?\n\n\ntreatments have different effects on patients based on their (disease) characteristics\nfor example, whether tamoxifen increases survival for breast cancer patients depends on whether their tumor is hormone sensitive\nsome characteristics may be well captured in medical imaging:\n\nT-cell distributions around tumors related to effect of immunotherapy in cancer\nheterogeneity of tumor on CT may predict response to radiotherapy\nholistic view of ‘body composition’ on CT-scans determines whether patient can tolerate chemotherapy"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#how-to-estimate-treatment-effects-based-on-images",
    "href": "talks/240708-imaging-ailab/index.html#how-to-estimate-treatment-effects-based-on-images",
    "title": "Medical imaging and AI for decision support",
    "section": "How to estimate treatment effects based on images?",
    "text": "How to estimate treatment effects based on images?\n\nIn principle the same as estimating a subgroup treatment effect (e.g. male vs female)\n\nConduct a randomized controlled trial where the treatments of interest are randomly allocated\nCollect (imaging) data at randomization timepoint\nUse a statistical learning technique like TARnet (Shalit, Johansson, and Sontag 2017) to estimate outcomes conditional on image and treatment\nconditional treatment effect \\(= f(X,T=1) - f(X,T=0)\\)\n\n\n\n\n\nWhat if you cannot do a (big enough) RCT?\n\n\nEmulate / approximate the ideal trial in observational data you do have, using causal inference techniques\n(which rely on untestable assumptions)"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#improving-decisions-with-ai",
    "href": "talks/240708-imaging-ailab/index.html#improving-decisions-with-ai",
    "title": "Medical imaging and AI for decision support",
    "section": "Improving decisions with AI",
    "text": "Improving decisions with AI\n\nprognosis (\\(X \\to Y\\), \\(Y\\) in the future)\ntreatment effect (\\(X\\) determines effect of a treatment \\(T\\) on outcome \\(Y\\) in the future)\n\n\nWhereas treatment effect estimation is typically thought of as a causal task requiring causal approaches (e.g. randomized controllerd trials)\nPrognosis models are often developed without any causal thinking (if it predicts it predicts)\nbut then advertised for making treatment decisions."
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#the-in-between-using-prediction-models-for-medical-decision-making",
    "href": "talks/240708-imaging-ailab/index.html#the-in-between-using-prediction-models-for-medical-decision-making",
    "title": "Medical imaging and AI for decision support",
    "section": "The in-between: using prediction models for (medical) decision making",
    "text": "The in-between: using prediction models for (medical) decision making\n\nprognosis (e.g. survival given medical image)"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#using-prediction-models-for-decision-making-is-often-thought-of-as-a-good-idea",
    "href": "talks/240708-imaging-ailab/index.html#using-prediction-models-for-decision-making-is-often-thought-of-as-a-good-idea",
    "title": "Medical imaging and AI for decision support",
    "section": "Using prediction models for decision making is often thought of as a good idea",
    "text": "Using prediction models for decision making is often thought of as a good idea\nFor example:\n\ngive chemotherapy to cancer patients with high predicted risk of recurrence\ngive statins to patients with a high risk of a heart attack\n\n\n\n\n\nTRIPOD+AI on prediction models (collinsTRIPODAIStatement2024?)\n\n\n“Their primary use is to support clinical decision making, such as … initiate treatment or lifestyle changes.”"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#building-models-for-decision-support-without-regards-for-the-historic-treatment-policy-is-a-bad-idea",
    "href": "talks/240708-imaging-ailab/index.html#building-models-for-decision-support-without-regards-for-the-historic-treatment-policy-is-a-bad-idea",
    "title": "Medical imaging and AI for decision support",
    "section": "Building models for decision support without regards for the historic treatment policy is a bad idea",
    "text": "Building models for decision support without regards for the historic treatment policy is a bad idea"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#treatment-naive-prediction-models",
    "href": "talks/240708-imaging-ailab/index.html#treatment-naive-prediction-models",
    "title": "Medical imaging and AI for decision support",
    "section": "Treatment-naive prediction models",
    "text": "Treatment-naive prediction models\n\n\n\n\n\\[\\begin{align}\n    E[Y|X] \\class{fragment}{= E[E_{t~\\sim \\pi_0(X)}[Y|X,t]]}\n\\end{align}\\]"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#treatment-naive-prediction-models-1",
    "href": "talks/240708-imaging-ailab/index.html#treatment-naive-prediction-models-1",
    "title": "Medical imaging and AI for decision support",
    "section": "Treatment-naive prediction models",
    "text": "Treatment-naive prediction models\n(Results from vanamsterdamWhenAccuratePrediction2024?)\n\ngood or bad discrimination post deployment may be a sign of a harmful or a beneficial policy change\nmodels that are perfectly calibrated before and after deployment are certainly not useful for decision making because they didn’t change the distribution"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#prediction-modeling-is-very-popular-in-medical-research",
    "href": "talks/240708-imaging-ailab/index.html#prediction-modeling-is-very-popular-in-medical-research",
    "title": "Medical imaging and AI for decision support",
    "section": "Prediction modeling is very popular in medical research",
    "text": "Prediction modeling is very popular in medical research"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#recommended-validation-practices-and-reporting-guidelines-do-not-protect-against-harm",
    "href": "talks/240708-imaging-ailab/index.html#recommended-validation-practices-and-reporting-guidelines-do-not-protect-against-harm",
    "title": "Medical imaging and AI for decision support",
    "section": "Recommended validation practices and reporting guidelines do not protect against harm",
    "text": "Recommended validation practices and reporting guidelines do not protect against harm\nbecause they do not evaluate the policy change"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#bigger-data-does-not-protect-against-harmful-prediction-models",
    "href": "talks/240708-imaging-ailab/index.html#bigger-data-does-not-protect-against-harmful-prediction-models",
    "title": "Medical imaging and AI for decision support",
    "section": "Bigger data does not protect against harmful prediction models",
    "text": "Bigger data does not protect against harmful prediction models"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#more-flexible-models-do-not-protect-against-harmful-prediction-models",
    "href": "talks/240708-imaging-ailab/index.html#more-flexible-models-do-not-protect-against-harmful-prediction-models",
    "title": "Medical imaging and AI for decision support",
    "section": "More flexible models do not protect against harmful prediction models",
    "text": "More flexible models do not protect against harmful prediction models"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#section",
    "href": "talks/240708-imaging-ailab/index.html#section",
    "title": "Medical imaging and AI for decision support",
    "section": "",
    "text": "What to do?"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#section-1",
    "href": "talks/240708-imaging-ailab/index.html#section-1",
    "title": "Medical imaging and AI for decision support",
    "section": "",
    "text": "What to do?\n\n\nEvaluate policy change (cluster randomized controlled trial)\nBuild models that are likely to have value for decision making"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#deploying-a-model-is-an-intervention-that-changes-the-way-treatment-decisions-are-made",
    "href": "talks/240708-imaging-ailab/index.html#deploying-a-model-is-an-intervention-that-changes-the-way-treatment-decisions-are-made",
    "title": "Medical imaging and AI for decision support",
    "section": "Deploying a model is an intervention that changes the way treatment decisions are made",
    "text": "Deploying a model is an intervention that changes the way treatment decisions are made"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#how-do-we-learn-about-the-effect-of-an-intervention",
    "href": "talks/240708-imaging-ailab/index.html#how-do-we-learn-about-the-effect-of-an-intervention",
    "title": "Medical imaging and AI for decision support",
    "section": "How do we learn about the effect of an intervention?",
    "text": "How do we learn about the effect of an intervention?\nWith a randomized experiment\n\n\nfor using a decision support model, the unit of intervention is usually the doctor\nrandomly assign doctors to have access to the model or not\nmeasure differences in treatment decisions and patient outcomes\nthis called a cluster RCT\nif using model improves outcomes, use that one\n\n\n\n\n\nUsing cluster RCTs to evaluated models for decision making is not a new idea (Cooper et al. 1997)\n\n\n“As one possibility, suppose that a trial is performed in which clinicians are randomized either to have or not to have access to such a decision aid in making decisions about where to treat patients who present with pneumonia.”\n\n\n\n\n\n\n\n\n\n\n\nWhat we don’t learn\n\n\nwas the model predicting anything sensible?"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#so-build-treatment-naive-prediction-models-and-trial-them-for-decision-support",
    "href": "talks/240708-imaging-ailab/index.html#so-build-treatment-naive-prediction-models-and-trial-them-for-decision-support",
    "title": "Medical imaging and AI for decision support",
    "section": "So build treatment-naive prediction models and trial them for decision support?",
    "text": "So build treatment-naive prediction models and trial them for decision support?\nNot a good idea\n\nbaking a cake without a recipe\nhoping it turns into something nice\nnot pleasant to people that need to taste result of the experiment\n\n(i.e. patients may have side-effects / die)"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#we-should-build-models-that-are-likely-to-be-valuable-for-decision-making",
    "href": "talks/240708-imaging-ailab/index.html#we-should-build-models-that-are-likely-to-be-valuable-for-decision-making",
    "title": "Medical imaging and AI for decision support",
    "section": "We should build models that are likely to be valuable for decision making",
    "text": "We should build models that are likely to be valuable for decision making\n\nBuild models that predict expected outcomes under hypothetical interventions (prediction-under-intervention models)\ndoctor / patient can pick the treatment with best expected outcomes, depending on patient’s values and preferences\nwhereas treatment-naive prediction models average out over the historic treatment policy, prediction-under-intervention allows the user to select a treatment option\n\n\n\n\n\nHilden and Habbema on prognosis (Hilden and Habbema 1987)\n\n\n“Prognosis cannot be divorced from contemplated medical action, nor from action to be taken by the patient in response to prognostication.”\n\n\n\n\nprediction-under-intervention is not a new idea, but language and methods on causality have come a long way since (Hilden and Habbema 1987)."
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#estimand-for-prediction-under-intervention-models",
    "href": "talks/240708-imaging-ailab/index.html#estimand-for-prediction-under-intervention-models",
    "title": "Medical imaging and AI for decision support",
    "section": "Estimand for prediction-under-intervention models",
    "text": "Estimand for prediction-under-intervention models\nWhat is the estimand?\n\nprediction: \\(E[Y|X]\\)\naverage treatment effect: \\(E[Y|\\text{do}(T=1)] - E[Y|\\text{do}(T=0)]\\)\nconditional average treatment effect: \\(E[Y|\\text{do}(T=1),X] - E[Y|\\text{do}(T=0),X]\\)\nprediction-under-intervention: \\(E[Y|\\text{do}(T=t),X]\\)"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#more-on-prediction-under-intervention-models",
    "href": "talks/240708-imaging-ailab/index.html#more-on-prediction-under-intervention-models",
    "title": "Medical imaging and AI for decision support",
    "section": "More on prediction-under-intervention models",
    "text": "More on prediction-under-intervention models\ndevelopment:\n\nideally estimated from RCTs, but these are often too small or don’t measure the right data\nalternatively can use observational data and causal inference methods\nassumption of no unobserved confounding often hard to justify in observational data\nbut there’s more between heaven (RCT) and earth (confounder adjustment)\n\nproxy-variable methods (e.g. Miao, Geng, and Tchetgen Tchetgen 2018; Wouter A. C. van Amsterdam et al. 2022)\nconstant relative treatment effect assumption (e.g. Alaa et al. 2021; Wouter A. C. van Amsterdam and Ranganath 2023; Candido dos Reis et al. 2017)\ndiff-in-diff\ninstrumental variable analysis (Wald 1940; Puli and Ranganath 2021; Hartford et al. 2017)\nfront-door analysis\n\nmany of these have potential new applications with AI and medical imaging"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#evaluation-of-prediction-under-intervention-models",
    "href": "talks/240708-imaging-ailab/index.html#evaluation-of-prediction-under-intervention-models",
    "title": "Medical imaging and AI for decision support",
    "section": "Evaluation of prediction-under-intervention models",
    "text": "Evaluation of prediction-under-intervention models\n\nprediction accuracy can be tested in RCTs, or in observational data with specialized methods accounting for confounding (e.g. Keogh and Van Geloven 2024)\nin confounded observational data, typical metrics (e.g. AUC or calibration) are not sufficient as we want to predict well in data from other distribution than observed data (i.e. other treatment decisions)\na new policy can be evaluated in historic RCTs (e.g. Karmali et al. 2018)\nultimate test is cluster RCT\nif not perfect, likely a better recipe than treatment-naive models"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#take-aways",
    "href": "talks/240708-imaging-ailab/index.html#take-aways",
    "title": "Medical imaging and AI for decision support",
    "section": "Take-aways",
    "text": "Take-aways\n\ndeploying models for decision support is an intervention and should be evaluated as such\nwhen developing or evaluating (AI) prediction models for medical decisions, think about\n\nwhat is the effect of using this model on medical decisions?\nwhat is the effect of this policy change on patient outcomes?\n\nprediction-under-intervention models have a foreseeable effect on patient oucomes when used for decision making\n\n\n\n\n\n\n\n\n\nFrom algorithms to action: improving patient care requires causality (W. A. C. van Amsterdam et al. 2024)\n\n\n\n\n\n\nWhen accurate prediction models yield harmful sel-fulfilling prophecies (vanamsterdamWhenAccuratePrediction2024?)"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#references",
    "href": "talks/240708-imaging-ailab/index.html#references",
    "title": "Medical imaging and AI for decision support",
    "section": "References",
    "text": "References\n\n\n\n\nAlaa, Ahmed M., Deepti Gurdasani, Adrian L. Harris, Jem Rashbass, and Mihaela van der Schaar. 2021. “Machine Learning to Guide the Use of Adjuvant Therapies for Breast Cancer.” Nature Machine Intelligence, June, 1–11. https://doi.org/10/gk6bh7.\n\n\nAmsterdam, W.A. C. van, Pim A. de Jong, Joost J. C. Verhoeff, Tim Leiner, and Rajesh Ranganath. 2024. “From Algorithms to Action: Improving Patient Care Requires Causality.” BMC Medical Informatics and Decision Making 24 (1). https://doi.org/10.1186/s12911-024-02513-3.\n\n\nAmsterdam, Wouter A. C. van, and Rajesh Ranganath. 2023. “Conditional Average Treatment Effect Estimation with Marginally Constrained Models.” Journal of Causal Inference 11 (1): 20220027. https://doi.org/10.1515/jci-2022-0027.\n\n\nAmsterdam, Wouter A. C. van, Joost J. C. Verhoeff, Netanja I. Harlianto, Gijs A. Bartholomeus, Aahlad Manas Puli, Pim A. de Jong, Tim Leiner, Anne S. R. van Lindert, Marinus J. C. Eijkemans, and Rajesh Ranganath. 2022. “Individual Treatment Effect Estimation in the Presence of Unobserved Confounding Using Proxies: A Cohort Study in Stage III Non-Small Cell Lung Cancer.” Scientific Reports 12 (1, 1): 5848. https://doi.org/10.1038/s41598-022-09775-9.\n\n\nCandido dos Reis, Francisco J., Gordon C. Wishart, Ed M. Dicks, David Greenberg, Jem Rashbass, Marjanka K. Schmidt, Alexandra J. van den Broek, et al. 2017. “An Updated PREDICT Breast Cancer Prognostication and Treatment Benefit Prediction Model with Independent Validation.” Breast Cancer Research 19 (1): 58. https://doi.org/10/gbhgpq.\n\n\nCooper, Gregory F., Constantin F. Aliferis, Richard Ambrosino, John Aronis, Bruce G. Buchanan, Richard Caruana, Michael J. Fine, et al. 1997. “An Evaluation of Machine-Learning Methods for Predicting Pneumonia Mortality.” Artificial Intelligence in Medicine 9 (2): 107–38. https://doi.org/10.1016/S0933-3657(96)00367-3.\n\n\nHartford, Jason, Greg Lewis, Kevin Leyton-Brown, and Matt Taddy. 2017. “Deep IV: A Flexible Approach for Counterfactual Prediction.” In International Conference on Machine Learning, 1414–23. PMLR. https://proceedings.mlr.press/v70/hartford17a.html.\n\n\nHilden, Jørgen, and J. Dik F. Habbema. 1987. “Prognosis in Medicine: An Analysis of Its Meaning and Rôles.” Theoretical Medicine 8 (3): 349–65. https://doi.org/10.1007/BF00489469.\n\n\nKarmali, Kunal N., Donald M. Lloyd-Jones, Joep van der Leeuw, David C. Goff Jr, Salim Yusuf, Alberto Zanchetti, Paul Glasziou, et al. 2018. “Blood Pressure-Lowering Treatment Strategies Based on Cardiovascular Risk Versus Blood Pressure: A Meta-Analysis of Individual Participant Data.” PLOS Medicine 15 (3): e1002538. https://doi.org/10.1371/journal.pmed.1002538.\n\n\nKeogh, Ruth H., and Nan Van Geloven. 2024. “Prediction Under Interventions: Evaluation of Counterfactual Performance Using Longitudinal Observational Data.” Epidemiology (Cambridge, Mass.) 35 (3): 329–39. https://doi.org/10.1097/EDE.0000000000001713.\n\n\nMiao, Wang, Zhi Geng, and Eric J Tchetgen Tchetgen. 2018. “Identifying Causal Effects with Proxy Variables of an Unmeasured Confounder.” Biometrika 105 (4): 987–93. https://doi.org/10.1093/biomet/asy038.\n\n\nPuli, Aahlad Manas, and Rajesh Ranganath. 2021. “General Control Functions for Causal Effect Estimation from Instrumental Variables.” http://arxiv.org/abs/1907.03451.\n\n\nShalit, Uri, Fredrik D. Johansson, and David Sontag. 2017. “Estimating Individual Treatment Effect: Generalization Bounds and Algorithms.” http://arxiv.org/abs/1606.03976.\n\n\nWald, Abraham. 1940. “The Fitting of Straight Lines If Both Variables Are Subject to Error.” The Annals of Mathematical Statistics 11 (3): 284–300. https://doi.org/10.1214/aoms/1177731868."
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#what-is-ai-1",
    "href": "talks/240418-ii-spring-meeting/index.html#what-is-ai-1",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "What is AI?",
    "text": "What is AI?\n\n\n\n\n\n\nWhat is artificial intelligence?\n\n\ncomputers doing tasks that normally require intelligence 1\n\n\n\n\n\n\n\n\n\n\nWhat is artificial general intelligence?\n\n\nGeneral purpose AI that performs a range of tasks in different domains like humans\n\n\n\n\nthese are my own definitions"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#ai-subsumes-rule-based-systems-and-machine-learning",
    "href": "talks/240418-ii-spring-meeting/index.html#ai-subsumes-rule-based-systems-and-machine-learning",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "AI subsumes rule-based systems and machine learning",
    "text": "AI subsumes rule-based systems and machine learning\n\nRule-based AI: knowledge base of rules\nMachine learning: statistical learning from examples #- (traditional) machine learning (logistic regression, SVM, RF, #GBM) #- modern machine learning: deep learning and foundation models"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#rule-based-systems-are-ai",
    "href": "talks/240418-ii-spring-meeting/index.html#rule-based-systems-are-ai",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "Rule-based systems are AI",
    "text": "Rule-based systems are AI\n\nrule: all cows are animals\nobservation: this is a cow \\(\\to\\) it is an animal\napplications:\n\nmedication interaction checkers\nbedside patient monitors"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#ml-tasks",
    "href": "talks/240418-ii-spring-meeting/index.html#ml-tasks",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "ML tasks",
    "text": "ML tasks\n\n\n\n\n\n\n\n\ndata:\n\n\n\ni\nlength\nweight\nsex\n\n\n\n\n1\n137\n30\nboy\n\n\n2\n122\n24\ngirl\n\n\n3\n101\n18\ngirl\n\n\n…\n…\n…\n…\n\n\n\n\n\\[l_i,w_i,s_i \\sim p(l,w,s)\\]"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#ml-tasks-generation",
    "href": "talks/240418-ii-spring-meeting/index.html#ml-tasks-generation",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "ML tasks: generation",
    "text": "ML tasks: generation\n\n\n\n\n\n\n\n\nuse samples to learn model \\(p_{\\theta}\\) for joint distribution \\(p\\) \\[\n  l_j,w_j,s_j \\sim p_{\\theta}(l,w,s)\n\\]"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#ml-tasks-conditional-generation",
    "href": "talks/240418-ii-spring-meeting/index.html#ml-tasks-conditional-generation",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "ML tasks: conditional generation",
    "text": "ML tasks: conditional generation\n\n\n\n\n\n\n\n\nuse samples to learn model for conditional distribution \\(p\\) \\[\n  l_j,w_j \\sim p_{\\theta}(l,w|s=\\text{boy})\n\\]\n\n\n\n\ntask\n\n\n\n\n\ngeneration\n\\(l_j,w_j,s_j \\sim p_{\\theta}(l,w,s)\\)"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#ml-tasks-conditional-generation-2",
    "href": "talks/240418-ii-spring-meeting/index.html#ml-tasks-conditional-generation-2",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "ML tasks: conditional generation 2",
    "text": "ML tasks: conditional generation 2\n\n\n\n\n\n\n\n\nuse samples to learn model for conditional distribution \\(p\\) of one variable \\[\ns_j \\sim p_{\\theta}(s|l=l',w=w')\n\\]\n\n\n\n\ntask\n\n\n\n\n\ngeneration\n\\(l_j,w_j,s_j \\sim p_{\\theta}(l,w,s)\\)\n\n\nconditional generation\n\\(l_j,w_j \\sim p_{\\theta}(l,w|s=\\text{boy})\\)"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#ml-tasks-discrimination",
    "href": "talks/240418-ii-spring-meeting/index.html#ml-tasks-discrimination",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "ML tasks: discrimination",
    "text": "ML tasks: discrimination\n\n\n\n\n\n\n\n\ncall this one variable outcome and classify when expected value passes threshold (e.g. 0.5): \\[\ns_j = p_{\\theta}(s|l=l',w=w') &gt; 0.5\n\\]\n\n\n\n\ntask\n\n\n\n\n\ngeneration\n\\(l_j,w_j,s_j \\sim p_{\\theta}(l,w,s)\\)\n\n\nconditional generation\n\\(l_j,w_j \\sim p_{\\theta}(l,w|s=\\text{boy})\\)\n\n\ndiscrimination\n\\(p_{\\theta}(s|l=l_i,w=w_i) &gt; 0.5\\)"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#ml-tasks-reinforcement-learning",
    "href": "talks/240418-ii-spring-meeting/index.html#ml-tasks-reinforcement-learning",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "ML tasks: reinforcement learning",
    "text": "ML tasks: reinforcement learning\n\ne.g. computers playing games\nmaybe not so useful for clinical research as requires many experiments"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#machine-learning-is-statistical-learning-with-flexible-models",
    "href": "talks/240418-ii-spring-meeting/index.html#machine-learning-is-statistical-learning-with-flexible-models",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "Machine learning is statistical learning with flexible models",
    "text": "Machine learning is statistical learning with flexible models\n\n\n- There is no fundamental difference between statistics and machine learning\n- both optimize parameters to improve some criterion (loss / likelihood) that measures model fit to data\n- models used in machine learning are more flexible"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#ml-models-can-fit-more-functions-but-also-more-likely-to-overfit",
    "href": "talks/240418-ii-spring-meeting/index.html#ml-models-can-fit-more-functions-but-also-more-likely-to-overfit",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "ML models can fit more functions but also more likely to overfit",
    "text": "ML models can fit more functions but also more likely to overfit"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#should-pick-the-right-amount-of-model-complexity",
    "href": "talks/240418-ii-spring-meeting/index.html#should-pick-the-right-amount-of-model-complexity",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "Should pick the ‘right’ amount of model complexity",
    "text": "Should pick the ‘right’ amount of model complexity"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#what-is-a-large-language-model-like-chatgpt-1",
    "href": "talks/240418-ii-spring-meeting/index.html#what-is-a-large-language-model-like-chatgpt-1",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "What is a large-language model like chatGPT?",
    "text": "What is a large-language model like chatGPT?\n\n\n\n\n\n\nWhat is chatGPT?\n\n\na stochastic auto-regressive next-word predictor with a chatbot interface\n\n\n\n\ntrained by predicting the next &lt;…&gt;\n\nin a large corpus of text\nwith a large model\nfor a long time on expensive hardware"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#auto-regressive-conditional-generation",
    "href": "talks/240418-ii-spring-meeting/index.html#auto-regressive-conditional-generation",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "auto-regressive conditional generation:",
    "text": "auto-regressive conditional generation:\n\\[\\begin{align}\n    \\text{word}_1 &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{prompt})\\\\\n\\end{align}\\]"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#auto-regressive-conditional-generation-1",
    "href": "talks/240418-ii-spring-meeting/index.html#auto-regressive-conditional-generation-1",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "auto-regressive conditional generation:",
    "text": "auto-regressive conditional generation:\n\\[\\begin{align}\n    \\text{word}_1 &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{prompt})\\\\\n    \\text{word}_2 &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{word}_1,\\text{prompt})\n\\end{align}\\]"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#auto-regressive-conditional-generation-2",
    "href": "talks/240418-ii-spring-meeting/index.html#auto-regressive-conditional-generation-2",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "auto-regressive conditional generation:",
    "text": "auto-regressive conditional generation:\n\\[\\begin{align}\n    \\text{word}_1 &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{prompt})\\\\\n    \\text{word}_2 &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{word}_1,\\text{prompt})\n\\end{align}\\]"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#auto-regressive-conditional-generation-3",
    "href": "talks/240418-ii-spring-meeting/index.html#auto-regressive-conditional-generation-3",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "auto-regressive conditional generation:",
    "text": "auto-regressive conditional generation:\n\\[\\begin{align}\n    \\text{word}_1 &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{prompt})\\\\\n    \\text{word}_2 &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{word}_1,\\text{prompt})\\\\\n    \\text{word}_n &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{word}_{n-1},\\ldots,\\text{word}_1,\\text{prompt})\n\\end{align}\\]"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#auto-regressive-conditional-generation-4",
    "href": "talks/240418-ii-spring-meeting/index.html#auto-regressive-conditional-generation-4",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "auto-regressive conditional generation:",
    "text": "auto-regressive conditional generation:\n\\[\\begin{align}\n    \\text{word}_1 &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{prompt})\\\\\n    \\text{word}_2 &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{word}_1,\\text{prompt})\\\\\n    \\text{word}_n &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{word}_{n-1},\\ldots,\\text{word}_1,\\text{prompt})\\\\\n    \\text{STOP}   &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{word}_{n-1},\\ldots,\\text{word}_1,\\text{prompt})\n\\end{align}\\]"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#gpt-4-scale",
    "href": "talks/240418-ii-spring-meeting/index.html#gpt-4-scale",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "GPT-4 scale",
    "text": "GPT-4 scale"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#rule-based-vs-llms",
    "href": "talks/240418-ii-spring-meeting/index.html#rule-based-vs-llms",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "rule-based vs LLMs",
    "text": "rule-based vs LLMs\n\n\n\ndeduction from explicit knowledge\nknowledge verifiable and fast\nconstrained to deducible\n\n\n\n\n\n\n\n\nextracted from observed data\nunverifiable and compute intensive\n“chatGPT seems to know(?) much”"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#ml-versus-statistics-when-to-use-what",
    "href": "talks/240418-ii-spring-meeting/index.html#ml-versus-statistics-when-to-use-what",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "ML versus statistics, when to use what",
    "text": "ML versus statistics, when to use what\n\n\nmachine learning\n\nhave more data\nmore complex functions (images)\n\n\nstatistics (e.g. GLMs)\n\nless data\nmore domain knowledge"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#a-sobering-note",
    "href": "talks/240418-ii-spring-meeting/index.html#a-sobering-note",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "A sobering note",
    "text": "A sobering note\n- ML in medicine has been ‘hot’ since at least the 90s (Cooper et al. 1997)\n- not much evidence that it outperforms regression on most tasks (Christodoulou et al. 2019)\n- though many poorly performed studies (Dhiman et al. 2022)"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#two-questions",
    "href": "talks/240418-ii-spring-meeting/index.html#two-questions",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "two questions",
    "text": "two questions\nQuestion 1\n\nprediction model of \\(Y|X\\) fits the data really well (AUC = 0.99 and perfect calibration)\nwill changing \\(X\\) induce a change \\(Y\\)?\n\nQuestion 2\n\nGive statins when risk of cardiovascular event in 10 years exceeds 10%\nML model based on age, medication history, cardiac CT-scan predicts this very well\nwill using this model for treatment decisions improve patient outcomes?"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#improving-the-world-is-a-causal-task",
    "href": "talks/240418-ii-spring-meeting/index.html#improving-the-world-is-a-causal-task",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "Improving the world is a causal task",
    "text": "Improving the world is a causal task\n\nstatistics / ML: what to expect when we passively observe the world\nnot how we can intervene to make things better, this requires causality\nQuestion 1\n\nyellowish fingers predict lung cancer, paint fingers to skin color?\nweight loss predicts death in lung cancer, send patients to couch with McDonalds?"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#when-accurate-prediction-models-yield-harmful-self-fulfilling-prophecies",
    "href": "talks/240418-ii-spring-meeting/index.html#when-accurate-prediction-models-yield-harmful-self-fulfilling-prophecies",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "When accurate prediction models yield harmful self-fulfilling prophecies",
    "text": "When accurate prediction models yield harmful self-fulfilling prophecies"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#prediction-modeling-is-very-popular-in-medical-research",
    "href": "talks/240418-ii-spring-meeting/index.html#prediction-modeling-is-very-popular-in-medical-research",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "Prediction modeling is very popular in medical research",
    "text": "Prediction modeling is very popular in medical research"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#treatment-naive-risk-models",
    "href": "talks/240418-ii-spring-meeting/index.html#treatment-naive-risk-models",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "Treatment-naive risk models",
    "text": "Treatment-naive risk models"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#is-this-obvious",
    "href": "talks/240418-ii-spring-meeting/index.html#is-this-obvious",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "Is this obvious?",
    "text": "Is this obvious?\n\n\n\n\n\n\nTip\n\n\nIt may seem obvious that you should not ignore historical treatments in your prediction models, if you want to improve treatment decisions, but many of these models are published daily, and some guidelines even allow for implementing these models based on predictve performance only"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#other-risk-models",
    "href": "talks/240418-ii-spring-meeting/index.html#other-risk-models",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "Other risk models:",
    "text": "Other risk models:\n- condition on given treatment and traits\n- unobserved confounding (hat type) leads to wrong treatment decisions"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#recommended-validation-practices-do-not-protect-against-harm",
    "href": "talks/240418-ii-spring-meeting/index.html#recommended-validation-practices-do-not-protect-against-harm",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "Recommended validation practices do not protect against harm",
    "text": "Recommended validation practices do not protect against harm\nbecause they do not evaluate the policy change"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#bigger-data-does-not-protect-against-harmful-risk-models",
    "href": "talks/240418-ii-spring-meeting/index.html#bigger-data-does-not-protect-against-harmful-risk-models",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "Bigger data does not protect against harmful risk models",
    "text": "Bigger data does not protect against harmful risk models"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#more-flexible-models-do-not-protect-against-harmful-risk-models",
    "href": "talks/240418-ii-spring-meeting/index.html#more-flexible-models-do-not-protect-against-harmful-risk-models",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "More flexible models do not protect against harmful risk models",
    "text": "More flexible models do not protect against harmful risk models"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#gap-between-prediction-accuracy-and-value-for-decision-making",
    "href": "talks/240418-ii-spring-meeting/index.html#gap-between-prediction-accuracy-and-value-for-decision-making",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "Gap between prediction accuracy and value for decision making",
    "text": "Gap between prediction accuracy and value for decision making"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#section",
    "href": "talks/240418-ii-spring-meeting/index.html#section",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "",
    "text": "What to do?"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#section-1",
    "href": "talks/240418-ii-spring-meeting/index.html#section-1",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "",
    "text": "What to do?\n\n\nEvaluate policy change (cluster randomized controlled trial)\nBuild models that are likely to have value for decision making"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#prediction-under-intervention-models",
    "href": "talks/240418-ii-spring-meeting/index.html#prediction-under-intervention-models",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "Prediction-under-intervention models",
    "text": "Prediction-under-intervention models\nPredict outcome under hypothetical intervention of giving certain treatment"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#when-developing-risk-models",
    "href": "talks/240418-ii-spring-meeting/index.html#when-developing-risk-models",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "When developing risk models,",
    "text": "When developing risk models,\nalways discuss:\n\n\n\n\n\n1. what is effect on treatment policy?\n2. what is effect on patient outcomes?"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#take-aways",
    "href": "talks/240418-ii-spring-meeting/index.html#take-aways",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "take-aways",
    "text": "take-aways\n\nAI subsumes rule-based programs and machine learning\nmachine learning is statistical learning from data with flexible models\nchatGPT does auto-regressive next-word prediction\nchatGPT produces beautiful mistakes: eloquently written logical fallacies\nprediction: what to expect when passively observing the world\ncausality: what happens when I change something?\nprediction models can cause harmful self-fulfilling prophecies when used for decision making\nwhen building prediction models for decision support, you cannot ignore decisions on the treatments in historic data\nmodels for prediction-under-intervention have foreseeable effects when used for decision making\nultimate test of model utility is determined by outcomes in (cluster) RCT"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#references",
    "href": "talks/240418-ii-spring-meeting/index.html#references",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "",
    "text": "thank you\n\n\n\n\nAmsterdam, Wouter A. C. van, Nan van Geloven, Jesse H. Krijthe, Rajesh Ranganath, and Giovanni Ciná. 2024. “When Accurate Prediction Models Yield Harmful Self-Fulfilling Prophecies.” arXiv. https://doi.org/10.48550/arXiv.2312.01210.\n\n\nAmsterdam, Wouter A. C. van, Pim A. de Jong, Joost J. C. Verhoeff, Tim Leiner, and Rajesh Ranganath. 2024. “From Algorithms to Action: Improving Patient Care Requires Causality.” arXiv. https://doi.org/10.48550/arXiv.2209.07397.\n\n\nChristodoulou, Evangelia, Jie Ma, Gary S. Collins, Ewout W. Steyerberg, Jan Y. Verbakel, and Ben Van Calster. 2019. “A Systematic Review Shows No Performance Benefit of Machine Learning over Logistic Regression for Clinical Prediction Models.” Journal of Clinical Epidemiology 110 (June): 12–22. https://doi.org/10.1016/j.jclinepi.2019.02.004.\n\n\nCooper, Gregory F., Constantin F. Aliferis, Richard Ambrosino, John Aronis, Bruce G. Buchanan, Richard Caruana, Michael J. Fine, et al. 1997. “An Evaluation of Machine-Learning Methods for Predicting Pneumonia Mortality.” Artificial Intelligence in Medicine 9 (2): 107–38. https://doi.org/10.1016/S0933-3657(96)00367-3.\n\n\nDhiman, Paula, Jie Ma, Constanza L. Andaur Navarro, Benjamin Speich, Garrett Bullock, Johanna A. A. Damen, Lotty Hooft, et al. 2022. “Methodological Conduct of Prognostic Prediction Models Developed Using Machine Learning in Oncology: A Systematic Review.” BMC Medical Research Methodology 22 (1): 101. https://doi.org/10.1186/s12874-022-01577-x."
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#about",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#about",
    "title": "An introduction to AI for biostatisticians",
    "section": "About",
    "text": "About\n\nUniversity Medical Center Utrecht\n\nDivision: Julius Center for Health Sciences and Primary Care\n\nDepartment: Data Science & Biostatistics\n\nSub-department: Data Science Methods\n\n\n\nBackground:\n\nphysics (BSc.)\nmedicine (MD.)\nmachine learning / causal inference in healthcare (PhD.)\nepidemiology / biostatistics (MSc.)\n\nWork on:\n\ncausal inference and machine learning in health care\nmethods and applications"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#disclaimer",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#disclaimer",
    "title": "An introduction to AI for biostatisticians",
    "section": "Disclaimer",
    "text": "Disclaimer\n\nof course, I used AI to help with the slides\n\ngenerate tikz diagrams with github copilot\nwrite text and equations with github copilot\ngenerate vector illustrations in adobe illustrator\ngenerate png images with Bing chat\n\nno competing interests"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#definition",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#definition",
    "title": "An introduction to AI for biostatisticians",
    "section": "Definition",
    "text": "Definition\n\n\n\n\n\n\nWhat is AI?\n\n\nArtificial Intelligence is the branch of computer science that focuses on creating systems capable of performing tasks that typically require human intelligence. (Russell and Norvig 2020)\n\n\n\n\nThese tasks include: learning, reasoning, problem-solving, perception, natural language understanding, and decision-making.\nAI systems can be designed to operate autonomously, adapt to new inputs, and improve their performance over time."
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#early-milestones",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#early-milestones",
    "title": "An introduction to AI for biostatisticians",
    "section": "Early Milestones",
    "text": "Early Milestones\n\n1940s: Concept of AI emerged with Alan Turing’s work on computation and intelligence.\n1956: The term “Artificial Intelligence” was coined at the Dartmouth Conference by John McCarthy.\n1960s-1970s: Early AI programs focused on solving algebra, proving theorems, and playing games (e.g., Chess)."
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#key-developments",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#key-developments",
    "title": "An introduction to AI for biostatisticians",
    "section": "Key Developments",
    "text": "Key Developments\n\n1980s: Introduction of expert systems (rule-based systems for decision making).\n1990s: Machine learning began gaining traction, allowing AI systems to learn from data.\n2010s: Deep learning and neural networks revolutionized AI, enabling breakthroughs in areas like image recognition, natural language processing, and more."
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#ai-landscape-what-is-ai",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#ai-landscape-what-is-ai",
    "title": "An introduction to AI for biostatisticians",
    "section": "AI landscape: what is AI?",
    "text": "AI landscape: what is AI?"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#rule-based-systems-are-ai",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#rule-based-systems-are-ai",
    "title": "An introduction to AI for biostatisticians",
    "section": "Rule-based systems are AI",
    "text": "Rule-based systems are AI\n\n\n\n\nrule: all cows are animals\nobservation: this is a cow \\(\\to\\) it is an animal\napplications in health care:\n\nmedication interaction checkers\nbedside patient monitors\n\ne.g. if heart rate &gt; 100, alert nurse"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#assume-we-have-this-data",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#assume-we-have-this-data",
    "title": "An introduction to AI for biostatisticians",
    "section": "Assume we have this data",
    "text": "Assume we have this data\n\n\n\n\n\n\n\n\n\n\n\ni\nlength\nweight\nsex\n\n\n\n\n1\n137\n30\nboy\n\n\n2\n122\n24\ngirl\n\n\n3\n101\n18\ngirl\n\n\n…\n…\n…\n…\n\n\n\n\nWe typically assume these data are (i.i.d.) samples from some unknown distribution \\(p(l,w,s)\\):\n\\[l_i,w_i,s_i \\sim p(l,w,s)\\]"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#ml-tasks-generation",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#ml-tasks-generation",
    "title": "An introduction to AI for biostatisticians",
    "section": "ML tasks: generation",
    "text": "ML tasks: generation\n\n\n\n\n\n\n\n\n\nformulate a model for joint distribution \\(p_{\\theta}\\)\n\nstatistics: ‘small’ model family\nmachine learning: ‘large’ model family\n\nuse samples to optimize \\(\\theta\\)\ngenerate new samples\n\n\\[l_j,w_j,s_j \\sim p_{\\theta}(l,w,s)\\]\n\n\n\n\ntask\n\n\n\n\n\ngeneration\n\\(l_j,w_j,s_j \\sim p_{\\theta}(l,w,s)\\)\n\n\n\n\n\napplication: simulate data for power calculations, privacy-preserving data sharing"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#ml-tasks-conditional-generation",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#ml-tasks-conditional-generation",
    "title": "An introduction to AI for biostatisticians",
    "section": "ML tasks: conditional generation",
    "text": "ML tasks: conditional generation\n\n\n\n\n\n\n\n\nuse samples to learn model for conditional distribution \\(p\\) \\[\n  l_j,w_j \\sim p_{\\theta}(l,w|s=\\text{boy})\n\\]\n\n\n\n\ntask\n\n\n\n\n\ngeneration\n\\(l_j,w_j,s_j \\sim p_{\\theta}(l,w,s)\\)\n\n\nconditional generation\n\\(l_j,w_j \\sim p_{\\theta}(l,w|s=\\text{boy})\\)\n\n\n\n\n\napplication: imputation, question answering"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#ml-tasks-conditional-generation-2",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#ml-tasks-conditional-generation-2",
    "title": "An introduction to AI for biostatisticians",
    "section": "ML tasks: conditional generation 2",
    "text": "ML tasks: conditional generation 2\n\n\n\n\n\n\n\n\nuse samples to learn model for conditional distribution \\(p\\) of one variable \\[\ns_j \\sim p_{\\theta}(s|l=l',w=w')\n\\]\n\n\n\ntask\n\n\n\n\n\ngeneration\n\\(l_j,w_j,s_j \\sim p_{\\theta}(l,w,s)\\)\n\n\nconditional generation\n\\(l_j,w_j \\sim p_{\\theta}(l,w|s=\\text{boy})\\)"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#ml-tasks-discrimination-classification",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#ml-tasks-discrimination-classification",
    "title": "An introduction to AI for biostatisticians",
    "section": "ML tasks: discrimination / classification",
    "text": "ML tasks: discrimination / classification\n\n\n\n\n\n\n\n\ncall this one variable outcome and - classify when majority of generated samples are of a certain class - or: have a model that outputs expected values \\[\ns_j = p_{\\theta}(s|l=l',w=w') &gt; 0.5\n\\]\n\n\n\ntask\n\n\n\n\n\ngeneration\n\\(l_j,w_j,s_j \\sim p_{\\theta}(l,w,s)\\)\n\n\nconditional generation\n\\(l_j,w_j \\sim p_{\\theta}(l,w|s=\\text{boy})\\)\n\n\ndiscrimination\n\\(p_{\\theta}(s|l=l_i,w=w_i) &gt; 0.5\\)\n\n\n\n\napplication: prediction, diagnosis"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#ml-tasks-reinforcement-learning",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#ml-tasks-reinforcement-learning",
    "title": "An introduction to AI for biostatisticians",
    "section": "ML tasks: reinforcement learning",
    "text": "ML tasks: reinforcement learning\n\ne.g. computers playing games\ntypically requires many experiments, maybe not too useful in health care"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#neural-networks-and-deep-learning",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#neural-networks-and-deep-learning",
    "title": "An introduction to AI for biostatisticians",
    "section": "Neural Networks and Deep Learning",
    "text": "Neural Networks and Deep Learning\nFrom Linear Regression …\n\n\n\n\n\n\n\\[y = \\sum_{i=0}^5 x_i \\beta_i\\]\n\noptimize \\(\\beta_i\\) to minimize mean squared error, e.g. using second-order methods"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#neural-networks-and-deep-learning-1",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#neural-networks-and-deep-learning-1",
    "title": "An introduction to AI for biostatisticians",
    "section": "Neural Networks and Deep Learning",
    "text": "Neural Networks and Deep Learning\n… to ‘Deep’ Learning\n\n\n\n\n\n\n\\[\\begin{align}\n    h_i &= w_{0i} + w_{1i} x_1 + \\ldots \\\\\n    h_i &= g(h_i) \\\\\n      y &= \\sum_{i=1}^3 h_i w_i\n\\end{align}\\]\n\nsticked \\(h_i\\) between input and output\n\\(g\\) is a non-linear function: each \\(h_i\\) is a non-linear transformation of the input\nrenamed \\(\\beta_i\\) (‘coefficients’) to \\(w_{0i}\\) and \\(w_i\\) (‘weights’)"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#why-would-neural-networks-work",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#why-would-neural-networks-work",
    "title": "An introduction to AI for biostatisticians",
    "section": "Why would neural networks work?",
    "text": "Why would neural networks work?\n\ntrue underlying relationships may be non-linear\nuniversal approximation theorem: a neural network with one hidden layer of sufficient width can approximate any continuous function\nproblems:\n\nno longer convex optimization\ntypical second-order optimizers scale quadratically or worse with number of parameters\ndeterministic computation, but not easily understandable (black box)"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#training-neural-networks",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#training-neural-networks",
    "title": "An introduction to AI for biostatisticians",
    "section": "Training neural networks",
    "text": "Training neural networks\n\nuse framework to define ‘forward-pass’ of network (e.g. PyTorch, TensorFlow, Keras, Jax)\ndeep learning: initialize parameters randomly, use gradient descent (first-order) methods\ndefine loss function (e.g. mean squared error, cross-entropy (a.k.a. log-loss))\nuse optimizer to minimize loss function (e.g. Stochastic Gradient Descent, Adam)"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#stochastic-gradient-descent",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#stochastic-gradient-descent",
    "title": "An introduction to AI for biostatisticians",
    "section": "Stochastic gradient descent",
    "text": "Stochastic gradient descent\n\\[L(\\theta) = \\sum_{i=1}^n \\ell(y_i, f(x_i;\\theta))\\]\n\ntake mini-batch of size \\(m &lt;&lt; n\\)\ncalculate loss on mini-batch and approximate gradient:\n\n\\[\\nabla L(\\theta) \\approx \\frac{1}{m} \\sum_{i=1}^m \\nabla \\ell(y_i, f(x_i;\\theta))\\]\n\nupdate parameter one step\n\n\\[\\theta_{t+1} = \\theta_t - \\alpha \\nabla L(\\theta)\\]"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#training-neural-networks-1",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#training-neural-networks-1",
    "title": "An introduction to AI for biostatisticians",
    "section": "Training neural networks",
    "text": "Training neural networks\n\nbig networks require much memory and computation: do parallel on graphics processing units (GPUs) with mini-batches of data (i.e. stochastic gradient descent)\ntrain on training data, validate on validation data\nafter all tuning is done, evaluate on test data\nhow to prevent over-fitting?"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#regularization",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#regularization",
    "title": "An introduction to AI for biostatisticians",
    "section": "Regularization",
    "text": "Regularization\n\nregularization:\n\nL1 (lasso) / L2 (Ridge): add penalty to weights"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#early-stopping",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#early-stopping",
    "title": "An introduction to AI for biostatisticians",
    "section": "Early stopping",
    "text": "Early stopping"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#regularization-1",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#regularization-1",
    "title": "An introduction to AI for biostatisticians",
    "section": "Regularization",
    "text": "Regularization\n\nregularization:\n\nL1 (lasso) / L2 (Ridge): add penalty to weights\nearly stopping: stop training when validation error starts increasing\nrandom initialization: initialize weights randomly\nalso:\n\ndropout: randomly set some weights to zero\nbatch normalization: normalize inputs of each layer\ndata augmentation: increase diversity of training data\n\n\n\n\n\n\n\n\n\n\nParameter counting is a bad proxy for model complexity in neural networks\n\n\nWhereas in regression models, model complexity is well-captured by the number of parameters, this is not the case for neural networks."
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#convolutional-neural-networks",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#convolutional-neural-networks",
    "title": "An introduction to AI for biostatisticians",
    "section": "Convolutional Neural Networks",
    "text": "Convolutional Neural Networks\nImage as matrix of pixel values\n\nDOI: 10.1093/llc/fqy085"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#convolutional-neural-networks-1",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#convolutional-neural-networks-1",
    "title": "An introduction to AI for biostatisticians",
    "section": "Convolutional Neural Networks",
    "text": "Convolutional Neural Networks\nConvolution operation"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#convolutional-neural-networks-2",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#convolutional-neural-networks-2",
    "title": "An introduction to AI for biostatisticians",
    "section": "Convolutional Neural Networks",
    "text": "Convolutional Neural Networks\nImages have local structure"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#convolutional-neural-networks-3",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#convolutional-neural-networks-3",
    "title": "An introduction to AI for biostatisticians",
    "section": "Convolutional Neural Networks",
    "text": "Convolutional Neural Networks\nCNNs build hierarchical features with local invariant structure"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#where-would-cnns-be-useful-in-healthcare",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#where-would-cnns-be-useful-in-healthcare",
    "title": "An introduction to AI for biostatisticians",
    "section": "Where would CNNs be useful in healthcare?",
    "text": "Where would CNNs be useful in healthcare?\n\nimages crucial importance in many healthcare setting, e.g. dermatology, radiology\ntake lung cancer diagnosis on chest radiographs\n\ntraditional statistical approach: ask radiologist to summarize medical image with some key features\n\ntumor size, location\noutcome: benign or malignant\n\nCNN approach: learn directly from images to outcome\n\nlearn representation while doing so\nincorporate domain knowledge (e.g. invariances to e.g. translations)"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#neural-networks-for-sequence-data",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#neural-networks-for-sequence-data",
    "title": "An introduction to AI for biostatisticians",
    "section": "Neural Networks for Sequence data",
    "text": "Neural Networks for Sequence data\n\n\n\n\nmany data are sequences: text, time series, DNA\nspecific architectures for sequence data\n\nRecurrent Neural Networks (RNNs)\nnatural language processing: Transformers (Vaswani et al. 2023)\n\n\n\n\n\n\n\nTransformer Architecture"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#chatgpt-a-stochastic-auto-regressive-conditional-generator-with-a-chatbot-interface",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#chatgpt-a-stochastic-auto-regressive-conditional-generator-with-a-chatbot-interface",
    "title": "An introduction to AI for biostatisticians",
    "section": "chatGPT: a stochastic auto-regressive conditional generator with a chatbot interface",
    "text": "chatGPT: a stochastic auto-regressive conditional generator with a chatbot interface\n\n\n\n\ntrained by predicting the next &lt;…&gt; (word)\n\nin a large corpus of text\nwith a large model\nfor a long time on expensive hardware\n\npost-processed to optimize user experience (remove offensive language, etc.)\n\n\npresent test-user with two generated answers, ask which is better\nif user picks one, use that as training signal"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#auto-regressive-conditional-generation",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#auto-regressive-conditional-generation",
    "title": "An introduction to AI for biostatisticians",
    "section": "auto-regressive conditional generation:",
    "text": "auto-regressive conditional generation:\n\\[\\begin{align}\n    \\text{word}_1 &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{prompt})\n\\end{align}\\]"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#auto-regressive-conditional-generation-1",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#auto-regressive-conditional-generation-1",
    "title": "An introduction to AI for biostatisticians",
    "section": "auto-regressive conditional generation:",
    "text": "auto-regressive conditional generation:\nPrompt=“Frank went to the bar and”\n\\[\\begin{align}\n    \\color{green}{had} &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{Frank went to the bar and})\n\\end{align}\\]"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#auto-regressive-conditional-generation-2",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#auto-regressive-conditional-generation-2",
    "title": "An introduction to AI for biostatisticians",
    "section": "auto-regressive conditional generation:",
    "text": "auto-regressive conditional generation:\nPrompt=“Frank went to the bar and”\n\\[\\begin{align}\n    \\color{green}{had} &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{Frank went to the bar and})\\\\\n    \\color{orange}{a} &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{Frank went to the bar and } \\color{green}{had})\n\\end{align}\\]"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#auto-regressive-conditional-generation-3",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#auto-regressive-conditional-generation-3",
    "title": "An introduction to AI for biostatisticians",
    "section": "auto-regressive conditional generation:",
    "text": "auto-regressive conditional generation:\nPrompt=“Frank went to the bar and”\n\\[\\begin{align}\n    \\color{green}{had} &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{Frank went to the bar and})\\\\\n    \\color{orange}{a} &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{Frank went to the bar and } \\color{green}{had})\\\\\n    \\color{red}{drink} &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{Frank went to the bar and } \\color{green}{had} \\ \\color{orange}{a})\n\\end{align}\\]"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#auto-regressive-conditional-generation-4",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#auto-regressive-conditional-generation-4",
    "title": "An introduction to AI for biostatisticians",
    "section": "auto-regressive conditional generation:",
    "text": "auto-regressive conditional generation:\nPrompt=“Frank went to the bar and”\n\\[\\begin{align}\n    \\color{green}{had} &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{Frank went to the bar and})\\\\\n    \\color{orange}{a} &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{Frank went to the bar and } \\color{green}{had})\\\\\n    \\color{red}{drink} &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{Frank went to the bar and } \\color{green}{had} \\ \\color{orange}{a})\\\\\n    \\text{STOP} &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{Frank went to the bar and } \\color{green}{had} \\ \\color{orange}{a} \\ \\color{red}{drink})\n\\end{align}\\]"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#stochastic-auto-regressive-conditional-generation",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#stochastic-auto-regressive-conditional-generation",
    "title": "An introduction to AI for biostatisticians",
    "section": "stochastic auto-regressive conditional generation:",
    "text": "stochastic auto-regressive conditional generation:\nPrompt=“Frank went to the bar and”\n\\[\\begin{align}\n    \\color{green}{met} &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{Frank went to the bar and})\n\\end{align}\\]"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#stochastic-auto-regressive-conditional-generation-1",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#stochastic-auto-regressive-conditional-generation-1",
    "title": "An introduction to AI for biostatisticians",
    "section": "stochastic auto-regressive conditional generation:",
    "text": "stochastic auto-regressive conditional generation:\nPrompt=“Frank went to the bar and”\n\\[\\begin{align}\n    \\color{green}{met} &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{Frank went to the bar and})\\\\\n    \\color{orange}{a} &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{Frank went to the bar and } \\color{green}{met})\n\\end{align}\\]"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#stochastic-auto-regressive-conditional-generation-2",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#stochastic-auto-regressive-conditional-generation-2",
    "title": "An introduction to AI for biostatisticians",
    "section": "stochastic auto-regressive conditional generation:",
    "text": "stochastic auto-regressive conditional generation:\nPrompt=“Frank went to the bar and”\n\\[\\begin{align}\n    \\color{green}{met} &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{Frank went to the bar and})\\\\\n    \\color{orange}{a} &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{Frank went to the bar and } \\color{green}{met})\\\\\n    \\color{red}{friend} &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{Frank went to the bar and } \\color{green}{met} \\ \\color{orange}{a})\n\\end{align}\\]"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#stochastic-auto-regressive-conditional-generation-3",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#stochastic-auto-regressive-conditional-generation-3",
    "title": "An introduction to AI for biostatisticians",
    "section": "stochastic auto-regressive conditional generation:",
    "text": "stochastic auto-regressive conditional generation:\nPrompt=“Frank went to the bar and”\n\\[\\begin{align}\n    \\color{green}{met} &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{Frank went to the bar and})\\\\\n    \\color{orange}{a} &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{Frank went to the bar and } \\color{green}{met})\\\\\n    \\color{red}{friend} &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{Frank went to the bar and } \\color{green}{met} \\ \\color{orange}{a})\\\\\n    \\text{STOP} &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{Frank went to the bar and } \\color{green}{met} \\ \\color{orange}{a} \\ \\color{red}{friend})\n\\end{align}\\]"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#gpt-4-scale-underlying-current-chatgpt",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#gpt-4-scale-underlying-current-chatgpt",
    "title": "An introduction to AI for biostatisticians",
    "section": "GPT-4 scale (underlying current ChatGPT)",
    "text": "GPT-4 scale (underlying current ChatGPT)"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#for-complex-tasks-neural-networks-keep-getting-better-with",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#for-complex-tasks-neural-networks-keep-getting-better-with",
    "title": "An introduction to AI for biostatisticians",
    "section": "For complex tasks, neural networks keep getting better with:",
    "text": "For complex tasks, neural networks keep getting better with:\n- more compute resources\n- bigger data\n- bigger models (enabled by data and compute)\n\n\n\n\n\n(Kaplan et al. 2020)\n\n\n\n\n\n\n\n(Kaplan et al. 2020)\n\n\n\n\n\n\n\n(Kaplan et al. 2020)"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#scaling-over-time",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#scaling-over-time",
    "title": "An introduction to AI for biostatisticians",
    "section": "scaling over time",
    "text": "scaling over time"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#neural-network-architectures",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#neural-network-architectures",
    "title": "An introduction to AI for biostatisticians",
    "section": "Neural Network Architectures",
    "text": "Neural Network Architectures\n\ncommon theme:\nuse an architecture that fits the data type well\n\nimages with local structure: CNNs\ntime series: RNNs\n\nscale!"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#rule-based-ai-versus-chatgpt",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#rule-based-ai-versus-chatgpt",
    "title": "An introduction to AI for biostatisticians",
    "section": "rule-based AI versus chatGPT",
    "text": "rule-based AI versus chatGPT\n\n\n\n\nrule-based AI:\n\nexplicit rules\nno learning, restricted to rules\ndependable, verifiable\n\n\n\n\nLLMs:\n\nno explicit rules\nlearned from data, can ‘learn’ almost anything\nnot dependable, not verifiable\nproduces text that may have appeared in training data (‘the internet’)"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#what-we-dont-know-about-chatgpt",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#what-we-dont-know-about-chatgpt",
    "title": "An introduction to AI for biostatisticians",
    "section": "What we don’t know about chatGPT",
    "text": "What we don’t know about chatGPT\n\nwhat data was it trained on, what is the architecture?\ndoes it have a world model? does it understand?\ndoes next-word prediction imply understanding?\ncan we interrogate it to self-explain: chain of thought tests?\nare these explanations faithful?\nare these explanations correct?"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#what-might-llms-be-useful-for-in-health-care",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#what-might-llms-be-useful-for-in-health-care",
    "title": "An introduction to AI for biostatisticians",
    "section": "What might LLMs be useful for in health care?",
    "text": "What might LLMs be useful for in health care?\n\nanything with expert control:\n\nadministration:\n\ndraft discharge letters\n\nthinking ‘outside the box’:\n\ngenerate hypotheses (potential diagnoses)\n\n\nmore dangerous\n\neducation\n\nunreliable\n\ndecision support"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#ai-wrap-up",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#ai-wrap-up",
    "title": "An introduction to AI for biostatisticians",
    "section": "AI wrap-up",
    "text": "AI wrap-up\n\nbeen around for long\nbecame very successful in past decades with deep learning\nimages: convolutional neural networks\nLLMs: next-word prediction\nscaling: more data, more compute, bigger models"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#references",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#references",
    "title": "An introduction to AI for biostatisticians",
    "section": "References",
    "text": "References\n\n\n\n\nKaplan, Jared, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. 2020. “Scaling Laws for Neural Language Models.” January 22, 2020. https://doi.org/10.48550/arXiv.2001.08361.\n\n\nMoen, Erick, Dylan Bannon, Takamasa Kudo, William Graf, Markus Covert, and David Van Valen. 2019. “Deep Learning for Cellular Image Analysis.” Nature Methods 16 (12): 1233–46. https://doi.org/10.1038/s41592-019-0403-1.\n\n\nRussell, Stuart, and Peter Norvig. 2020. Artificial Intelligence: A Modern Approach. Pearson. https://books.google.com?id=koFptAEACAAJ.\n\n\nSamuel, A. L. 1959. “Some Studies in Machine Learning Using the Game of Checkers.” IBM Journal of Research and Development 3 (3): 210–29. https://doi.org/10.1147/rd.33.0210.\n\n\nVaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2023. “Attention Is All You Need.” August 1, 2023. http://arxiv.org/abs/1706.03762."
  },
  {
    "objectID": "talks/250714-protect-update/index.html#updates-in-protect-methods",
    "href": "talks/250714-protect-update/index.html#updates-in-protect-methods",
    "title": "PROTECT update",
    "section": "Updates in PROTECT methods",
    "text": "Updates in PROTECT methods\n\nswap conditional hazard ratio with marginal hazard ratio\ncalculations for model checks\n\ncorrect marginalization incorporating prior likelihood of latent factor\ncompare against cross-validated baseline likelihoods (not full-batch)"
  },
  {
    "objectID": "talks/250714-protect-update/index.html#conditional-vs-marginal-hazard-ratio",
    "href": "talks/250714-protect-update/index.html#conditional-vs-marginal-hazard-ratio",
    "title": "PROTECT update",
    "section": "Conditional vs marginal hazard ratio",
    "text": "Conditional vs marginal hazard ratio\n\nrealization: PROTECT models a conditional hazard ratio for treatment (conditional on latent factor, … some other variables)\ntrials calculate a marginal hazard ratio\nthese are incommensurable\ncan calculate a marginal hazard ratio by simulating survival times from hypothetical trials using inferred parameters and patient data by setting treatment to 0 and 1 for every patient"
  },
  {
    "objectID": "talks/250714-protect-update/index.html#protect-uses-a-latent-factor-model-for-the-unobserved-confounder",
    "href": "talks/250714-protect-update/index.html#protect-uses-a-latent-factor-model-for-the-unobserved-confounder",
    "title": "PROTECT update",
    "section": "PROTECT uses a latent factor model for the unobserved confounder",
    "text": "PROTECT uses a latent factor model for the unobserved confounder\n\n\n\n\nPROTECT models the joint likelihood of ‘observables’:\n\ntreatment \\(T\\), survival \\(Y\\) and proxies \\(W\\) of fitness (performance score, fraily)\n… conditional on ‘controls’ \\(X\\) (age, stage, histology)\n\nin addition to ‘global parameters’ \\(\\theta\\) that any regression model has (e.g. treatment to outcome regression coefficient), PROTECT has ‘local parameters’ (local to every patient \\(i=1, ... N\\)): \\(F_i\\)"
  },
  {
    "objectID": "talks/250714-protect-update/index.html#protect-inference",
    "href": "talks/250714-protect-update/index.html#protect-inference",
    "title": "PROTECT update",
    "section": "PROTECT inference",
    "text": "PROTECT inference\n\nby running MCMC on the ‘training data’, we get samples from the posterior distribution over PROTECT’s parameters:\n\n\n\\[\\begin{align*}\np(\\theta,F|T,Y,W,X) &\\propto p(Y,T,W|X,\\theta,F) p(F|X, \\theta) p(\\theta)\n\\end{align*}\\]\n\nin PROTECT, the joint likelihood is formulated as the product of the observation sites following the causal factorization:\n\n\n\n\\[\\begin{align*}\np(Y,T,W|X,\\theta,F) =  p(Y|T,X,\\theta,F) p(T|X,\\theta,F) p(W|X,\\theta,F)\n\\end{align*}\\]\n\nduring inference, the posterior for latent factor \\(F_i\\) of patient \\(i\\) is informed by their full observed data: \\(X_i, W_i, T_i, Y_i\\)"
  },
  {
    "objectID": "talks/250714-protect-update/index.html#protect-model-checks",
    "href": "talks/250714-protect-update/index.html#protect-model-checks",
    "title": "PROTECT update",
    "section": "PROTECT model checks",
    "text": "PROTECT model checks\n\nmultiple models may be considered compatible with prior knowledge (in practice: different sets of priors)\nin Utrecht, we found for some priors PROTECT copied the treatment into the latent factor, leading to a violation of (a form of) positivity, and unidentifiedness of the treatment effect\nPROTECT has data-driven model checks to assess whether the latent factor ‘effectively communicates’ information between all its dependents (W, T, Y)\nfor this, we need distributions over \\(F\\) using partial information (i.e. different ‘posterior predictive modes’), e.g. ‘no-\\(Y\\)’:\n\n\n\\[P(F_i|W_i,T_i,X_i,\\theta = \\theta_s)\\]\n\nnote that for every sample \\(\\theta_s\\) of the posterior distribution of global parameters, this distirbution is different"
  },
  {
    "objectID": "talks/250714-protect-update/index.html#nested-integratoin",
    "href": "talks/250714-protect-update/index.html#nested-integratoin",
    "title": "PROTECT update",
    "section": "Nested integratoin",
    "text": "Nested integratoin\n\\[P(F_i|W_i,T_i,X_i,\\theta = \\theta_s)\\]\n\nto calculate predictive likelihoods, for example for \\(Y\\) given \\(X,W,T\\), we need to do nested integration:\n\n\n\\[\\begin{align*}\nl(Y_i|X_i,W_i,T_i,\\{\\theta_s\\}) &= \\sum_s l(Y_i|X_i,W_i,T_i,\\theta_s) \\\\\n                                &= \\sum_s \\int_{-\\infty}^{\\infty}l(Y_i|X_i,W_i,T_i,f,\\theta_s)p(f|T_i,W_i,X_i,\\theta_s)df\n\\end{align*}\\]"
  },
  {
    "objectID": "talks/250714-protect-update/index.html#nested-integration-done-right",
    "href": "talks/250714-protect-update/index.html#nested-integration-done-right",
    "title": "PROTECT update",
    "section": "Nested integration done right",
    "text": "Nested integration done right\n\nwe need to numerically approximate the integrals\nthis approximation should be unbiased and good enough to not be sensitive to e.g. the random seed for MCMC\nwe can approximate by running separate MCMC for every sample \\(\\theta_s\\), or a subset\nbecause this is effectively a large set of 1D integrals, can use faster approximation"
  },
  {
    "objectID": "talks/250714-protect-update/index.html#approximation-in-original-protect",
    "href": "talks/250714-protect-update/index.html#approximation-in-original-protect",
    "title": "PROTECT update",
    "section": "approximation in original PROTECT",
    "text": "approximation in original PROTECT\n\n\ntake a grid of values for \\(f\\), for each value (and a given \\(\\theta_s\\)), calculate the joint likelihood of the observables for that posterior predictive mode (e.g. \\(W_i,T_i\\))\ncalculate the weighted sum of the log-likelihood of observed \\(Y_i\\), weighted by the joint likelihood of the \\(F-\\)conditioning observables\nomission: calculation did not weigh in the prior probability of \\(f\\), so the predictive likelihoods do not correspond to the actual PROTECT model"
  },
  {
    "objectID": "talks/250714-protect-update/index.html#new-solution-use-gauss-hermite-quadrature",
    "href": "talks/250714-protect-update/index.html#new-solution-use-gauss-hermite-quadrature",
    "title": "PROTECT update",
    "section": "‘new’ solution: use Gauss-Hermite Quadrature",
    "text": "‘new’ solution: use Gauss-Hermite Quadrature\n\n\n\n\nto integrate over a gaussian distribution, pick \\(K\\) carefully chosen points \\(X_k\\) with corresponding weights \\(W_k\\)\nimplemented in PROTECT library, consequences:\n\nwith much fewer points (\\(K=32\\)),\nmuch better approximation,\nincorporates prior over \\(f\\)\n\nthe new approach is tested in cases with analytically knwon likelihoods (gaussian outcome and proxies)\n\n\n\n\n\n\nBy Qwfp - Own work, CC BY-SA 3.0, https://commons.wikimedia.org/w/index.php?curid=10803823"
  },
  {
    "objectID": "talks/250714-protect-update/index.html#new-utrecht-results",
    "href": "talks/250714-protect-update/index.html#new-utrecht-results",
    "title": "PROTECT update",
    "section": "New Utrecht results",
    "text": "New Utrecht results\n\nrct: log(HR) -0.17\nbefore:\n\nselected hyperparameters: s_bftx: 2.5, s_bfy: {0.1, 1.0, 2.5}\nb_txbinary_y_marginal 0.010 (sd: 0.223, 95 hdi: -0.409 - 0.450)\n\nnow:\n\nselected hyperparameters:\n\nsbftxs = np.array([0.1, 2.5, 10.0, 10.0, 100.0, 100.0])\nsbfys = np.array([1.0, 1.0, 1.0, 2.5, 1.0, 2.5])\n\nb_tx_y_marginal: 0.067 (sd: 0.229, 95 hdi: -0.356 - 0.525)\nmarginalized HR: 0.033 (sd: 0.20)"
  },
  {
    "objectID": "talks/250714-protect-update/index.html#utrecht-overlap",
    "href": "talks/250714-protect-update/index.html#utrecht-overlap",
    "title": "PROTECT update",
    "section": "Utrecht overlap?",
    "text": "Utrecht overlap?"
  },
  {
    "objectID": "talks/251202-pui-seminar-sfp/index.html#prediction-model-performance-versus-healthcare-impact",
    "href": "talks/251202-pui-seminar-sfp/index.html#prediction-model-performance-versus-healthcare-impact",
    "title": "Self-fulfilling prophecies: But is the prophet heard?",
    "section": "Prediction model performance versus healthcare impact",
    "text": "Prediction model performance versus healthcare impact\n\nmany prediction models: given feature \\(X\\), estimate probability outcome \\(Y\\)\n\ne.g. given age, cholesterol and sex, predict 10-year risk of a heart attack\n\nevaluated on predictive performance: calibration and discrimination (AUC)"
  },
  {
    "objectID": "talks/251202-pui-seminar-sfp/index.html#prediction-model-performance-versus-healthcare-impact-1",
    "href": "talks/251202-pui-seminar-sfp/index.html#prediction-model-performance-versus-healthcare-impact-1",
    "title": "Self-fulfilling prophecies: But is the prophet heard?",
    "section": "Prediction model performance versus healthcare impact",
    "text": "Prediction model performance versus healthcare impact\n\nthen used for decision support\n\ne.g. give statins if predicted risk of heart attack &gt; 10%\n\naim: improve healthcare outcomes, without over-treating\nsold as ‘personalized healthcare’, from ‘one-size-fits-all’ to ‘right treatment for the right patient’\nthe hope is: better predictive performance \\(\\implies\\) better impact"
  },
  {
    "objectID": "talks/251202-pui-seminar-sfp/index.html#what-happened-here",
    "href": "talks/251202-pui-seminar-sfp/index.html#what-happened-here",
    "title": "Self-fulfilling prophecies: But is the prophet heard?",
    "section": "What happened here?",
    "text": "What happened here?\n\nhad a ‘good’ model, got a bad policy"
  },
  {
    "objectID": "talks/251202-pui-seminar-sfp/index.html#regulation-to-the-rescue-we-need-to-monitor-ai-models",
    "href": "talks/251202-pui-seminar-sfp/index.html#regulation-to-the-rescue-we-need-to-monitor-ai-models",
    "title": "Self-fulfilling prophecies: But is the prophet heard?",
    "section": "Regulation to the rescue: we need to monitor (AI) models",
    "text": "Regulation to the rescue: we need to monitor (AI) models"
  },
  {
    "objectID": "talks/251202-pui-seminar-sfp/index.html#lets-monitor-the-model-performance-over-time",
    "href": "talks/251202-pui-seminar-sfp/index.html#lets-monitor-the-model-performance-over-time",
    "title": "Self-fulfilling prophecies: But is the prophet heard?",
    "section": "Let’s monitor the model performance over time",
    "text": "Let’s monitor the model performance over time"
  },
  {
    "objectID": "talks/251202-pui-seminar-sfp/index.html#what-happened-in-monitoring",
    "href": "talks/251202-pui-seminar-sfp/index.html#what-happened-in-monitoring",
    "title": "Self-fulfilling prophecies: But is the prophet heard?",
    "section": "What happened in monitoring?",
    "text": "What happened in monitoring?\n\nthe model re-inforced its own predictions (self-fulfilling prophecy)\ntook a measure of predictive performance (AUC)\nmistook it for a measure of (good) impact"
  },
  {
    "objectID": "talks/251202-pui-seminar-sfp/index.html#our-paper",
    "href": "talks/251202-pui-seminar-sfp/index.html#our-paper",
    "title": "Self-fulfilling prophecies: But is the prophet heard?",
    "section": "Our paper",
    "text": "Our paper\nWe formalized the simplest general case\n\nbefore: everyone treated (or untreated)\nnew binary feature \\(X\\)\noutcome prediction model: \\(\\mu(x) = P(Y=1|X=x)\\)\nnew policy based on OPM: treat when \\(\\mu(x) &gt; \\lambda\\) (assume non-constant policy)\n\n\nDefine:\n\nharmful: new policy leads to worse outcomes (for \\(X=x\\))\nself-fulfilling: after deployment, re-evaluating the model yields better AUC"
  },
  {
    "objectID": "talks/251202-pui-seminar-sfp/index.html#when-can-harmful-self-fulfilling-prophecies-occur",
    "href": "talks/251202-pui-seminar-sfp/index.html#when-can-harmful-self-fulfilling-prophecies-occur",
    "title": "Self-fulfilling prophecies: But is the prophet heard?",
    "section": "When can harmful self-fulfilling prophecies occur?",
    "text": "When can harmful self-fulfilling prophecies occur?\n\nfor a grid of values of:\n\nbaseline outcome rates\ntreatment effect for \\(X=0\\)\ntreatment effect for \\(X=1\\) (treatment interaction)\nprevalence of \\(X\\)\nhistoric policy and interpretation of \\(Y\\)\n\ncalculate:\n\nexpected values of outcomes (harmful?)\npre- and post-deployment AUC (self-fulfilling?)\n\nquestion: Can harmful self-fulfilling prophecies occur in realistic scenarios?"
  },
  {
    "objectID": "talks/251202-pui-seminar-sfp/index.html#harmful-self-fulfilling-prophecies-occur-in-cases-without-extreme-treatment-interaction-effects",
    "href": "talks/251202-pui-seminar-sfp/index.html#harmful-self-fulfilling-prophecies-occur-in-cases-without-extreme-treatment-interaction-effects",
    "title": "Self-fulfilling prophecies: But is the prophet heard?",
    "section": "Harmful self-fulfilling prophecies occur in cases without extreme treatment (interaction) effects",
    "text": "Harmful self-fulfilling prophecies occur in cases without extreme treatment (interaction) effects"
  },
  {
    "objectID": "talks/251202-pui-seminar-sfp/index.html#calibration-result",
    "href": "talks/251202-pui-seminar-sfp/index.html#calibration-result",
    "title": "Self-fulfilling prophecies: But is the prophet heard?",
    "section": "Calibration result",
    "text": "Calibration result\n\n\n\nergo deployment of model was useless"
  },
  {
    "objectID": "talks/251202-pui-seminar-sfp/index.html#editorial",
    "href": "talks/251202-pui-seminar-sfp/index.html#editorial",
    "title": "Self-fulfilling prophecies: But is the prophet heard?",
    "section": "Editorial",
    "text": "Editorial"
  },
  {
    "objectID": "talks/251202-pui-seminar-sfp/index.html#press-coverage---urgent-mail",
    "href": "talks/251202-pui-seminar-sfp/index.html#press-coverage---urgent-mail",
    "title": "Self-fulfilling prophecies: But is the prophet heard?",
    "section": "Press coverage - urgent mail",
    "text": "Press coverage - urgent mail"
  },
  {
    "objectID": "talks/251202-pui-seminar-sfp/index.html#press-coverage",
    "href": "talks/251202-pui-seminar-sfp/index.html#press-coverage",
    "title": "Self-fulfilling prophecies: But is the prophet heard?",
    "section": "Press coverage",
    "text": "Press coverage"
  },
  {
    "objectID": "talks/251202-pui-seminar-sfp/index.html#press-coverage-1",
    "href": "talks/251202-pui-seminar-sfp/index.html#press-coverage-1",
    "title": "Self-fulfilling prophecies: But is the prophet heard?",
    "section": "Press coverage",
    "text": "Press coverage"
  },
  {
    "objectID": "talks/251202-pui-seminar-sfp/index.html#science-media-center-roundup-7-experts",
    "href": "talks/251202-pui-seminar-sfp/index.html#science-media-center-roundup-7-experts",
    "title": "Self-fulfilling prophecies: But is the prophet heard?",
    "section": "Science Media Center Roundup (7 experts)",
    "text": "Science Media Center Roundup (7 experts)"
  },
  {
    "objectID": "talks/251202-pui-seminar-sfp/index.html#science-media-center-roundup-7-experts-1",
    "href": "talks/251202-pui-seminar-sfp/index.html#science-media-center-roundup-7-experts-1",
    "title": "Self-fulfilling prophecies: But is the prophet heard?",
    "section": "Science Media Center Roundup (7 experts)",
    "text": "Science Media Center Roundup (7 experts)\n\nWithholding lifesaving treatments: When AI predicts low survival for certain patients, clinicians may deny treatment, causing worse outcomes that falsely validate the model.\nRehabilitation triage bias: AI tools predicting poor recovery after surgery can lead hospitals to allocate fewer rehab resources to those patients, directly causing the poor outcomes the model anticipated.\nPost-deployment performance paradox: If real-world care improves outcomes for certain patients, models trained on historical data may appear to “fail,” encouraging withdrawal of beneficial changes and reinforcing the old, harmful patterns.\nPerpetuating historical under-treatment: Models trained on biased historical data may predict poor outcomes for groups who were previously under-treated, and clinicians acting on these predictions can continue the cycle, worsening outcomes and deepening disparities.\nGeneralisation beyond healthcare: Predictive models used in policing can label historically over-policed demographics as “high risk,” triggering intensified surveillance that produces the very outcomes used to justify the predictions."
  },
  {
    "objectID": "talks/251202-pui-seminar-sfp/index.html#how-about-guidlines-and-regulation",
    "href": "talks/251202-pui-seminar-sfp/index.html#how-about-guidlines-and-regulation",
    "title": "Self-fulfilling prophecies: But is the prophet heard?",
    "section": "How about guidlines and regulation?",
    "text": "How about guidlines and regulation?\n\nreporting guidelines (e.g. TRIPOD+AI / PROBAST+AI (Collins et al. 2024; Moons et al. 2025)) do not provide enough evidence for safe deployment (“Prognostic Models for Decision Support Need to Report Their Targeted Treatments and the Expected Changes in Treatment Decisions” 2024)\nsome acceptance criteria lists (AJCC) even allow for harmful self-fulfilling prophecies (Kattan et al. 2016)\nEMA and FDA are developing monitoring guidelines, mostly emphasis on predictive performance, but good performance \\(\\neq\\) postive impact"
  },
  {
    "objectID": "talks/251202-pui-seminar-sfp/index.html#reflection",
    "href": "talks/251202-pui-seminar-sfp/index.html#reflection",
    "title": "Self-fulfilling prophecies: But is the prophet heard?",
    "section": "Reflection",
    "text": "Reflection\n\ngot good attention from both scientific community and press\nus: one (of many) warnings, not guide for best practices\nneed good guidance on model development, evaluation and monitoring with a view of impact"
  },
  {
    "objectID": "talks/251202-pui-seminar-sfp/index.html#references",
    "href": "talks/251202-pui-seminar-sfp/index.html#references",
    "title": "Self-fulfilling prophecies: But is the prophet heard?",
    "section": "References",
    "text": "References\n\n\nCollins, Gary S., Karel G. M. Moons, Paula Dhiman, Richard D. Riley, Andrew L. Beam, Ben Van Calster, Marzyeh Ghassemi, et al. 2024. “TRIPOD+AI Statement: Updated Guidance for Reporting Clinical Prediction Models That Use Regression or Machine Learning Methods.” BMJ 385 (April): e078378. https://doi.org/10.1136/bmj-2023-078378.\n\n\nKattan, Michael W., Kenneth R. Hess, Mahul B. Amin, Ying Lu, Karl G. M. Moons, Jeffrey E. Gershenwald, Phyllis A. Gimotty, et al. 2016. “American Joint Committee on Cancer Acceptance Criteria for Inclusion of Risk Models for Individualized Prognosis in the Practice of Precision Medicine.” CA: A Cancer Journal for Clinicians 66 (5): 370–74. https://doi.org/10.3322/caac.21339.\n\n\nMoons, Karel G. M., Johanna A. A. Damen, Tabea Kaul, Lotty Hooft, Constanza Andaur Navarro, Paula Dhiman, Andrew L. Beam, et al. 2025. “PROBAST+AI: An Updated Quality, Risk of Bias, and Applicability Assessment Tool for Prediction Models Using Regression or Artificial Intelligence Methods.” BMJ 388 (March): e082505. https://doi.org/10.1136/bmj-2024-082505.\n\n\n“Prognostic Models for Decision Support Need to Report Their Targeted Treatments and the Expected Changes in Treatment Decisions.” 2024, December. https://www.bmj.com/content/385/bmj-2023-078378/rr-1.\n\n\nVan Amsterdam, Wouter A. C., Nan Van Geloven, Jesse H. Krijthe, Rajesh Ranganath, and Giovanni Cinà. 2025. “When Accurate Prediction Models Yield Harmful Self-Fulfilling Prophecies.” Patterns 6 (4): 101229. https://doi.org/10.1016/j.patter.2025.101229."
  },
  {
    "objectID": "talks/251202-pui-seminar-sfp/index.html#deterministic-evaluation-of-usefulness-of-policy",
    "href": "talks/251202-pui-seminar-sfp/index.html#deterministic-evaluation-of-usefulness-of-policy",
    "title": "Self-fulfilling prophecies: But is the prophet heard?",
    "section": "Deterministic evaluation of usefulness of policy",
    "text": "Deterministic evaluation of usefulness of policy"
  },
  {
    "objectID": "talks/251201-aimethodslab-causality/index.html#todays-program",
    "href": "talks/251201-aimethodslab-causality/index.html#todays-program",
    "title": "Causality in Prediction Research & Target Trial Emulation",
    "section": "Today’s program",
    "text": "Today’s program\n\nWouter van Amsterdam: mini tutorial in confounding and causal inference\nOisín Ryan: Target Trial Emulation for vaccine safety studies\nSteven Hageman: Prediction models for Cardiovascular Risk management\nLotta Meijerink: Prediction models for treatment decisions in Radiotherapy"
  },
  {
    "objectID": "talks/251201-aimethodslab-causality/index.html#predictions-and-associations",
    "href": "talks/251201-aimethodslab-causality/index.html#predictions-and-associations",
    "title": "Causality in Prediction Research & Target Trial Emulation",
    "section": "Predictions and associations",
    "text": "Predictions and associations\n“What to expect when we passively observe the world”"
  },
  {
    "objectID": "talks/251201-aimethodslab-causality/index.html#what-are-causal-questions",
    "href": "talks/251201-aimethodslab-causality/index.html#what-are-causal-questions",
    "title": "Causality in Prediction Research & Target Trial Emulation",
    "section": "What are causal questions?",
    "text": "What are causal questions?\nQuestions with an element of ‘what if’\n\nWhat will happen if we treat all patients with A (versus B)?"
  },
  {
    "objectID": "talks/251201-aimethodslab-causality/index.html#what-if-we-send-all-babies-to-the-hospital-for-delivery",
    "href": "talks/251201-aimethodslab-causality/index.html#what-if-we-send-all-babies-to-the-hospital-for-delivery",
    "title": "Causality in Prediction Research & Target Trial Emulation",
    "section": "What if we send all babies to the hospital for delivery?",
    "text": "What if we send all babies to the hospital for delivery?"
  },
  {
    "objectID": "talks/251201-aimethodslab-causality/index.html#home-delivery-versus-hospital-delivery",
    "href": "talks/251201-aimethodslab-causality/index.html#home-delivery-versus-hospital-delivery",
    "title": "Causality in Prediction Research & Target Trial Emulation",
    "section": "Home delivery versus hospital delivery",
    "text": "Home delivery versus hospital delivery\n\nYou’re a data scientist in a children’s hospital\nHave data on\n\ndelivery location (home or hospital)\nneonatal outcomes (good or bad)\npregnancy risk (high or low)\n\nQuestion: if we send all deliveries to the hospital, will neonatal outcomes improve?"
  },
  {
    "objectID": "talks/251201-aimethodslab-causality/index.html#observed-data",
    "href": "talks/251201-aimethodslab-causality/index.html#observed-data",
    "title": "Causality in Prediction Research & Target Trial Emulation",
    "section": "Observed data",
    "text": "Observed data\n\npercentage of good neonatal outcomes\n\n\n\n\nlocation\n\n\n\n\n\n\n\nhome\nhospital\n\n\nrisk\nlow\n648 / 720 = 90%\n19 / 20 = 95%\n\n\n\n\nbetter outcomes for babies with low risk when delivered in the hospital"
  },
  {
    "objectID": "talks/251201-aimethodslab-causality/index.html#observed-data-1",
    "href": "talks/251201-aimethodslab-causality/index.html#observed-data-1",
    "title": "Causality in Prediction Research & Target Trial Emulation",
    "section": "Observed data",
    "text": "Observed data\n\npercentage of good neonatal outcomes\n\n\n\n\nlocation\n\n\n\n\n\n\n\nhome\nhospital\n\n\nrisk\nlow\n648 / 720 = 90%\n19 / 20 = 95%\n\n\n\nhigh\n40 / 80 = 50%\n144 / 180 = 80%\n\n\n\n\nbetter outcomes for babies delivered in the hospital for both risk groups\nbetween 5% and 30% better"
  },
  {
    "objectID": "talks/251201-aimethodslab-causality/index.html#observed-data-2",
    "href": "talks/251201-aimethodslab-causality/index.html#observed-data-2",
    "title": "Causality in Prediction Research & Target Trial Emulation",
    "section": "Observed data",
    "text": "Observed data\n\n\n\n\n\nlocation\n\n\n\n\n\n\n\nhome\nhospital\n\n\nrisk\nlow\n648 / 720 = 90%\n19 / 20 = 95%\n\n\n\nhigh\n40 / 80 = 50%\n144 / 180 = 80%\n\n\n\n\n\n\n\n\n\nmarginal\n688 / 800 = 86%\n163 / 200 = 81.5%\n\n\n\n\nbetter outcomes for babies delivered in the hospital for both risk groups\nbut not better marginal (‘overall’)\nhow is this possible?\nwhat is the correct way to estimate the effect of delivery location?"
  },
  {
    "objectID": "talks/251201-aimethodslab-causality/index.html#causal-directed-acyclic-graphs",
    "href": "talks/251201-aimethodslab-causality/index.html#causal-directed-acyclic-graphs",
    "title": "Causality in Prediction Research & Target Trial Emulation",
    "section": "Causal Directed Acyclic Graphs",
    "text": "Causal Directed Acyclic Graphs\ndiagram that represents our assumptions on causal relations\n\nnodes are variables\narrows (directed edges) point from cause to effect"
  },
  {
    "objectID": "talks/251201-aimethodslab-causality/index.html#making-a-dag-for-our-example",
    "href": "talks/251201-aimethodslab-causality/index.html#making-a-dag-for-our-example",
    "title": "Causality in Prediction Research & Target Trial Emulation",
    "section": "Making a DAG for our example:",
    "text": "Making a DAG for our example:\n\n\n\n\n\n\nassumptions:\n\nwomen with high risk of bad neonatal outcomes (pregnancy risk) are referred to the hospital for delivery\nhospital deliveries lead to better outcomes for babies as more emergency treatments possible\nboth pregnancy risk and hospital delivery cause neonatal outcome\n\nthe other variable pregnancy risk is a common cause of the treatment (hospital delivery) and the outcome (this is called a confounder)"
  },
  {
    "objectID": "talks/251201-aimethodslab-causality/index.html#intervention-as-graph-surgery",
    "href": "talks/251201-aimethodslab-causality/index.html#intervention-as-graph-surgery",
    "title": "Causality in Prediction Research & Target Trial Emulation",
    "section": "Intervention as graph surgery",
    "text": "Intervention as graph surgery\n\nOur question: what if we send all deliveries to the hospital?\nIn this hypothetical world, all deliveries (low risk and high risk) go to hospital (or home)\nCan be observed in a Randomized Controlled Trial (RCT)\nIn the DAG: the arrow from pregnancy risk to hospital delivery should be removed"
  },
  {
    "objectID": "talks/251201-aimethodslab-causality/index.html#using-dags-to-identify-causal-effects",
    "href": "talks/251201-aimethodslab-causality/index.html#using-dags-to-identify-causal-effects",
    "title": "Causality in Prediction Research & Target Trial Emulation",
    "section": "Using DAGs to identify causal effects",
    "text": "Using DAGs to identify causal effects\n\nin our example, we can calculate the causal effect of hospital delivery on neonatal outcome by looking at the effect within levels of pregnancy risk\nthis is an example of a broader theme:\n\nwe have non-experimental (observational) data\nwould like to answer a question about an intervention, as we would observe in a randomized trial\ncausal inference toolbox: express assumptions on our data\nderive how to estimate the causal effect from observational data (covariate adjustment, inverse probability weighting, etc)"
  },
  {
    "objectID": "talks/251201-aimethodslab-causality/index.html#todays-program-1",
    "href": "talks/251201-aimethodslab-causality/index.html#todays-program-1",
    "title": "Causality in Prediction Research & Target Trial Emulation",
    "section": "Today’s program",
    "text": "Today’s program\n\nWouter van Amsterdam: mini tutorial in confounding and causal inference\nOisín Ryan: Target Trial Emulation for vaccine safety studies\nSteven Hageman: Prediction models for Cardiovascular Risk management\nLotta Meijerink: Prediction models for treatment decisions in Radiotherapy"
  },
  {
    "objectID": "talks/250507-effect-measure-stability-meeting/index.html#history",
    "href": "talks/250507-effect-measure-stability-meeting/index.html#history",
    "title": "Effect Measure Stability",
    "section": "History",
    "text": "History\n\nApril 2023, read paper “Risk Ratio, odds ratio, risk difference… Which causal measure is easier to generalize?”\nReached out to Benedicte, had a conversation\nThought of an empirical project to test an hypothesis inspired by the paper\nEarly 2024, Rodrigue Ndabashinze reached out to do his epidemiology MSc. thesis with me\nJan 2025, started on this project, together with Valentijn de Jong\nApr 2025, meet Julie at EurCIM, decide to present some early results from our project"
  },
  {
    "objectID": "talks/250507-effect-measure-stability-meeting/index.html#effects-of-interventions",
    "href": "talks/250507-effect-measure-stability-meeting/index.html#effects-of-interventions",
    "title": "Effect Measure Stability",
    "section": "Effects of interventions",
    "text": "Effects of interventions\n\nIn healthcare we need to make decisions regarding interventions (‘treatments’), based on their ‘effects’\nLet \\(Y^0,Y^1\\) be potential outcomes under treatment \\(0\\) and \\(1\\) respectively:\n\n\n\\[ \\Psi = f(E[Y^0], E[Y^1]) \\]\n\nIf \\(Y\\) is binary, \\(\\Psi\\) could be a risk difference (\\(\\Psi_{rd}\\)), risk ratio (\\(\\Psi_{rr}\\)), survival ratio (\\(\\Psi_{sr}\\)), number needed to treat, odds ratio, etc."
  },
  {
    "objectID": "talks/250507-effect-measure-stability-meeting/index.html#estimating-effects",
    "href": "talks/250507-effect-measure-stability-meeting/index.html#estimating-effects",
    "title": "Effect Measure Stability",
    "section": "Estimating effects",
    "text": "Estimating effects\n\nWe get estimates of treatment effects from RCTs, as these give us random samples from \\(P(Y^0),P(Y^1)\\), \\(D=\\)\n\n\n\n\n\n\n\\(Y=0\\)\n\\(Y=1\\)\n\n\n\n\ncontrol\n\\(\\sum_{i}^{n_0} Y_i^0 = 0\\)\n\\(\\sum_{i}^{n_0} Y_i^0 = 1\\)\n\n\ntreatment\n\\(\\sum_i^{n_1} Y_i^1 = 0\\)\n\\(\\sum_i^{n_1} Y_i^1 = 1\\)\n\n\n\n\n\nFor a well-conducted RCT, many choices \\(\\Psi\\) are a valid measure of the treatment effect"
  },
  {
    "objectID": "talks/250507-effect-measure-stability-meeting/index.html#how-to-use-the-rct-evidence",
    "href": "talks/250507-effect-measure-stability-meeting/index.html#how-to-use-the-rct-evidence",
    "title": "Effect Measure Stability",
    "section": "How to use the RCT evidence?",
    "text": "How to use the RCT evidence?\n\nTypical highest standard of evidence: have a series of all \\(k\\) published RCT results, \\(D_1, \\ldots, D_k\\).\nCalculate an effect meausre \\(\\Psi_i\\) for each trial (with variance estimate \\(v_i\\)), and then combine them to get a single estimate with meta-analysis.\n\n\n\\[\\begin{aligned}\n\\Psi_i &\\;\\sim\\; N \\bigl(\\mu,\\;v_i\\bigr), \\quad i=1,\\dots,k\n\\end{aligned}\\]\n\n\\(\\mu\\) is overall effect measure; \\(\\Psi\\) typically on log scale, or risk difference\nthis is a ‘fixed effects’ model with a single underlying treatment effect"
  },
  {
    "objectID": "talks/250507-effect-measure-stability-meeting/index.html#heterogeneity-poses-challenges-for-decision-making",
    "href": "talks/250507-effect-measure-stability-meeting/index.html#heterogeneity-poses-challenges-for-decision-making",
    "title": "Effect Measure Stability",
    "section": "Heterogeneity poses challenges for decision making",
    "text": "Heterogeneity poses challenges for decision making\n\n\\(\\Psi\\) is a functional of the underlying joint distribution of \\(Y^0\\) and \\(Y^1\\), which may depend on covariates \\(X\\):\n\n\n\\[ \\Psi(x) = f(E[Y^0|X=x], E[Y^1|X=x]) \\]\n\nNeed to make a decision on interventions for a specific subpopulation (‘target’) with a specific distribution: \\(P^*(Y^0,Y^1,X)\\)"
  },
  {
    "objectID": "talks/250507-effect-measure-stability-meeting/index.html#issues-with-trial-evidence",
    "href": "talks/250507-effect-measure-stability-meeting/index.html#issues-with-trial-evidence",
    "title": "Effect Measure Stability",
    "section": "Issues with trial evidence",
    "text": "Issues with trial evidence\n\nTrials are typically conducted in specific subpopulations, which\n\nmay not cover \\(P^*(X)\\) (e.g. elderly, pregnant women and children are often excluded)\nmay have a different disctribution of \\(X\\)"
  },
  {
    "objectID": "talks/250507-effect-measure-stability-meeting/index.html#meta-analysis-with-random-effects",
    "href": "talks/250507-effect-measure-stability-meeting/index.html#meta-analysis-with-random-effects",
    "title": "Effect Measure Stability",
    "section": "Meta-analysis with random effects",
    "text": "Meta-analysis with random effects\n\\[\\begin{aligned}\n\\Psi_i \\mid \\theta_i &\\;\\sim\\; N \\bigl(\\theta_i,\\;v_i\\bigr), \\quad i=1,\\dots,k \\\\[6pt]\n\\theta_i \\mid \\mu,\\tau &\\;\\sim\\; N\\bigl(\\mu,\\;\\tau^{2}\\bigr)\n\\end{aligned}\\]\n\n\\(\\mu\\) is overall effect measure, \\(\\tau\\) is heterogeneity of the effect measure (which could be 0)\nthis is a random effects model, setting \\(\\tau=0\\) retreives the ‘fixed effects’ model"
  },
  {
    "objectID": "talks/250507-effect-measure-stability-meeting/index.html#motivation-1",
    "href": "talks/250507-effect-measure-stability-meeting/index.html#motivation-1",
    "title": "Effect Measure Stability",
    "section": "Motivation",
    "text": "Motivation\n\nNeed to make assumptions to pick best measure for:\n\nlearning about our target population\ndecision making\n\nnote: decision making may depend on a different effect measure (e.g. risk differences) than what is chosen / best for meta-analysis\n\n\n\n\n\n\n\n\nPotential assumption:\n\n\nThe variance in outcome risk in control arms depends more on the distribution of \\(X\\) (or on more \\(X\\)s), than the effect of the treatment (contrast between treated and control)"
  },
  {
    "objectID": "talks/250507-effect-measure-stability-meeting/index.html#project-hypothesis",
    "href": "talks/250507-effect-measure-stability-meeting/index.html#project-hypothesis",
    "title": "Effect Measure Stability",
    "section": "Project hypothesis",
    "text": "Project hypothesis\n\nFor meta-analyses of RCTs, assume presence of differences in distribution of covariates that influence the baseline risk, but not the effect of the treatment\nPerform meta-analysis for both risk-ratio and survival-ratio\nDepending on whether an outcome is a benefit or a harm, the underlying variance of the treatment effect (\\(\\tau\\)) should differ"
  },
  {
    "objectID": "talks/250507-effect-measure-stability-meeting/index.html#project-set-up",
    "href": "talks/250507-effect-measure-stability-meeting/index.html#project-set-up",
    "title": "Effect Measure Stability",
    "section": "Project set-up",
    "text": "Project set-up\n\nGo to library of meta-analyses of RCTs (Cochrane)\nDo wide search for meta-analyses of RCTs of interventions\nPull RCT-level aggregated data from Cochrane library\nClassify every outcome in every meta-analysis as benefit or harm\nre-perform meta-analysis for both risk-ratio and survival ratio\ncheck distributions of \\(\\tau\\)"
  }
]