[
  {
    "objectID": "unlisted.html",
    "href": "unlisted.html",
    "title": "Unlisted pages",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nSubtitle\n\n\n\n\n\n\nSep 23, 2022\n\n\nCausal Inference for AI meetup\n\n\nRotterdam / Leiden / Delft / Utrecht\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Wouter van Amsterdam, MD, PhD",
    "section": "",
    "text": "Twitter\n  \n  \n    \n     Linkedin\n  \n  \n    \n     ORCID\n  \n  \n    \n     github\n  \n  \n    \n     pubmed\n  \n  \n    \n     google-scholar\n  \n\n  \n  \nLearning from Historical data to make better decisions in the future\nI work on the intersection of machine learning (for flexible data analysis) and causal inference (to learn to make better decisions).\nI am an assistant professor at the University Medical Center Utrecht, working on methods and applications of machine learning and causal inference for health care. I have degrees in Physics (BSc), Medicine (MD), epidemiology (MSc) and a PhD on machine learning for healthcare, advised by Rajesh Ranganath from NYU and Joost Verhoeff, Tim Leiner and Pim de Jong from the UMC Utrecht.\n\n\n\n\nUMC Utrecht| Assistant Professor | 2023 - now\nBabylon Health | Senior Research Scientist | 2021 - 2023\nCV (pdf, feb 2025)"
  },
  {
    "objectID": "index.html#prospective-students-collaborators",
    "href": "index.html#prospective-students-collaborators",
    "title": "Wouter van Amsterdam, MD, PhD",
    "section": "Prospective students / collaborators",
    "text": "Prospective students / collaborators\nThere are 3 open PhD positions at our data science methods department, see LinkedIN One of these positions will be co-supervised by me: (preventing) prediction paradox: prediction models that when deployed affect the outcome they are tyring to predict through downstream medical decisions. Applicatans with a background in causal inference, machine learning and / or prediction research are welcome to reach out. The position is with Maarten van Smeden, Ewout Steyerberg, Oisin Ryan and myself.\nI have several open projects in the field of machine learning and causal inference. Students (MSc / PhD) with a background in statistics, data science or machine learning and good coding skills are welcome to contact me."
  },
  {
    "objectID": "index.html#news",
    "href": "index.html#news",
    "title": "Wouter van Amsterdam, MD, PhD",
    "section": "News",
    "text": "News\nI’m a guest editor for a special issue in BMC diagnostic and prognostic research titled “Validation and transparency for AI-based diagnosis and prognosis in healthcare”, together with Maarten van Smeden and Anne de Hond. Submission is open until Jan 31st 2025."
  },
  {
    "objectID": "index.html#selected-papers",
    "href": "index.html#selected-papers",
    "title": "Wouter van Amsterdam, MD, PhD",
    "section": "Selected papers",
    "text": "Selected papers\nA causal viewpoint on prediction model performance under changes in case-mix: Discrimination and calibration respond differently for prognosis and diagnosis predictions.\nvan Amsterdam, W. A. C. (2024). arXiv preprint\nurl pdf\nWhen accurate prediction models yield harmful self-fulfilling prophecies.\nvan Amsterdam, W. A. C., van Geloven, N., Krijthe, J. H., Ranganath, R., & Ciná, G. Patterns. 2025 Apr;6(4):101229. url pdf\nCausal Inference in Oncology: Why, What, How and When.\nvan Amsterdam, W. A. C., Elias, S., & Ranganath, R. (2024). Clinical Oncology.\nurl pdf\nPrognostic models for decision support need to report their targeted treatments and the expected changes in treatment decisions.\nvan Amsterdam, W. A. C. and Cinà, Giovanni and Didelez, Vanessa and Keogh, Ruth H. and Peek, Niels and Sperrin, Matthew and Vickers, Andrew J. and van Geloven, Nan and Shalit, Uri (2024). BMJ Rapid-response\nurl\nFrom algorithms to action: improving patient care requires causality.\nvan Amsterdam, W. A. C., de Jong, P. A., Verhoeff, J. J. C., Leiner, T., & Ranganath, R. (2024). BMC Medical Informatics and Decision Making\nurl pdf\nIndividual treatment effect estimation in the presence of unobserved confounding using proxies: A cohort study in stage III non-small cell lung cancer.  van Amsterdam, W. A. C., Verhoeff, J. J. C., Harlianto, N. I., Bartholomeus, G. A., Puli, A. M., de Jong, P. A., Leiner, T., van Lindert, A. S. R., Eijkemans, M. J. C., & Ranganath, R. (2022). Scientific Reports\nurl pdf\nConditional average treatment effect estimation with marginally constrained models.\nvan Amsterdam, W. A. C., & Ranganath, R. (2023). Journal of Causal Inference\nurl pdf\nEliminating biasing signals in lung cancer images for prognosis predictions with deep learning.\nvan Amsterdam, W. A. C., Verhoeff, J. J. C., de Jong, P. A., Leiner, T., & Eijkemans, M. J. C. (2019). Npj Digital Medicine\nurl pdf\nMore papers on google scholar"
  },
  {
    "objectID": "index.html#talks",
    "href": "index.html#talks",
    "title": "Wouter van Amsterdam, MD, PhD",
    "section": "Talks",
    "text": "Talks\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nSubtitle\n\n\n\n\n\n\nApr 17, 2025\n\n\nCausal Data Science in Utrecht: causality for prediction model generalization\n\n\nApplied Data Science event Utrecht University\n\n\n\n\nJan 27, 2025\n\n\nmy priorities for AI in health\n\n\nDagstuhl Seminar 2025\n\n\n\n\nNov 25, 2024\n\n\nA causal viewpoint on prediction model performance under changes in case-mix\n\n\nMethods meeting at the Julius Center, UMC Utrecht\n\n\n\n\nNov 6, 2024\n\n\nPearl Causal Hierarchy\n\n\nCausal Inference at Julius reading group\n\n\n\n\nSep 26, 2024\n\n\nAn introduction to AI for biostatisticians\n\n\nBMS-Aned seminar\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#teaching",
    "href": "index.html#teaching",
    "title": "Wouter van Amsterdam, MD, PhD",
    "section": "Teaching",
    "text": "Teaching\n\n2025 Causal Data Science summer school (see last years materials below)\n2025 European Medicines Agency course “Big Data”, module: Target Trial Emulation\n2024 Introduction to Causal Inference and Causal Data Science summer school\n2023 Big Data summer school"
  },
  {
    "objectID": "index.html#posts",
    "href": "index.html#posts",
    "title": "Wouter van Amsterdam, MD, PhD",
    "section": "Posts",
    "text": "Posts\n\n\n\n\n\n\n\n\nWhat is stronger evidence of prediction model robustness?\n\n\n\n\n\n\nWouter van Amsterdam\n\n\nApr 25, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nIs the JAMA opening up their language for causal effects?\n\n\n\n\n\n\nWouter van Amsterdam\n\n\nJun 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nPartial residual plots with multiply imputed data\n\n\n\n\n\n\nWouter van Amsterdam\n\n\nMar 22, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#students",
    "href": "index.html#students",
    "title": "Wouter van Amsterdam, MD, PhD",
    "section": "Students",
    "text": "Students\n\nJames Hesp (SciML4Medicine project) - PhD student\nBenedetta Dionisi Ferrera (INT Milan, remote) - PhD student\nSu Li (Methodology and Statistics) - MSc. student\nFlorian Metwaly (Methodology and Statistics) - MSc. student\nRodrigue Ndabashinze (Epidemiology, University of Antwerp) - MSc. student\n\n\nFormer\n\nSamil Kilinc (Applied Data Science, 2024)\nKiara Peek (Applied Data Science, 2024)\nMyra van Laar (Biomedical Sciences)\nGijs Bartholomeus (Medicine)\nNetanja Harlianto (Medicine)"
  },
  {
    "objectID": "index.html#in-the-news",
    "href": "index.html#in-the-news",
    "title": "Wouter van Amsterdam, MD, PhD",
    "section": "In the News",
    "text": "In the News\n\nOur work on harmful-selfulfilling prophecies got covered in The Independent, Pharmophorum, and 6 independent experts at an SMC-roundup\nI gave an interview for BiotechNEWs on my vision for the future of AI in healthcare pdf"
  },
  {
    "objectID": "index.html#activities",
    "href": "index.html#activities",
    "title": "Wouter van Amsterdam, MD, PhD",
    "section": "Activities",
    "text": "Activities\n\nprogram chair Workshop, MLHC 2025\nboard member BMS-ANed (Dutch biometrics society)\ncoordinator of UMC Utrecht AI methods lab\nambassador for Applied Data Science of Utrecht University\nco-coordinator of Causal Data Science Special Interest Group of Utrecht University"
  },
  {
    "objectID": "index.html#contact",
    "href": "index.html#contact",
    "title": "Wouter van Amsterdam, MD, PhD",
    "section": "Contact",
    "text": "Contact\nwamster3 at umcutrecht dot nl"
  },
  {
    "objectID": "posts/190816-lm-functional-form.html",
    "href": "posts/190816-lm-functional-form.html",
    "title": "Finding the functional form for multiple linear regression",
    "section": "",
    "text": "A frequent question that comes up when modeling continuous outcomes with multiple linear regression is what the correct functional form for the relationship between the independent variables is. TLDR: the answer is a partial residual plot. Here I will generate some data to illustrate this"
  },
  {
    "objectID": "posts/190816-lm-functional-form.html#functional-relationship-in-linear-regression",
    "href": "posts/190816-lm-functional-form.html#functional-relationship-in-linear-regression",
    "title": "Finding the functional form for multiple linear regression",
    "section": "",
    "text": "A frequent question that comes up when modeling continuous outcomes with multiple linear regression is what the correct functional form for the relationship between the independent variables is. TLDR: the answer is a partial residual plot. Here I will generate some data to illustrate this"
  },
  {
    "objectID": "posts/190816-lm-functional-form.html#data",
    "href": "posts/190816-lm-functional-form.html#data",
    "title": "Finding the functional form for multiple linear regression",
    "section": "Data",
    "text": "Data\n\nsuppressMessages({require(ggplot2); theme_set(theme_bw())})\nset.seed(12345)\nN = 1000\nx &lt;- runif(N, min = 0, max=2*pi)\nw &lt;- .5*x + sin(x) + rnorm(N, sd=.25)\nsy &lt;- rnorm(N, sd=.1)\ny &lt;- x + w + sy\ndf = data.frame(x,w,y)\n\nThe data consists of two real-valued ‘independent’ variables \\(x,w\\), where\n\\[\n\\begin{align}\nx &\\sim U(0, 2 \\pi) \\\\\n\\epsilon_w &\\sim N(0, 0.25) \\\\\n\\epsilon_y &\\sim N(0, 0.1) \\\\\nw &:= \\frac{x}{2} + \\sin(x) \\\\\ny &:= x + w + \\epsilon_y\n\\end{align}\n\\]\nClearly \\(y\\) is linear in both \\(x\\) and \\(w\\). A plot of the data:\n\nggplot(df, aes(x=x, y=w,col=y, size=y)) + \n  geom_point() + theme_minimal()\n\n\n\n\njoint distribution of x, w, y"
  },
  {
    "objectID": "posts/190816-lm-functional-form.html#plots",
    "href": "posts/190816-lm-functional-form.html#plots",
    "title": "Finding the functional form for multiple linear regression",
    "section": "Plots",
    "text": "Plots\n\nIncorrect: marginal association\nLet’s say we’re particularly interested in the relationship between \\(y\\) and \\(x\\), both conditional on \\(w\\). Looking at the marginal association between \\(y\\) and \\(x\\) with a scatterplot will set us on the wrong foot, because of the association between \\(x\\) and \\(w\\).\n\nggplot(df, aes(x=x,y=y)) + \n  geom_point()\n\n\n\n\nmarginal association between x and y\n\n\n\n\n\n\nCorrect: partial residual plot\nTo construct the correct plot, we can generate a partial residual plot, which is created with resid(lm(y~x+w))+b_x x ~ x.\nWhere b_x is the regression coefficient found through linear regression of \\(y\\) on \\(x\\) and \\(w\\). In a plot:\n\nlmfit &lt;- lm(y~x+w)\nyresid &lt;- resid(lmfit)\nb_x &lt;- coef(lmfit)['x']\nplotdata &lt;- data.frame(x, y=yresid + b_x * x)\n\nggplot(plotdata, aes(x=x,y=y)) + \n  geom_point() + \n  ylab(\"resid(lm(y~x+w)) + b_x x\")\n\n\n\n\n\n\n\nFigure 1: partial residual plot\n\n\n\n\n\n\n\nPartial residual plot when y is not linear in x\nWhat if \\(y\\) were not linear in \\(x\\)?\n\ny2 &lt;- x^2 + w + sy\nlmfit2 &lt;- lm(y2 ~ x + w)\nb_x2 &lt;- coef(lmfit2)['x']\nplotdata2 &lt;- data.frame(x, y=resid(lmfit2) + b_x2 * x)\n\nggplot(plotdata2, aes(x=x,y=y)) + \n  geom_point() + \n  ylab(\"resid(lm(y~x+w)) + b_x x\")\n\n\n\n\npartial residual plot when y not linear in x"
  },
  {
    "objectID": "posts/190816-lm-functional-form.html#conclusion",
    "href": "posts/190816-lm-functional-form.html#conclusion",
    "title": "Finding the functional form for multiple linear regression",
    "section": "Conclusion",
    "text": "Conclusion\nThe functional relationship between an outcome and a covariate in a linear regression conditional on other covariates is visualized with a partial residual plot, or:\n\nlmfit &lt;- lm(y~x+w)\nplot(resid(lmfit) + coef(lmfit)['x'] * x ~ x)"
  },
  {
    "objectID": "posts/240322-mice-partial-residual-plot.html",
    "href": "posts/240322-mice-partial-residual-plot.html",
    "title": "Partial residual plots with multiply imputed data",
    "section": "",
    "text": "In an earlier blog post I show how to plot the dependence of a response variable on covariate, both conditional on other covariates with a partial residual plot In this post I investigate how to do this when there are missing values using package mice.\nThis post will rely in Hanne Oberman’s vignette on ggmice, a plotting package for mice::mids objects."
  },
  {
    "objectID": "posts/240322-mice-partial-residual-plot.html#data-and-imputation",
    "href": "posts/240322-mice-partial-residual-plot.html#data-and-imputation",
    "title": "Partial residual plots with multiply imputed data",
    "section": "Data and imputation",
    "text": "Data and imputation\nIn this post we’ll use the boys dataset which is provided in the mice package. The mice package implements multiple imputation through chained equations1.\n\nlibrary(mice)\nlibrary(ggplot2); theme_set(theme_bw())\n\ndf &lt;- boys\n\nnimps &lt;- 5\nimp &lt;- mice(df, m = nimps, method = \"pmm\")"
  },
  {
    "objectID": "posts/240322-mice-partial-residual-plot.html#partial-residual-plot-with-complete-data",
    "href": "posts/240322-mice-partial-residual-plot.html#partial-residual-plot-with-complete-data",
    "title": "Partial residual plots with multiply imputed data",
    "section": "Partial residual plot with complete data",
    "text": "Partial residual plot with complete data\nWe’ll assume we’re interested in how weight (wgt) depends on height (hgt), corrected for all other variables. Both have missing values in the dataset.\nWe can use one of the imputed datasets to show how partial residual plots are made with complete data. With complete data, partial residual plots can be created like so:\n\ndf1 &lt;- complete(imp, 1)\n\nget_partial_resid &lt;- function(data) {\n  fit &lt;- lm(wgt~., data=data)\n  yresid &lt;- resid(fit)\n  return(yresid + coef(fit)['hgt'] * data$hgt)\n}\n\nplotdata1 &lt;- data.frame(hgt=df1$hgt, y=get_partial_resid(df1))\n\nggplot(plotdata1, aes(x=hgt, y=y)) + geom_point()\n\n\n\n\n\n\n\nFigure 1: Partial residual plot on complete data\n\n\n\n\n\nNote how this differs from the marginal association between hgt and wgt. The difference between the plots is explained by other covariates that are correlated both with hgt and wgt.\n\nggplot(df1, aes(x=hgt, y=wgt)) + geom_point()\n\n\n\n\n\n\n\nFigure 2: marginal association between age and height"
  },
  {
    "objectID": "posts/240322-mice-partial-residual-plot.html#putting-them-together",
    "href": "posts/240322-mice-partial-residual-plot.html#putting-them-together",
    "title": "Partial residual plots with multiply imputed data",
    "section": "Putting them together",
    "text": "Putting them together\nThe issue with the partial residual plot Figure 1 is that the residuals depend on the imputed values for all variables. How to go about this? We can treat the residuals as we would ‘coefficients’ in imputation and use Rubin’s rules on them. Let’s see how to do this with mice.\n\nimpdfs &lt;- complete(imp, \"all\")\nimpdfs &lt;- lapply(impdfs, function(data) data.frame(data, partial_resid=get_partial_resid(data)))\nimpdfs &lt;- lapply(1:nimps, function(i) data.frame(impdfs[[i]], impidx=i))\nimpdf_long &lt;- do.call(rbind, impdfs)\n\nNote that we cannot directly pool the residuals because they may be correlated with the imputed values for hgt. Pooling imputed values for hgt and the partial residual removes this correlation. Instead we could just plot all the values.\n\nggplot(impdf_long, aes(x=hgt, y=partial_resid)) + geom_point(aes(shape=factor(impidx)), alpha=0.5)\n\n\n\n\n\n\n\nFigure 3: partial residual plot with imputed datasets\n\n\n\n\n\nIn the future I’d like to learn how to make good bivariate estimates of these points (e.g. fitting a bivariate normal distribution). This should for example also come up in calculating sensitivity and specificity on multiply imputed datasets, as these are clearly correlated. Fully bayesian imputation is another possibility obviously."
  },
  {
    "objectID": "posts/240322-mice-partial-residual-plot.html#footnotes",
    "href": "posts/240322-mice-partial-residual-plot.html#footnotes",
    "title": "Partial residual plots with multiply imputed data",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nmultiple imputation with chained equations sequentially imputes values for all variables with missing values by building prediction models for each variable based on other variables. This imputation is done multiple times with multiple random seeds and thus results in a number of different imputed datasets. A typical analysis workflow is to do these imputations and on each imputed dataset fit a model of interest. The coefficients of these models can then be pooled using Rubin’s rules.↩︎"
  },
  {
    "objectID": "posts/240308-jaxopt-vs-r-vs-julia/index.html",
    "href": "posts/240308-jaxopt-vs-r-vs-julia/index.html",
    "title": "The need for speed, performing simulation studies in R, JAX and Julia",
    "section": "",
    "text": "Simulation experiments are important when evaluating methods but also for applied work in for example power analyses (e.g. Amsterdam, Harlianto, et al. 2022) or sensitivity analyses (e.g. Amsterdam, Verhoeff, et al. 2022). When using simulations to support scientific claims, the more experiments the better. Being able to perform simulation experiments faster allows researchers to:\nThe R language has been a popular language among many biostatisticians for a long time, but it is not generally considered the top performing language in terms of speed.  In recent years, JAX (developed by Google) and Julia have arisen as general scientific computation frameworks. JAX and Julia have grown in popularity both in the neural network community as in other scientific communities (e.g. “DifferentiableUniverseInitiative/Jax_cosmo” 2024; “SciML: Open Source Software for Scientific Machine Learning” n.d.). In this blog post I’ll compare R with JAX and Julia for a simple simulation study setup with logistic regression.\nWe’ll look at the following comparisons:"
  },
  {
    "objectID": "posts/240308-jaxopt-vs-r-vs-julia/index.html#jax-and-julia-vs-r-a-high-level-overview",
    "href": "posts/240308-jaxopt-vs-r-vs-julia/index.html#jax-and-julia-vs-r-a-high-level-overview",
    "title": "The need for speed, performing simulation studies in R, JAX and Julia",
    "section": "JAX and Julia vs R: a high level overview",
    "text": "JAX and Julia vs R: a high level overview\nJAX is a rising star in computer science and natural sciences. Without going in too much details, JAX works by translating python code into an intermediate language that can be run very efficiently on different hardware backends (CPU, GPU, TPU), possibly with just-in-time compilation (JIT). JAX prides itself on providing composable transformations for vectorization (vmap), paralellization (pmap) and automatic differentiation (grad), all compatible with jit. In R, most of the heavy lifting in terms of computation (such as fitting a logistic regression model) is implemented in high-speed languages such as C++ or Fortran. The usual R-code merely provides an interface to these languages and allows the user to feed in data and analyze results. Whereas using JAX and R means working with two languages (one language to write accessible code, another to do fast computation), Julia is a just-in-time compiled language where such translation is not needed."
  },
  {
    "objectID": "posts/240308-jaxopt-vs-r-vs-julia/index.html#the-basic-setup",
    "href": "posts/240308-jaxopt-vs-r-vs-julia/index.html#the-basic-setup",
    "title": "The need for speed, performing simulation studies in R, JAX and Julia",
    "section": "The basic setup",
    "text": "The basic setup\nWe’ll use a simple logistic regression simulation setup, where for each observation:\n\\[\n\\begin{align}\n\\mathbf{x}_{\\text{full}} &\\sim \\mathcal{N}(0,I) \\in \\mathbb{R}^{10} \\\\\ny &= ||\\mathbf{x}||_0 &gt; 0 \\\\\n\\mathbf{x}_{\\text{obs}} &= [x_0\\ x_i \\ldots x_9]\n\\end{align}\n\\]\nSo \\(y\\) is the sum of elements of \\(\\mathbf{x}_{\\text{full}}\\) and the observed \\(\\mathbf{x}_{\\text{obs}}\\) contains only the first 9 out of 10 elements of \\(\\mathbf{x}_{\\text{full}}\\).\nWe will model this data with logistic regression:\n\\[\n\\begin{align}\n    \\text{logit}(y) &= \\mathbf{x}_{\\text{obs}} \\boldsymbol{\\beta}'\\\\\n    y &\\sim \\text{Bernoulli} (\\sigma (\\mathbf{x}_{\\text{obs}} \\boldsymbol{\\beta}'))\n\\end{align}\n\\]\nwhere \\(\\boldsymbol{\\beta} = [\\beta_1,\\ldots,\\beta_9]\\) is a 9-dimensional parameter vector that is to be estimated (we’re excluding the usual intercept term). We’ll generate nrep independent datasets and estimate \\(\\boldsymbol{\\beta}\\) in each one, and finally calculate the average parameter estimates \\(\\frac{1}{\\text{nrep}}\\sum_{i=1}^{\\text{nrep}}\\boldsymbol{\\beta}^i\\).\n\nHardware\nThe hardware I had available for this comparison is:\n\nmacm1: 2020 macbook air M1, 8Gb RAM, 8 threads\nlinux: linux machine, 64Gb RAM, 12 threads (Intel(R) Xeon(R) W-2135 CPU @ 3.70GH )"
  },
  {
    "objectID": "posts/240308-jaxopt-vs-r-vs-julia/index.html#the-code",
    "href": "posts/240308-jaxopt-vs-r-vs-julia/index.html#the-code",
    "title": "The need for speed, performing simulation studies in R, JAX and Julia",
    "section": "The code",
    "text": "The code\n\nMaking data\nMaking the data is pretty similar in all cases, except that JAX requires an explicit random key.\n\nRPythonJulia\n\n\nmake_data &lt;- function(n=1e3L) {\n    x_vec = rnorm(n*10)\n    X_full = matrix(x_vec, ncol=10)\n    eta = rowSums(X_full)\n    y = eta &gt; 0\n    # return only first 9 column to have some noise\n    X = X_full[,1:9]\n    return(list(X=X,y=y))\n}\n\n\ndef make_data(k, n=int(1e3)):\n    X_full = random.normal(k, (n,10)) # JAX needs explicit keys for psuedo random number generation\n    eta = jnp.sum(X_full, axis=-1)\n    y = eta &gt; 0\n    # return only first 9 column to have some noise\n    X = X_full[:,:9]\n    return (X, y)\n\n\nfunction make_data(n::Integer=1000)\n    X_full = randn(n,10)\n    eta = vec(sum(X_full, dims=2))\n    y = eta .&gt; 0 # vectorized greater than 0 comparison\n    X = X_full[:,1:9]\n    return X, y\nend\n\n\n\n\n\nRun single experiment\nNow we’ll write the code for a single analysis step, generating data and fitting the logistic regression. For R and Julia we will use the glm function to estimate the logistic regression model. The Julia code looks much like the R code. As far as I know there is no equivalent glm function implemented in JAX. Instead, we need to specify an objective function and will use a general purpose optimizer. JaxOpt provides both binary_logreg as an objective function and LBFGS, a popular general purpose optimizer, which we’ll use here.\n\nRPythonJulia\n\n\nsolve &lt;- function(...) {\n  data = make_data()\n  fit = glm(data$y~data$X-1, family='binomial')\n  coefs = coef(fit)\n  return(coefs)\n}\n\n\n# initialize a generic solver with the correct objective function\nsolver = LBFGS(binary_logreg)\nw_init = jnp.zeros((9,))\n\n@jit # jit toggles just-in-time compilation, one of the main features of JAX\ndef solve(k):\n    data = make_data(k)\n    param, state = solver.run(w_init, data)\n    return param\n\n\nfunction solve(i::Int64=1)\n    X, y = make_data()\n    fit = glm(X, y, Bernoulli())\n    coefs = coef(fit)\n    return coefs\nend\n\n\n\n\n\nIterate over runs / settings\nFinally we run the experiments nrep times and calculate the average coefficient vector.\n\nJAX primitive: map versus vmap\nNote that in JAX there are multiple ways to do this, most notably map and vmap. Whereas map may offer speedups compared to R due to jit-compiliation, for most purposes vmap is recommended as it allows JAX to find ways of making the computation more efficient. For example, a vector-vector multiplication vectorized over an input of vectors is equivalent to a single matrix-vector multiplication. JAX’s intermediate language finds these possible optimizations and swaps in the more efficient approach. Vectorized code runs in parallel and can be much faster. Note that in our case, vectorization may not be too beneficial as running LBFGS on different datasets may not lend itself to vectorizations (compared e.g. to neural network computations on batches of data). A downside of vectorization is that it requires more memory: all the datasets and optimization steps happen in parallel, whereas with loop-based execution, only the coefficients of each time step need to be stored.\n\nRPythonJulia\n\n\nif (nthreads == 1) {\n    set.seed(240316)\n    params &lt;- lapply(1:nreps, solve)\n} else {\n    params &lt;- future_map(1:nreps, solve, .options=furrr_options(seed=240316))\n}\noutmat &lt;- do.call(rbind, params)\nmeans &lt;- colMeans(outmat)\nprint(means[1])\n\n\nk0 = random.PRNGKey(240316)\nks = random.split(k0, args.nreps)\nif args.primitive == 'map':\n    params = lax.map(solve, ks)\nelif args.primitive == 'vmap':\n    params = vmap(solve)(ks)\nelse:\n    raise ValueError(f\"unrecognized primitive: {args.primitive}, choose map or vmap\")\n\nmeans = jnp.mean(params, axis=0)\nprint(means[0])\n\n\nRandom.seed!(240316)\noutmat = zeros(nreps, 9)\n\n@threads for i in 1:nreps # use @threads for multi-threading\n    solution = solve()\n    outmat[i,:] = solution\nend\n\nmeans = mean(outmat, dims=1)\nprint(means[1])\n\n\n\n\n\n\nBash scripts for speed comparisons\nI benchmarked each run with an external time command in Bash or ZSH and wrote the results to a file.\n\nBash (linux)ZSH (macos)\n\n\n\n\nCode\n#!/bin/bash\n\nfor nreps in 1000 10000 100000 1000000 10000000\ndo\n    echo $nreps\n    { time python scripts/jaxspeed.py $nreps map; } 2&gt;&1 | grep real &gt;&gt; bashtimings.txt\n    sed -i '$s/$/ jax '\"${nreps}\"' nreps 12 nthreads map primitive/' bashtimings.txt\n    { time python scripts/jaxspeed.py $nreps vmap; } 2&gt;&1 | grep real &gt;&gt; bashtimings.txt\n    sed -i '$s/$/ jax '\"${nreps}\"' nreps 12 nthreads vmap primitive/' bashtimings.txt\n\n    for nthreads in 1 6 12\n    do\n        echo $nthreads\n        { time julia -t $nthreads scripts/jlspeed.jl $nreps ; } 2&gt;&1 | grep real &gt;&gt; bashtimings.txt\n        sed -i '$s/$/ julia '\"${nreps}\"' nreps '\"${nthreads}\"' nthreads/' bashtimings.txt\n        { time Rscript scripts/rspeed.R $nreps $nthreads ; } 2&gt;&1 | grep real &gt;&gt; bashtimings.txt\n        sed -i '$s/$/ r '\"${nreps}\"' nreps '\"${nthreads}\"' nthreads/' bashtimings.txt\n    done\ndone\n\n\n\n\n\n\nCode\n#!/bin/zsh\n\nfor nreps in 1000 10000 100000 1000000 10000000\ndo\n    echo $nreps\n    { time python scripts/jaxspeed.py $nreps map ; } 2&gt;&gt; timings.txt\n    sed -i '' '$s/$/ '\"${nreps}\"' nreps 8 threads map primitive/' timings.txt\n    { time python scripts/jaxspeed.py $nreps vmap ; } 2&gt;&gt; timings.txt\n    sed -i '' '$s/$/ '\"${nreps}\"' nreps 8 threads vmap primitive/' timings.txt\n\n    for nthreads in 1 8\n    do\n        echo $nthreads\n        { time julia -t $nthreads scripts/jlspeed.jl $nreps ; } 2&gt;&gt; timings.txt\n        sed -i '' '$s/$/ '\"${nreps}\"' nreps '\"${nthreads}\"' nthreads/' timings.txt\n        { time Rscript scripts/rspeed.R $nreps $nthreads ; } 2&gt;&gt; timings.txt\n        sed -i '' '$s/$/ '\"${nreps}\"' nreps '\"${nthreads}\"' nthreads/' timings.txt\n    done\ndone"
  },
  {
    "objectID": "posts/240308-jaxopt-vs-r-vs-julia/index.html#the-speed",
    "href": "posts/240308-jaxopt-vs-r-vs-julia/index.html#the-speed",
    "title": "The need for speed, performing simulation studies in R, JAX and Julia",
    "section": "The speed",
    "text": "The speed\n\nRunning time\nFirst, let’s see how running time increases with the number of experiments, using all available threads. You cannot easily set number of threads in JAX (see e.g. this issue on github), so all JAX computations use all threads.\n\n\nCode\nsuppressMessages({\n    library(dplyr)\n    library(data.table)\n    library(purrr)\n    library(stringr)\n    library(ggplot2); theme_set(theme_bw())\n    library(knitr)\n    library(kableExtra)\n})\n\n# get timings from mac\nlns &lt;- readr::read_lines('timings.txt')\n# get timings from linux machine\nblns &lt;- readr::read_lines('bashtimings.txt')\n\n# remove lines with warnings / errors printed to txt file\nlns &lt;- str_subset(lns, \"^Rscript|julia|python\")\nmtimings &lt;- data.table(raw_string=lns)\nbtimings &lt;- data.table(raw_string=blns)\n\n# remove white space and first word (for linux)\ntimings &lt;- rbindlist(list(macm1=mtimings, linux=btimings), idcol='machine')\ntimings[, string:=str_trim(raw_string)] # remove white space\ntimings[, string:=str_replace(string, \"^real\\t\", \"\")] # remove first word linux\n\n# find the language from the string\ntimings[machine=='macm1', command:=word(string)]\ntimings[command=='Rscript', language:='r']\ntimings[command=='python', language:='jax']\ntimings[command=='julia', language:='julia']\ntimings[machine=='linux', language:=str_extract(string, \"(?&lt;=s )[a-z]+\")]\n\n# grab number of threads and reps\ntimings[, nthreads:=as.integer(str_extract(string, \"(\\\\d+)(?= nthreads)\"))]\ntimings[, max_threads:=max(nthreads, na.rm=T), by='machine']\ntimings[is.na(nthreads) & language == 'jax', nthreads:=max_threads]\ntimings[is.na(nthreads) & language %in% c('r', 'julia'), nthreads:=1L]\ntimings[, nreps:=as.integer(str_extract(string, \"(\\\\d+)(?= nreps)\"))]\ntimings[, max_threads:=max(nthreads), by='machine']\n\n# find jax primitive\ntimings[, primitive:=str_extract(string, \"(\\\\w+)(?= primitive)\")]\ntimings[machine=='macm1'&language=='jax'&is.na(primitive), primitive:='map']\n#timings &lt;- timings[!(language=='jax' & primitive!='map')]\n# timings[language=='jax', language:=paste0(language, '-', primitive)]\ntimings[language!='jax', primitive:='map']\ntimings &lt;- timings[!str_ends(primitive, 'nojit')]\n\n# grab the time \ntimings[machine=='macm1', time_str:=str_extract(string, \"(?&lt;=cpu\\\\ )(.*)(?= total)\")]\ntimings[, milliseconds:=as.integer(str_extract(time_str, \"(\\\\d+)$\"))]\ntimings[, seconds     :=as.integer(str_extract(time_str, \"(\\\\d+)(?=.)\"))]\ntimings[, minutes     :=as.integer(str_extract(time_str, \"(\\\\d+)(?=:)\"))]\ntimings[, hours       :=as.integer(str_extract(time_str, \"(\\\\d+)(?=:(\\\\d+:))\"))]\ntimings[machine=='linux', minutes:=as.integer(str_extract(string, \"^(\\\\d+)\"))]\ntimings[machine=='linux', seconds:=as.integer(str_extract(string, \"(?&lt;=m)(\\\\d+)\"))]\ntimings[machine=='linux', milliseconds:=as.integer(str_extract(string, \"(\\\\d+)(?=s)\"))]\ntimings[is.na(minutes), minutes:=0]\ntimings[is.na(hours), hours:=0]\n\n\ntimings[, sec_total:=60*60*hours + 60*minutes + seconds + milliseconds / 1000]\ntimings[, min_total:=sec_total / 60]\n\n# add some vars\ntimings[, n_per_min:=nreps / min_total]\ntimings[, n_per_min3:=n_per_min/1000]\n\n# remove a couple of failed runs where time went down for more experiments (= out of memory)\n#timings &lt;- timings[n_per_min &lt; 1.5e6]\n\n\nfwrite(timings, 'allresults.csv', row.names=F)\n\nggplot(timings[nthreads==max_threads], aes(x=nreps, y=min_total, col=language)) +\n  geom_point() + geom_line(aes(linetype=primitive)) + \n  scale_x_log10() + scale_y_log10() + \n  # facet_grid(machine+nthreads~primitive, labeller='label_both')\n  facet_grid(machine+nthreads~., labeller='label_both')\n\n\n\n\n\n\n\n\nFigure 1: Time to run experiments on the maximum number of threads\n\n\n\n\n\nNote that for JAX vmap the clock time actually goes down when the number of experiment increases. This is not some magic speedup but the machine running out of memory and thus not completing the experiment, a downside of vectorization. We’ll exclude these runs of the further comparisons. For map this is not the case.\n\n\nSpeed\nLet’s look at the speeds.\n\n\n\n\n\n\n\n\nFigure 2: Speed: number of repetitions per minute versus of number of experiments\n\n\n\n\n\nWhy is the speed going down for Julia on the macm1 machine after 1e6 experiments? Turns out there is not enough RAM to fit the experiments and the system switches to swap memory which is much slower than using RAM (even on a mac arm64). The speed of R stopped increasing after 1e6 experiments so I didn’t run more experiments.\n\n\nThreads vs Speed\nNow let’s check how much extra speed we get from using more threads in R and Julia.\n\n\n\n\n\n\n\n\nFigure 3: Scaling of speed with number of threads\n\n\n\n\n\n\n\n\nScaling of speed with number of threads, number of experiments per minute (1000s)\n\n\nlanguage\nnreps\nlinux_1\nlinux_6\nspeedup6\nlinux_12\nspeedup12\nmacm1_1\nmacm1_8\nspeedup8\n\n\n\n\njulia\n1e+03\n10.7\n11.8\n1.1\n11.0\n1.0\n16.2\n16.3\n1.0\n\n\njulia\n1e+04\n69.5\n108.1\n1.6\n101.0\n1.5\n96.9\n147.6\n1.5\n\n\njulia\n1e+05\n146.0\n514.8\n3.5\n567.1\n3.9\n151.3\n494.4\n3.3\n\n\njulia\n1e+06\n162.8\n857.3\n5.3\n1001.3\n6.2\n163.9\n983.6\n6.0\n\n\njulia\n1e+07\n168.6\n875.7\n5.2\n1059.3\n6.3\n163.9\n245.9\n1.5\n\n\nr\n1e+03\n14.8\n14.5\n1.0\n9.2\n0.6\n20.8\n23.7\n1.1\n\n\nr\n1e+04\n15.3\n53.0\n3.5\n52.4\n3.4\n22.5\n72.7\n3.2\n\n\nr\n1e+05\n14.6\n74.1\n5.1\n89.8\n6.2\n24.6\n98.2\n4.0\n\n\nr\n1e+06\n13.9\n70.8\n5.1\n91.0\n6.6\n20.9\n82.0\n3.9\n\n\n\n\n\n\n\nSpeed increases with increasing number of threads, though not with a simple linear scaling in the number of threads. The speed increase is similar for R and Julia.\n\n\nTop speeds per language\nLet’s see the top speeds per language, also compered to the top R speed on that machine.\n\n\n\n\nTable 1: Best speeds per language and machine\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nn experiments\nn threads\nrunning time (minutes)\nexperiments per minute (x1000)\nspeed-up vs best R\nlanguage\nprimitive\nmachine\n\n\n\n\n1e+05\n12\n0.6\n161.9\n1.8\njax\nvmap\nlinux\n\n\n1e+07\n12\n9.4\n1059.3\n11.6\njulia\nmap\nlinux\n\n\n1e+06\n12\n11.0\n91.0\n1.0\nr\nmap\nlinux\n\n\n1e+06\n8\n6.1\n163.9\n1.7\njax\nmap\nmacm1\n\n\n1e+06\n8\n1.0\n983.6\n10.0\njulia\nmap\nmacm1\n\n\n1e+05\n8\n1.0\n98.2\n1.0\nr\nmap\nmacm1\n\n\n\n\n\n\n\n\n\n\nTop speeds overall\nTop 10 speeds overall\n\n\n\n\nTable 2: top 10 speeds overall\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nn experiments\nn threads\nrunning time (minutes)\nexperiments per minute (x1000)\nspeed-up vs best R\nlanguage\nprimitive\nmachine\n\n\n\n\n1e+07\n12\n9.4\n1059.3\n11.6\njulia\nmap\nlinux\n\n\n1e+06\n12\n1.0\n1001.3\n11.0\njulia\nmap\nlinux\n\n\n1e+06\n8\n1.0\n983.6\n10.0\njulia\nmap\nmacm1\n\n\n1e+07\n6\n11.4\n875.7\n9.6\njulia\nmap\nlinux\n\n\n1e+06\n6\n1.2\n857.3\n9.4\njulia\nmap\nlinux\n\n\n1e+05\n12\n0.2\n567.1\n6.2\njulia\nmap\nlinux\n\n\n1e+05\n6\n0.2\n514.8\n5.7\njulia\nmap\nlinux\n\n\n1e+05\n8\n0.2\n494.4\n5.0\njulia\nmap\nmacm1\n\n\n1e+07\n8\n40.7\n245.9\n2.5\njulia\nmap\nmacm1\n\n\n1e+07\n1\n59.3\n168.6\n1.9\njulia\nmap\nlinux\n\n\n\n\n\n\n\n\nAll results are available in a csv file here"
  },
  {
    "objectID": "posts/240308-jaxopt-vs-r-vs-julia/index.html#takeaways",
    "href": "posts/240308-jaxopt-vs-r-vs-julia/index.html#takeaways",
    "title": "The need for speed, performing simulation studies in R, JAX and Julia",
    "section": "Takeaways",
    "text": "Takeaways\n\nSpeed\nIn this setup, both on a Mac M1 and a Linux machine,\n\nJulia was 10-11 times faster than R\nJAX was 1.7 times faster than R\n\n\n\nCode\n\nJulia code seems quite close to R code.\nIn this simple example, the JAX code doesn’t seem too dounting. However, JAX comes with some sharp bits and may be harder to program efficiently.1\n\n\n\nCaveats\n\nJAX needs to recompile when the size of the data changes. When running experiments with e.g. different sizes of data, JAX will become slower because it needs to recompile, or you’ll need to find other solutions like padding smaller data with dummy data and giving these dummy data 0 weights in the objective functions.\nI didn’t have a CUDA-enabled GPU machine for this comparison, vmap may be come (much) more performant on a GPU\nJAX gives bare bones results. If you want to do e.g. significance testing of coefficients, or model comparisons, you will need to find implementations for this or implement this yourself. R and Julia (specifically the GLM package provide a much wider suite of methods\nIn JAX I used general purpose optimizer. There may be more efficient ways of estimating a logistic regression model, whose optimizations are implemented in R and Julia but not JAX. In this sense it may not be a fair comparison, though these optimizations would need to be sought or implemented in JAX.\nJAX has autograd. When writing custom objective functions JAX can automatically calculate gradients and hessians, making it possible to use general purpose first or second order optimizers (e.g. Amsterdam and Ranganath 2023).\n\n\n\nExtensions\n\nOptimizing memory usage\nSince in this case we only need the avarage of the coefficients we need not store all intermediate results. All languages may beccome much more efficient if we can program this in.\n\nThe julia domumentation states that certain operations to atomic data structures can be done in a safe-way while multithreading. Instead of returning all coefficients of all datasets, we could calculate the average value of the coefficients (and e.g. the avareage of the squares of the values) with less memory overhead by:\n\ninstantiate an atomic vector of 9 coefficients\nlet every experiment (which may be in different threads) add its value to this shared atomic vector with atomic_add!\nat the end, calculate the mean by dividing by nreps.\n\nR functions can also overwrite global variables, but a question is whether this can be done in a multi-threading safe way\nIn JAX we may use scan to keep track of a running sum of coefficients and then vmap a bunch of scan computations\n\nIn future posts I plan to dive in to dive in to these optimizations to squeeze more out of these languages."
  },
  {
    "objectID": "posts/240308-jaxopt-vs-r-vs-julia/index.html#conclusion",
    "href": "posts/240308-jaxopt-vs-r-vs-julia/index.html#conclusion",
    "title": "The need for speed, performing simulation studies in R, JAX and Julia",
    "section": "Conclusion",
    "text": "Conclusion\n\n\n\n\n\n\nWhat should you use for glm-like simulation studies?\n\n\n\nProbably, Julia"
  },
  {
    "objectID": "posts/240308-jaxopt-vs-r-vs-julia/index.html#session-info",
    "href": "posts/240308-jaxopt-vs-r-vs-julia/index.html#session-info",
    "title": "The need for speed, performing simulation studies in R, JAX and Julia",
    "section": "Session Info",
    "text": "Session Info\n\nRPythonJulia\n\n\n#| echo: false\n#| eval: false\nlibrary(sessioninfo)\nsession_info(pkgs = \"attached\", to_file=\"_rsession.txt\")\n\n─ Session info ────────────────────────────────────────────────────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.3.2 (2023-10-31)\n os       macOS Sonoma 14.3\n system   aarch64, darwin23.0.0\n ui       RStudio\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/Amsterdam\n date     2024-03-21\n rstudio  2023.12.1+402 Ocean Storm (desktop)\n pandoc   3.1.12.2 @ /opt/homebrew/bin/ (via rmarkdown)\n\n─ Packages ────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n data.table  * 1.14.8  2023-02-17 [1] CRAN (R 4.3.1)\n dplyr       * 1.1.2   2023-04-20 [1] CRAN (R 4.3.1)\n ggplot2     * 3.4.2   2023-04-03 [1] CRAN (R 4.3.1)\n kableExtra  * 1.4.0   2024-01-24 [1] CRAN (R 4.3.2)\n knitr       * 1.43    2023-05-25 [1] CRAN (R 4.3.1)\n purrr       * 1.0.1   2023-01-10 [1] CRAN (R 4.3.1)\n sessioninfo * 1.2.2   2021-12-06 [1] CRAN (R 4.3.2)\n stringr     * 1.5.0   2022-12-02 [1] CRAN (R 4.3.1)\n\n [1] /opt/homebrew/lib/R/4.3/site-library\n [2] /opt/homebrew/Cellar/r/4.3.2/lib/R/library\n\n───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n\n\njax==0.4.25\njaxlib==0.4.25\njaxopt==0.8.3\nml-dtypes==0.3.2\nnumpy==1.26.4\nopt-einsum==3.3.0\nscipy==1.12.0\n\n\nname = \"jlspeed\"\nuuid = \"a8cd5241-1987-4548-90e5-ac0f39e812f2\"\nauthors = [\"Wouter van Amsterdam\"]\nversion = \"0.1.0\"\n\n[deps]\nArgParse = \"c7e460c6-2fb9-53a9-8c5b-16f535851c63\"\nGLM = \"38e38edf-8417-5370-95a0-9cbb8c7f171a\"\nRandom = \"9a3f8284-a2c9-5f02-9a11-845980a1fd5c\"\nStatsBase = \"2913bbd2-ae8a-5f71-8c99-4fb6c76f3a91\""
  },
  {
    "objectID": "posts/240308-jaxopt-vs-r-vs-julia/index.html#full-scripts",
    "href": "posts/240308-jaxopt-vs-r-vs-julia/index.html#full-scripts",
    "title": "The need for speed, performing simulation studies in R, JAX and Julia",
    "section": "Full scripts",
    "text": "Full scripts\n\nRPythonJulia\n\n\n# rspeed\nargs = commandArgs(trailingOnly = T)\nif (length(args) == 0) {\n  nreps = 100\n  nthreads = 1\n} else if (length(args) == 1) {\n  nreps = as.integer(args[1])\n  nthreads = 1\n} else {\n  nreps = as.integer(args[1])\n  nthreads = as.integer(args[2])\n  suppressMessages(library(furrr))\n  plan(multisession, workers=nthreads)\n}\n\nmake_data &lt;- function(n=1e3L) {\n    x_vec = rnorm(n*10)\n    X_full = matrix(x_vec, ncol=10)\n    eta = rowSums(X_full)\n    y = eta &gt; 0\n    # return only first 9 column to have some noise\n    X = X_full[,1:9]\n    return(list(X=X,y=y))\n}\n\nsolve &lt;- function(...) {\n  data = make_data()\n  fit = glm(data$y~data$X-1, family='binomial')\n  coefs = coef(fit)\n  return(coefs)\n}\n\nif (nthreads == 1) {\n    set.seed(240316)\n    params &lt;- lapply(1:nreps, solve)\n} else {\n    params &lt;- future_map(1:nreps, solve, .options=furrr_options(seed=240316))\n}\noutmat &lt;- do.call(rbind, params)\nmeans &lt;- colMeans(outmat)\nprint(means[1])\n\n\n\nimport jax, jaxopt jax.config.update(‘jax_platform_name’, ‘cpu’) # make sure jax doesnt use a gpu if it’s available from jax import numpy as jnp, random, vmap, jit, lax from jaxopt import LBFGS from jaxopt.objective import binary_logreg from argparse import ArgumentParser\nparser = ArgumentParser() parser.add_argument(‘nreps’, nargs=“?”, type=int, default=int(10)) parser.add_argument(‘primitive’, nargs=“?”, type=str, default=“vmap”)\ndef make_data(k, n=int(1e3)): X_full = random.normal(k, (n,10)) # JAX needs explicit keys for psuedo random number generation eta = jnp.sum(X_full, axis=-1) y = eta &gt; 0 # return only first 9 column to have some noise X = X_full[:,:9] return (X, y)\n\ninitialize a generic solver with the correct objective function\nsolver = LBFGS(binary_logreg) # need to specify parameter initialization values w_init = jnp.zeros((9,))\n(jit?) # jit toggles just-in-time compilation, one of the main features of JAX def solve(k): data = make_data(k) param, state = solver.run(w_init, data) return param\nif name == ‘main’: args = parser.parse_args() k0 = random.PRNGKey(240316) ks = random.split(k0, args.nreps) if args.primitive == ‘map’: params = lax.map(solve, ks) elif args.primitive == ‘vmap’: params = vmap(solve)(ks) else: raise ValueError(f”unrecognized primitive: {args.primitive}, choose map or vmap”)\nmeans = jnp.mean(params, axis=0)\nprint(means[0])\n\n\n\nusing Random, GLM, StatsBase, ArgParse\nimport Base.Threads.@threads\n\nfunction parse_cmdline()\n    parser = ArgParseSettings()\n\n    @add_arg_table parser begin\n        \"nreps\"\n          help = \"number of repetitions\"\n          required = false\n          arg_type = Int\n          default = 10\n    end\n\n    return parse_args(parser)\nend\n\nfunction make_data(n::Integer=1000)\n    X_full = randn(n,10)\n    eta = vec(sum(X_full, dims=2))\n    y = eta .&gt; 0 # vectorized greater than 0 comparison\n    X = X_full[:,1:9]\n    return X, y\nend\n\nfunction solve(i::Int64=1)\n    X, y = make_data()\n    fit = glm(X, y, Bernoulli())\n    coefs = coef(fit)\n    return coefs\nend\n\nfunction main()\n    args = parse_cmdline()\n    nreps = get(args, \"nreps\", 10)\n\n    Random.seed!(240316)\n    outmat = zeros(nreps, 9)\n\n    @threads for i in 1:nreps # use @threads for multi-threading\n        solution = solve()\n        outmat[i,:] = solution\n    end\n\n    means = mean(outmat, dims=1)\n    print(means[1])\nend\n\nmain()"
  },
  {
    "objectID": "posts/240308-jaxopt-vs-r-vs-julia/index.html#references",
    "href": "posts/240308-jaxopt-vs-r-vs-julia/index.html#references",
    "title": "The need for speed, performing simulation studies in R, JAX and Julia",
    "section": "References",
    "text": "References\n\n\nAmsterdam, Wouter A. C. van, Netanja I. Harlianto, Joost J. C. Verhoeff, Pim Moeskops, Pim A. de Jong, and Tim Leiner. 2022. “The Association Between Muscle Quantity and Overall Survival Depends on Muscle Radiodensity: A Cohort Study in Non-Small-Cell Lung Cancer Patients.” Journal of Personalized Medicine 12 (7): 1191. https://doi.org/10.3390/jpm12071191.\n\n\nAmsterdam, Wouter A. C. van, and Rajesh Ranganath. 2023. “Conditional Average Treatment Effect Estimation with Marginally Constrained Models.” Journal of Causal Inference 11 (1): 20220027. https://doi.org/10.1515/jci-2022-0027.\n\n\nAmsterdam, Wouter A. C. van, Joost J. C. Verhoeff, Netanja I. Harlianto, Gijs A. Bartholomeus, Aahlad Manas Puli, Pim A. de Jong, Tim Leiner, Anne S. R. van Lindert, Marinus J. C. Eijkemans, and Rajesh Ranganath. 2022. “Individual Treatment Effect Estimation in the Presence of Unobserved Confounding Using Proxies: A Cohort Study in Stage III Non-Small Cell Lung Cancer.” Scientific Reports 12 (1): 5848. https://doi.org/10.1038/s41598-022-09775-9.\n\n\n“DifferentiableUniverseInitiative/Jax_cosmo.” 2024. Differentiable Universe Initiative. https://github.com/DifferentiableUniverseInitiative/jax_cosmo.\n\n\n“SciML: Open Source Software for Scientific Machine Learning.” n.d. Accessed March 14, 2024. https://sciml.ai."
  },
  {
    "objectID": "posts/240308-jaxopt-vs-r-vs-julia/index.html#footnotes",
    "href": "posts/240308-jaxopt-vs-r-vs-julia/index.html#footnotes",
    "title": "The need for speed, performing simulation studies in R, JAX and Julia",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nOne concrete example with my own previous simulation studies (Amsterdam and Ranganath 2023) is that I used first used jax.numpy arrays for different parameters and then a scipy function to create all combinations of these parameters. Creating this grid of parameters this way forced copying of jax.numpy arrays from the GPU back to CPU and then copying the grid back to GPU. This made the entire process orders of magnitude slower (it was a large grid O(1e12)). Gotchas like these can bite you. Also, JAX relies on pure functions that cannot depend on global variables.↩︎"
  },
  {
    "objectID": "posts/250425-robustness/index.html",
    "href": "posts/250425-robustness/index.html",
    "title": "What is stronger evidence of prediction model robustness?",
    "section": "",
    "text": "We’re evaluating a prediction model \\(f\\) that takes features \\(X\\) to predict binary outcome \\(Y\\). We’d like the model to be robust, meaning that it’s predictive performance is stable in different environments. To test this, the model has been evaluated in multiple testing environments (e.g. different hospitals, populations, regions, health-care settings, etc.). In each environment, we measure predictive performance with:\n\ndiscrimination: area under the ROC curve (integration of sensitivity and specificity for varying threshold \\(0 \\leq \\tau \\leq 1\\))\ncalibration: alignement between predicted probabilities and observed outcome rates\n\n\n\n\n\n\n\nWhich result would provide stronger evidence of robustness?\n\n\n\nA. observe stable discrimination and calibration across all environments B. observe stable discrimination but poor calibration in some environments"
  },
  {
    "objectID": "posts/250425-robustness/index.html#question",
    "href": "posts/250425-robustness/index.html#question",
    "title": "What is stronger evidence of prediction model robustness?",
    "section": "",
    "text": "We’re evaluating a prediction model \\(f\\) that takes features \\(X\\) to predict binary outcome \\(Y\\). We’d like the model to be robust, meaning that it’s predictive performance is stable in different environments. To test this, the model has been evaluated in multiple testing environments (e.g. different hospitals, populations, regions, health-care settings, etc.). In each environment, we measure predictive performance with:\n\ndiscrimination: area under the ROC curve (integration of sensitivity and specificity for varying threshold \\(0 \\leq \\tau \\leq 1\\))\ncalibration: alignement between predicted probabilities and observed outcome rates\n\n\n\n\n\n\n\nWhich result would provide stronger evidence of robustness?\n\n\n\nA. observe stable discrimination and calibration across all environments B. observe stable discrimination but poor calibration in some environments"
  },
  {
    "objectID": "posts/250425-robustness/index.html#answer",
    "href": "posts/250425-robustness/index.html#answer",
    "title": "What is stronger evidence of prediction model robustness?",
    "section": "Answer",
    "text": "Answer\nWe’ll answer this in three steps:\n\nwhere do differences between environments come from?\nhow are discrminiation and calibration calculated?\nputting 1 and 2 together, answer the question\n\n\nWhere do differences between environments come from?\n\nTo evaluate the question we’ll first layout how exactly environments may be different. In probability statements, how the joint distribution of \\(X\\) and \\(Y\\) depends on the environment \\(E\\). Without making any assumptions, we can decompose the joint distriution in two ways using the chain rule (or general product rule):\n\\[\\begin{align*}\n  P_E(X,Y) &= P_E(Y|X)P_E(X) \\\\\n           &= P_E(X|Y)P_E(Y)\n\\end{align*}\\]\nHow can environments differ? Clearly, one or more of the four terms needs to depend on environment \\(E\\). For discrimination and or calibration to be stable, we need at least some parts of the distribution to remain the same across environments, i.e. transportable. Let’s consider the minimal differences that would lead to a change in distribution between environments. These are minimal in the sence that only one of the four terms depends on \\(E\\), and the others are transportable across environments. The options are:\n\n\n\nTable 1: Enumeration of possibilities for minimal differences across environments\n\n\n\n\n\ncase\ndecomposition\ndepends on E\ntransportable\n\n\n\n\n1\n\\(P(Y|X)P(X)\\)\n\\(P(X)\\)\n\\(P(Y|X)\\)\n\n\n2\n\n\\(P(Y|X)\\)\n\\(P(X)\\)\n\n\n3\n\\(P(X|Y)P(Y)\\)\n\\(P(Y)\\)\n\\(P(X|Y)\\)\n\n\n4\n\n\\(P(X|Y)\\)\n\\(P(Y)\\)\n\n\n\n\n\n\n\n\nHow are discrimination and calibration calculated?\nDiscrimination measures how well a model can separate positive from neagtive cases and is typically measured with sensitivity, specificity and the AUC. Given a threshold \\(0 \\leq \\tau \\leq 1\\),\n\nSensitivity is the ratio of positive predictions in the positive cases: \\(P(f(X) &gt; \\tau | Y=1)\\)\nSpecificity is the ratio of negative predictions in the negative cases: \\(P(f(X) \\leq \\tau | Y=0)\\)\n\nThe AUC is obtained by varying \\(\\tau\\) between 0 and 1, plotting the sensitivity and specificity for every value of \\(\\tau\\) and calculating the area under the curve.\n\n\n\n\n\n\nCrucial insight:\n\n\n\nDiscrimination is a function of the distribution of features given the outcome. This means that when \\(P(X|Y)\\) is the same across environments, so is the model’s AUC (i.e. in case 3)\n\n\nCalibration measures how well predicted probabilities align with even rates. A model \\(f\\) is perfectly calibrated if for all values \\(0 \\leq \\alpha \\leq 1\\) that \\(f\\) obtains, we have that:\n\\[\n  E_{X,Y \\sim P(X,Y)}[Y|f(X)=\\alpha]=\\alpha.\n\\]\n\n\n\n\n\n\nCrucial insight:\n\n\n\nCalibration is a function of the distribution of the outcome given the features. This means that when \\(P(Y|X)\\) is the same across environments, so is the model’s calibration (i.e. in case 1)\n\n\nSo discrimination is stable when \\(P(X|Y)\\) is transportable and calibration is stable when \\(P(Y|X)\\) is transportable. Are they ever both? Using Bayes’ Theorem we have that:\n\\[\nP(Y|X) = P(X|Y) \\frac{P(Y)}{P(X)} \\equiv P(X|Y) = P(Y|X) \\frac{P(X)}{P(Y)}\n\\]\nClearly, if any of the right-hand sides is not transportable, then neither is the left-hand side.\n\n\n\n\n\n\nCrucial insight:\n\n\n\nCalibration and discrimination are never both stable across environments.1\n\n\nExcept for well-engineered counter examples.\n\n\nPutting it all together\nArmed with this knowledge, let’s go back to Table 1 with minimal changes in the joint distribution of \\(X\\) and \\(Y\\) across environments, and fill in what will happen with discrimination and calibration.\n\n\n\nTable 2: Discrimination and calibration under different changes in environment\n\n\n\n\n\ncase\ntransportable\ndiscrimination\ncalibration\n\n\n\n\n1\n\\(P(Y|X)\\)\n\nstable\n\n\n2\n\\(P(X)\\)\n\n\n\n\n3\n\\(P(X|Y)\\)\nstable\n\n\n\n4\n\\(P(Y)\\)\n\n\n\n\n\n\n\n\nNotice a pattern? Even under minimal changes between environments, at least diescrimination or calibration will change. So what happened in setting A? Given that both calibration and discrimination are stable, we can conclude that \\(P(X|Y)\\) and \\(P(Y|X)\\) are both transportable across the tested environments. The only logical conclusion is not that the model is robust against changes in environment, but that the testing environments were meaningfully different. In contrast, in setting B we have that discrimination is stable but calibration is not. We can deduce that \\(P(X|Y)\\) was transportable across environments, and \\(P(Y)\\) was not. The observed stable discrimination of the model gives confidence that even under meaningfully different environments, the model retains discrimination."
  },
  {
    "objectID": "posts/250425-robustness/index.html#roundup-tldr",
    "href": "posts/250425-robustness/index.html#roundup-tldr",
    "title": "What is stronger evidence of prediction model robustness?",
    "section": "Roundup / TLDR",
    "text": "Roundup / TLDR\nEnvironments must differ with respect to something. If the distribution of features given outcome remains the same (\\(X|Y\\)), discrimination is preserved, if the distribution of outcome given features remains the same (\\(Y|X\\)), calibration is preserved. If both are the same, the environments were not meaningfully different to begin with.\nA question that remains is how these differences in environments may come about. On this, I wrote a paper titled A causal viewpoint on prediction model performance under changes in case-mix: discrimination and calibration respond differently for prognosis and diagnosis predictions which you can find on ArXiv"
  },
  {
    "objectID": "posts/250425-robustness/index.html#footnotes",
    "href": "posts/250425-robustness/index.html#footnotes",
    "title": "What is stronger evidence of prediction model robustness?",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nCounter examples may be constructed. For example, say \\(P(Y|X)\\) follows a mixture of beta distributions with their modes at \\(\\mu_1 = 0.25\\) and \\(\\mu_2 = 0.75\\) in one environment. We’re shifting \\(P(X)\\) across environments, so \\(P(Y|X)\\) is transportable and calibration is stable. If in another environment we shift \\(\\mu_1\\) to 0, then AUC will go up; if we shift \\(\\mu_2\\) to 0.5 the AUC will go down. We can set \\(\\mu_1\\) and \\(\\mu_2\\) to carefully choose values so that the AUC remanins the same in the second environment.↩︎"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#prediction",
    "href": "talks/240516-sig-causality-prediction/index.html#prediction",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "Prediction",
    "text": "Prediction\n\nhave some features \\(X\\) (patient characteristics, medical images, lab results)\ndefine relevant outcome \\(Y\\) (e.g. 1-year survival, blood pressure, treatment complication)\nbuild prediction model \\(f: \\mathbb{X} \\to \\mathbb{Y}\\) that predicts \\(Y\\) from \\(X\\), e.g.:\n\n\n\\[ \\theta^* = \\arg \\min_{\\theta} \\sum_i^n ( f_{\\theta}(x_i) - y_i )^2 \\]\n\n\nHoping that\n\\[ \\lim_{n \\to \\infty} f_{\\theta^*} = E[Y|X] \\]"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#prediction-typical-approach",
    "href": "talks/240516-sig-causality-prediction/index.html#prediction-typical-approach",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "Prediction: typical approach",
    "text": "Prediction: typical approach\n\ndefine population, start a (prospective) longitudinal cohort\nmeasure \\(X\\) at prediction baseline\nfollow-up patients to measure \\(Y\\)\nfit model \\(f\\) to \\(\\{x_i,y_i\\}\\)\nevaluate prediction performance with e.g. discrimination, calibration, \\(R^2\\)"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#causal-inference",
    "href": "talks/240516-sig-causality-prediction/index.html#causal-inference",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "Causal inference",
    "text": "Causal inference\n\\(y^0:=\\) imaginative outcome if I don’t treat the patient\n\n\n\n\n\n\n\n\n\n\n\\[\\begin{align}\ny^0 &= \\mu_0 + \\epsilon, \\quad \\epsilon \\overset{\\mathrm{iid}}{\\sim} N(0,\\sigma)\\\\\n\\end{align}\\]\n\n\nthis formula together with distribution over error term gives rise to a distribution over the outcome when intervening on treatment (i.e. an interventional distribution)\n\\[\nP(Y=y|\\text{do}(T=0))\n\\]"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#causal-inference-1",
    "href": "talks/240516-sig-causality-prediction/index.html#causal-inference-1",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "Causal inference",
    "text": "Causal inference\n\\(y^0:=\\) imaginative outcome if I don’t treat the patient\n\\(y^1:=\\) imaginative outcome if I do treat\n\n\\[\\begin{align}\ny^0 &= \\mu_0 + \\epsilon, \\quad \\epsilon \\overset{\\mathrm{iid}}{\\sim} N(0,\\sigma) \\to &P(Y=y|\\text{do}(T=0))\\\\\ny^1 &= \\mu_1 + \\epsilon, \\quad \\epsilon \\overset{\\mathrm{iid}}{\\sim} N(0,\\sigma) \\to &P(Y=y|\\text{do}(T=1))\n\\end{align}\\]\n\n\\[\\begin{align}\n\\text{treatment effect} &:= E[y^1] - E[y^0] = \\mu_1 - \\mu_0 \\\\\n                        &:= E[Y|\\text{do}(T=1)] - E[Y|\\text{do}(T=0)]\n\\end{align}\\]"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#causal-inference-typical-approach",
    "href": "talks/240516-sig-causality-prediction/index.html#causal-inference-typical-approach",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "Causal inference: typical approach",
    "text": "Causal inference: typical approach\n\ndefine target population and targeted treatment comparison\nrun randomized controlled trial, randomizing treatment allocation\nmeasure patient outcomes\nestimate parameter that summarizes average treatment effect (ATE)\n\n\n\n\n\nWhat if you cannot do a (big enough) RCT?\n\n\nEmulate / approximate the ideal trial in observational data you do have, using causal inference techniques\n(which rely on untestable assumptions)"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#causal-inference-versus-prediction",
    "href": "talks/240516-sig-causality-prediction/index.html#causal-inference-versus-prediction",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "Causal inference versus prediction",
    "text": "Causal inference versus prediction\n\n\nprediction\n\ntypical estimand \\(E[Y|X]\\)\ntypical study: longitudinal cohort\ntypical interpretation: \\(X\\) predicts \\(Y\\)\nprimary use: know what \\(Y\\) to expect when observing \\(X\\) assuming no change in joint distribution\n\n\ncausal inference\n\ntypical estimand \\(E[Y|\\text{do}(T=1)] - E[Y|\\text{do}(T=0)]\\)\ntypical study: RCT\ntypical interpretation: causal effect of \\(T\\) on \\(Y\\)\nprimary use: know what treatment to give"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#the-in-between-using-prediction-models-for-medical-decision-making",
    "href": "talks/240516-sig-causality-prediction/index.html#the-in-between-using-prediction-models-for-medical-decision-making",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "The in-between: using prediction models for (medical) decision making",
    "text": "The in-between: using prediction models for (medical) decision making"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#using-prediction-models-for-decision-making-is-often-thought-of-as-a-good-idea",
    "href": "talks/240516-sig-causality-prediction/index.html#using-prediction-models-for-decision-making-is-often-thought-of-as-a-good-idea",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "Using prediction models for decision making is often thought of as a good idea",
    "text": "Using prediction models for decision making is often thought of as a good idea\nFor example:\n\ngive chemotherapy to cancer patients with high predicted risk of recurrence\ngive statins to patients with a high risk of a heart attack\n\n\n\n\n\nTRIPOD+AI on prediction models (collinsTRIPODAIStatement2024?)\n\n\n“Their primary use is to support clinical decision making, such as … initiate treatment or lifestyle changes.”"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#prediction-modeling-is-very-popular-in-medical-research",
    "href": "talks/240516-sig-causality-prediction/index.html#prediction-modeling-is-very-popular-in-medical-research",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "Prediction modeling is very popular in medical research",
    "text": "Prediction modeling is very popular in medical research"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#treatment-naive-risk-models",
    "href": "talks/240516-sig-causality-prediction/index.html#treatment-naive-risk-models",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "Treatment-naive risk models",
    "text": "Treatment-naive risk models\n\n\n\n\n\\[\\begin{align}\n    E[Y|X] \\class{fragment}{= E[E_{t~\\sim \\pi_0(X)}[Y|X,t]]}\n\\end{align}\\]"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#is-this-obvious",
    "href": "talks/240516-sig-causality-prediction/index.html#is-this-obvious",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "Is this obvious?",
    "text": "Is this obvious?\n\n\n\n\n\n\nTip\n\n\nIt may seem obvious that you should not ignore historical treatments in your prediction models, if you want to improve treatment decisions, but many of these models are published daily, and some guidelines even allow for implementing these models based on predictve performance only"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#recommended-validation-practices-do-not-protect-against-harm",
    "href": "talks/240516-sig-causality-prediction/index.html#recommended-validation-practices-do-not-protect-against-harm",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "Recommended validation practices do not protect against harm",
    "text": "Recommended validation practices do not protect against harm\nbecause they do not evaluate the policy change"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#bigger-data-does-not-protect-against-harmful-risk-models",
    "href": "talks/240516-sig-causality-prediction/index.html#bigger-data-does-not-protect-against-harmful-risk-models",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "Bigger data does not protect against harmful risk models",
    "text": "Bigger data does not protect against harmful risk models"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#more-flexible-models-do-not-protect-against-harmful-risk-models",
    "href": "talks/240516-sig-causality-prediction/index.html#more-flexible-models-do-not-protect-against-harmful-risk-models",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "More flexible models do not protect against harmful risk models",
    "text": "More flexible models do not protect against harmful risk models"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#gap-between-prediction-accuracy-and-value-for-decision-making",
    "href": "talks/240516-sig-causality-prediction/index.html#gap-between-prediction-accuracy-and-value-for-decision-making",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "Gap between prediction accuracy and value for decision making",
    "text": "Gap between prediction accuracy and value for decision making"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#section",
    "href": "talks/240516-sig-causality-prediction/index.html#section",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "",
    "text": "What to do?"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#section-1",
    "href": "talks/240516-sig-causality-prediction/index.html#section-1",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "",
    "text": "What to do?\n\n\nEvaluate policy change (cluster randomized controlled trial)\nBuild models that are likely to have value for decision making"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#deploying-a-model-is-an-intervention-that-changes-the-way-treatment-decisions-are-made",
    "href": "talks/240516-sig-causality-prediction/index.html#deploying-a-model-is-an-intervention-that-changes-the-way-treatment-decisions-are-made",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "Deploying a model is an intervention that changes the way treatment decisions are made",
    "text": "Deploying a model is an intervention that changes the way treatment decisions are made"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#how-do-we-learn-about-the-effect-of-an-intervention",
    "href": "talks/240516-sig-causality-prediction/index.html#how-do-we-learn-about-the-effect-of-an-intervention",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "How do we learn about the effect of an intervention?",
    "text": "How do we learn about the effect of an intervention?\nWith causal inference!\n\nfor using a decision support model, the unit of intervention is usually the doctor\nrandomly assign doctors to have access to the model or not\nmeasure differences in treatment decisions and patient outcomes\nthis called a cluster RCT\nif using model improves outcomes, use that one\n\n\n\n\n\nUsing cluster RCTs to evaluated models for decision making is not a new idea (Cooper et al. 1997)\n\n\n“As one possibility, suppose that a trial is performed in which clinicians are randomized either to have or not to have access to such a decision aid in making decisions about where to treat patients who present with pneumonia.”\n\n\n\n\n\n\n\n\n\n\n\nWhat we don’t learn\n\n\nwas the model predicting anything sensible?"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#so-build-prediction-models-and-trial-them",
    "href": "talks/240516-sig-causality-prediction/index.html#so-build-prediction-models-and-trial-them",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "So build prediction models and trial them?",
    "text": "So build prediction models and trial them?\nNot a good idea\n\nbaking a cake without a recipe\nhoping it turns into something nice\nnot pleasant to people that need to taste the experiment\n\n(i.e. patients may have side-effects / die)"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#models-that-are-likely-to-be-valuable-for-decision-making",
    "href": "talks/240516-sig-causality-prediction/index.html#models-that-are-likely-to-be-valuable-for-decision-making",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "Models that are likely to be valuable for decision making",
    "text": "Models that are likely to be valuable for decision making\n\nprediction under hypothetical interventions (prediction-under-intervention) models predict expected outcomes under the hypothetical intervention of giving a certain treatment\n\n\n\n\n\nHilden and Habbema on prognosis (Hilden and Habbema 1987)\n\n\n“Prognosis cannot be divorced from contemplated medical action, nor from action to be taken by the patient in response to prognostication.”\n\n\n\n\nwhereas treatment-naive prediction models average out over the historic treatment policy, prediction-under-intervention allows the user to select a treatment option\nprediction-under-intervention is not a new idea, but language and methods on causality have come a long way since (Hilden and Habbema 1987)."
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#estimand-for-prediction-under-intervention-models",
    "href": "talks/240516-sig-causality-prediction/index.html#estimand-for-prediction-under-intervention-models",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "Estimand for prediction-under-intervention models",
    "text": "Estimand for prediction-under-intervention models\nWhat is the estimand?\n\nprediction: \\(E[Y|X]\\)\ntreatment effect: \\(E[Y|\\text{do}(T=1)] - E[Y|\\text{do}(T=0)]\\)\nprediction-under-intervention: \\(E[Y|\\text{do}(T=t),X]\\)"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#estimating-prediction-under-intervention-models",
    "href": "talks/240516-sig-causality-prediction/index.html#estimating-prediction-under-intervention-models",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "Estimating prediction-under-intervention models",
    "text": "Estimating prediction-under-intervention models\n\nthe estimand \\(E[Y|\\text{do}(T=t),X]\\) is an interventional distribution\nRCTs randomly sample from interventional distributions\nprediction-under-intervention models may be estimated and evaluated in RCT data\nhowever, RCTs are typically designed to estimate a single parameter\nprediction models need more data\nin comes causal inference from observational data?"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#challenges-with-observational-data",
    "href": "talks/240516-sig-causality-prediction/index.html#challenges-with-observational-data",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "Challenges with observational data",
    "text": "Challenges with observational data\n\nassumption of no unobserved confounding may be hard to justify\nbut there’s more between heaven (RCT) and earth (confounder adjustment)\n\nproxy-variable methods\nconstant relative treatment effect assumption\ndiff-in-diff\ninstrumental variable analysis (high variance estimates)\nfront-door analysis"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#proxy-variables",
    "href": "talks/240516-sig-causality-prediction/index.html#proxy-variables",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "Proxy variables?",
    "text": "Proxy variables?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nproblem: didn’t observe confounder fitness so cannot do confounder adjustment\ninstead, leverage assumptions on confounder - proxy relationship (e.g. monotonicity)\neffect may still be identifyable (van Amsterdam et al. 2022)"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#constant-relative-treatment-effect",
    "href": "talks/240516-sig-causality-prediction/index.html#constant-relative-treatment-effect",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "Constant relative treatment effect?",
    "text": "Constant relative treatment effect?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWidely used paradigm (cardiovascular risk, chemotherapy in breast cancer, …)\nUntreated risk is a quantity of the interventional distribution (i.e. causal)\nCurrent risk-models: mix of treated / untreated patients (amsterdamAlgorithmsActionImproving2024?),\nor ungrounded methods (Candido dos Reis et al. 2017; Xu et al. 2021).\nNeed better `causal’ methods (van Amsterdam and Ranganath 2023)"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#prediction-under-intervention-approaches-sound-great",
    "href": "talks/240516-sig-causality-prediction/index.html#prediction-under-intervention-approaches-sound-great",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "Prediction-under-intervention approaches sound great",
    "text": "Prediction-under-intervention approaches sound great\n\nbut come with their own assumptions and trade-offs\ndo sensitivity analysis\nmay not have treatment information\nmay be many decision time-points, hard to formulate estimand over long time-horizon"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#how-to-proceed",
    "href": "talks/240516-sig-causality-prediction/index.html#how-to-proceed",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "How to proceed?",
    "text": "How to proceed?\n\nbuild prediction-under-intervention model with best data + assumptions\ntest policy value in historical RCT data of competing policies (e.g. current practice vs policy by new model)\n\nfor each patient in RCT, determine recommended treatment according to policy\nif actual (randomly allocated) treatment is concordant, keep the patient\nif not, drop observation\ncalculate average outcomes in the subpopulation\npolicy with highest average outcomes is best\n\nthen do a cluster RCT"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#take-aways",
    "href": "talks/240516-sig-causality-prediction/index.html#take-aways",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "Take-aways",
    "text": "Take-aways\n\nPrediction and causal inference come together neatly by declaring \\(E[Y|\\text{do}(T=t),X]\\) as the estimand\n(mis)using prediction models for treatment decisions without causal thinking and evaluation is a bad idea\ndeploying models for decision support is an intervention and should be evaluated as such\n\n\n\n\n\n\n\n\n\nFrom algorithms to action: improving patient care requires causality (amsterdamAlgorithmsActionImproving2024?)\n\n\n\n\n\n\nWhen accurate prediction models yield harmful sel-fulfilling prophecies (vanamsterdamWhenAccuratePrediction2024a?)"
  },
  {
    "objectID": "talks/240516-sig-causality-prediction/index.html#references",
    "href": "talks/240516-sig-causality-prediction/index.html#references",
    "title": "Causality and prediction: developing and validating models for decision making",
    "section": "References",
    "text": "References\n\n\n\n\nCandido dos Reis, Francisco J., Gordon C. Wishart, Ed M. Dicks, David Greenberg, Jem Rashbass, Marjanka K. Schmidt, Alexandra J. van den Broek, et al. 2017. “An Updated PREDICT Breast Cancer Prognostication and Treatment Benefit Prediction Model with Independent Validation.” Breast Cancer Research 19 (1): 58. https://doi.org/10/gbhgpq.\n\n\nCooper, Gregory F., Constantin F. Aliferis, Richard Ambrosino, John Aronis, Bruce G. Buchanan, Richard Caruana, Michael J. Fine, et al. 1997. “An Evaluation of Machine-Learning Methods for Predicting Pneumonia Mortality.” Artificial Intelligence in Medicine 9 (2): 107–38. https://doi.org/10.1016/S0933-3657(96)00367-3.\n\n\nHilden, Jørgen, and J. Dik F. Habbema. 1987. “Prognosis in Medicine: An Analysis of Its Meaning and rôles.” Theoretical Medicine 8 (3): 349–65. https://doi.org/10.1007/BF00489469.\n\n\nvan Amsterdam, Wouter A. C., and Rajesh Ranganath. 2023. “Conditional Average Treatment Effect Estimation with Marginally Constrained Models.” Journal of Causal Inference 11 (1): 20220027. https://doi.org/10.1515/jci-2022-0027.\n\n\nvan Amsterdam, Wouter A. C., Joost J. C. Verhoeff, Netanja I. Harlianto, Gijs A. Bartholomeus, Aahlad Manas Puli, Pim A. de Jong, Tim Leiner, Anne S. R. van Lindert, Marinus J. C. Eijkemans, and Rajesh Ranganath. 2022. “Individual Treatment Effect Estimation in the Presence of Unobserved Confounding Using Proxies: A Cohort Study in Stage III Non-Small Cell Lung Cancer.” Scientific Reports 12 (1): 5848. https://doi.org/10.1038/s41598-022-09775-9.\n\n\nXu, Zhe, Matthew Arnold, David Stevens, Stephen Kaptoge, Lisa Pennells, Michael J Sweeting, Jessica Barrett, Emanuele Di Angelantonio, and Angela M Wood. 2021. “Prediction of Cardiovascular Disease Risk Accounting for Future Initiation of Statin Treatment.” American Journal of Epidemiology, February, kwab031. https://doi.org/10/gmj9rw."
  },
  {
    "objectID": "talks/241125-ccm-methodsmeeting/index.html#motivation",
    "href": "talks/241125-ccm-methodsmeeting/index.html#motivation",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Motivation",
    "text": "Motivation\n\n\nclinicians use prediction models for medical decisions, e.g.\n\nmaking a diagnosis\nestimating a patients prognosis\ntriaging\ntreatment decisions\n\nthese prediction models need reliable performance\nissue: potential substantive difference between last evaluation and current use"
  },
  {
    "objectID": "talks/241125-ccm-methodsmeeting/index.html#change-in-setting",
    "href": "talks/241125-ccm-methodsmeeting/index.html#change-in-setting",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Change in setting",
    "text": "Change in setting\nWhat can we expect from the model’s performance (if anything) in the new setting?\n\n\n\n\n\n\n\n\n\nmodel trained / evaluated in tertiary care hospital\n\n\n\n\n\n\nmodel used in GP setting"
  },
  {
    "objectID": "talks/241125-ccm-methodsmeeting/index.html#this-paper-talk",
    "href": "talks/241125-ccm-methodsmeeting/index.html#this-paper-talk",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "This paper / talk",
    "text": "This paper / talk\n\nrecap performance: discrimination, calibration\nlook at the causal direction of the prediction:\n\nare we predicting an effect based on its causes (e.g. heart attack, based on cholesterol and age)\nare we predicting a cause based on its effects (infer presence of CVA based on neurological symptoms)\n\ndefine shift in case-mix as a change in the marginal distribution of the cause variable\nconclude that in theory:\n\nfor prognosis models: expect stable calibration, not discrimination\nfor diagnosis models: expect stable discrimination, not calibration\n\nillustrate with simulation\nevaluate on 2030+ prediction model evaluations"
  },
  {
    "objectID": "talks/241125-ccm-methodsmeeting/index.html#discrimination-sensitivity-specificity-auc",
    "href": "talks/241125-ccm-methodsmeeting/index.html#discrimination-sensitivity-specificity-auc",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Discrimination: sensitivity, specificity, AUC",
    "text": "Discrimination: sensitivity, specificity, AUC\n\nprediction model \\(f: X \\to [0,1]\\) (i.e. predicted probability, e.g. logistic regression)\ntake a threshold \\(\\tau\\), such that \\(f(x) &gt; \\tau\\) is a positive prediction\ntabulate predictions vs outcomes\n\n\n\n\n\n\n\noutcome\n\n\n\n\n\n\n\n1\n0\n\n\nprediction\n1\ntrue positives\nfalse positives\n\n\n\n0\nfalse negatives\ntrue negatives"
  },
  {
    "objectID": "talks/241125-ccm-methodsmeeting/index.html#discrimination-sensitivity-specificity",
    "href": "talks/241125-ccm-methodsmeeting/index.html#discrimination-sensitivity-specificity",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Discrimination: sensitivity, specificity",
    "text": "Discrimination: sensitivity, specificity\n\n\n\n\n\n\n\n\n\n\n\n\noutcome\n\n\n\n\n\n\n\n1\n0\n\n\nprediction\n1\ntrue positives\nfalse positives\n\n\n\n0\nfalse negatives\ntrue negatives\n\n\n\n\nsensitivity: TP / (TP+FN)\nspecificity: TN / (TN+FP)\n\n\n\n\n\nsensitivity: \\(P(X=1 | Y=1)\\), specificity: \\(P(X=0 | Y=0)\\)\nnote: sensitivity only requires data from the column of postive cases (i.e. \\(Y=1\\)), and specificity on negatives\nevent-rate: fraction of \\(Y=1\\) of total cases\nin theory discrimination is event-rate independent (Hond 2023)"
  },
  {
    "objectID": "talks/241125-ccm-methodsmeeting/index.html#discrimination-roc-curve-and-auc",
    "href": "talks/241125-ccm-methodsmeeting/index.html#discrimination-roc-curve-and-auc",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Discrimination: ROC curve and AUC",
    "text": "Discrimination: ROC curve and AUC\nif we vary the threshold \\(0 \\leq \\tau \\leq 1\\), we get a ROC curve, and the AUC is the area under this curve"
  },
  {
    "objectID": "talks/241125-ccm-methodsmeeting/index.html#calibration",
    "href": "talks/241125-ccm-methodsmeeting/index.html#calibration",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Calibration",
    "text": "Calibration\n“A model is said to be well calibrated if for every 100 patients given a risk of x%, close to x have the event.” (Van Calster and Vickers 2015)\n\n\n\n\n\n\n\n\n\npopulation\n\n\n\n\n\n\n\nsubgroup where \\(f(x)=10\\)%\n\n\n\n\n\n\n\nevent rate in said subgroup is 10%: \\(p(Y=1|f(x)=10\\%) = 10\\%\\)"
  },
  {
    "objectID": "talks/241125-ccm-methodsmeeting/index.html#calibration-plot",
    "href": "talks/241125-ccm-methodsmeeting/index.html#calibration-plot",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Calibration plot",
    "text": "Calibration plot\n\n\n\n\n\n\n\\(p(Y=1|X)\\) versus \\(f(x)\\)\n\n\n\ncalibration\n\n\n\n\n\n\ncalibration-plot"
  },
  {
    "objectID": "talks/241125-ccm-methodsmeeting/index.html#performance-metrics-summary",
    "href": "talks/241125-ccm-methodsmeeting/index.html#performance-metrics-summary",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Performance metrics summary",
    "text": "Performance metrics summary\n\ndiscrimination: function of \\(P(X|Y)\\) (features given outcome)\ncalibration: function of \\(P(Y|X)\\) (outcome given features)"
  },
  {
    "objectID": "talks/241125-ccm-methodsmeeting/index.html#where-does-the-association-come-from",
    "href": "talks/241125-ccm-methodsmeeting/index.html#where-does-the-association-come-from",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Where does the association come from?",
    "text": "Where does the association come from?\nIn prediction, we have features \\(X\\) and outcome \\(Y\\) and model \\(Y|X\\)\n1. \\(X\\) causes \\(Y\\): often in prognosis (\\(Y\\): heart-attack, \\(X\\): cholesterol and age)\n2. \\(Y\\) causes \\(X\\): often in diagnosis (CVA, based on neurological symptoms)\n3. \\(Z\\) causes both \\(X\\) and \\(Y\\): confounding (yellow fingers predict lung cancer)"
  },
  {
    "objectID": "talks/241125-ccm-methodsmeeting/index.html#defining-a-shift-in-case-mix",
    "href": "talks/241125-ccm-methodsmeeting/index.html#defining-a-shift-in-case-mix",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Defining a shift in case-mix",
    "text": "Defining a shift in case-mix\nDefine a shift in case-mix a change in the marginal distribution of the cause variable, e.g.\n\nfilter on risk factors (pregancies with type 1 diabetes in hospital)\nfilter on outcome risk (send patients with neurological symptoms to CVA center)\ndenote environment as variable \\(E\\):"
  },
  {
    "objectID": "talks/241125-ccm-methodsmeeting/index.html#what-does-this-definition-imply",
    "href": "talks/241125-ccm-methodsmeeting/index.html#what-does-this-definition-imply",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "What does this definition imply?",
    "text": "What does this definition imply?\n\n\n\n\n\n\n\n\n\n\n\\(P(Y|X,E) = P(Y|X)\\)\n\nin words: \\(P(Y|X)\\) is transportable across environments\nbecause there is no arrow from \\(E\\) to \\(Y\\), \\(X\\) blocks effect of \\(E\\) on \\(Y\\)\n\n\\(P(X|Y,E) \\neq P(X|Y)\\)\n\nin words: \\(P(X|Y)\\) is not transportable across environments\n\nimplication for causal (prognosis) prediction:\n\ncalibration is functional of \\(P(Y|X)\\), thus stable\ndiscrimination is functional of \\(P(X|Y)\\), thus not stable\n\nfor anti-causal (diagnosis) prediction: the reverse\nmain result: discrimination or calibration may be preserved under changes in case-mix, but never both"
  },
  {
    "objectID": "talks/241125-ccm-methodsmeeting/index.html#why-define-a-shift-in-case-mix-this-way",
    "href": "talks/241125-ccm-methodsmeeting/index.html#why-define-a-shift-in-case-mix-this-way",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Why define a shift in case-mix this way?",
    "text": "Why define a shift in case-mix this way?\n\ncause is temporally prior to effect, filtering at least on cause may be likely in many settings\nfiltering on both: anything goes, cannot say anything about expected performance based on graphical information"
  },
  {
    "objectID": "talks/241125-ccm-methodsmeeting/index.html#simulation-setup",
    "href": "talks/241125-ccm-methodsmeeting/index.html#simulation-setup",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Simulation setup",
    "text": "Simulation setup\n\\[\\begin{align*}\n    \\label{eq:dgm-prognosis}\n    \\text{prognosis:} &                     & \\text{diagnosis:} & \\\\\n    P_y &\\sim \\text{Beta}(\\alpha_e,\\beta_e) & y &\\sim \\text{Bernouli}(P_e) \\\\\n    x   &= \\text{logit}(P_y)                 & x &\\sim N(y, 1) \\\\\n    y   &\\sim \\text{Bernoulli}(P_y)         &   &\n\\end{align*}\\]"
  },
  {
    "objectID": "talks/241125-ccm-methodsmeeting/index.html#empirical-validation",
    "href": "talks/241125-ccm-methodsmeeting/index.html#empirical-validation",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Empirical validation",
    "text": "Empirical validation\n\na study of 2030+ evaluations of 1300+ prediction models (Wessler et al. 2021)\n\n\n\nregistry: all data available with only 4000 clicks\nsolution: scrape the website"
  },
  {
    "objectID": "talks/241125-ccm-methodsmeeting/index.html#results",
    "href": "talks/241125-ccm-methodsmeeting/index.html#results",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Results",
    "text": "Results\n\nfor each study, extract AUC on internal validation and for each external validation (no calibration data available)\ncalculate scaled deviation from internal AUC (\\(\\delta\\))\ntheory implies:\n\nfor prognosis models: \\(\\delta \\neq 0\\)\nfor diagnostic models: \\(\\delta=0\\)\n\ntest: variance of \\(\\delta\\) between evaluations of diagnostic or prognostic models (F-test)\nresult: \\(\\text{VAR}(\\delta_{\\text{diagnostic}})=0.019 \\approx 0.122 * \\text{VAR}(\\delta_{\\text{prognostic}})\\), p-value\\(&lt;0.001\\)"
  },
  {
    "objectID": "talks/241125-ccm-methodsmeeting/index.html#conclusion",
    "href": "talks/241125-ccm-methodsmeeting/index.html#conclusion",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Conclusion",
    "text": "Conclusion\n\ndiscrimination: a function of features given outcome\ncalibration: a function of outcome given outcome\nare we predicting an effect based on its causes (e.g. heart attack, based on cholesterol and age)\nare we predicting a cause based on its effects (infer presence of CVA based on neurological symptoms)\ndefine shift in case-mix as a change in the marginal distribution of the cause variable\nconclude that in theory:\n\nfor prognosis models: expect stable calibration, not discrimination\nfor diagnosis models: expect stable discrimination, not calibration\n\nillustrated with simulation, evaluated on 2030+ prediction model evaluations, one direction of theory seems confirmed\nfuture work: more empirical validations"
  },
  {
    "objectID": "talks/241125-ccm-methodsmeeting/index.html#questions",
    "href": "talks/241125-ccm-methodsmeeting/index.html#questions",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "Questions:",
    "text": "Questions:\n\nhow does this align with what you observed?\nwhere to publish this work?"
  },
  {
    "objectID": "talks/241125-ccm-methodsmeeting/index.html#references",
    "href": "talks/241125-ccm-methodsmeeting/index.html#references",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix",
    "section": "References",
    "text": "References\n\n\n\n\nHond, A. A. H. de. 2023. “From Code to Clinic: Theory and Practice for Artificial Intelligence Prediction Algorithms.” PhD thesis, Leiden University.\n\n\nVan Calster, Ben, and Andrew J. Vickers. 2015. “Calibration of Risk Prediction Models: Impact on Decision-Analytic Performance.” Medical Decision Making 35 (2): 162–69. https://doi.org/10.1177/0272989X14547233.\n\n\nWessler, Benjamin S., Jason Nelson, Jinny G. Park, Hannah McGinnes, Gaurav Gulati, Riley Brazil, Ben Van Calster, et al. 2021. “External Validations of Cardiovascular Clinical Prediction Models: A Large-Scale Review of the Literature.” Circulation: Cardiovascular Quality and Outcomes 14 (8): e007858. https://doi.org/10.1161/CIRCOUTCOMES.121.007858."
  },
  {
    "objectID": "talks/250417-ads-sigs/index.html#what-is-causality",
    "href": "talks/250417-ads-sigs/index.html#what-is-causality",
    "title": "Causal Data Science in Utrecht: causality for prediction model generalization",
    "section": "What is causality?",
    "text": "What is causality?\n\n\n\n\n\n\n\nPrediction:\n“What to expect when we passively observe the world”\n\n\nCausality:\n“What to expect when we actively intervene”"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#what-is-ai-1",
    "href": "talks/240418-ii-spring-meeting/index.html#what-is-ai-1",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "What is AI?",
    "text": "What is AI?\n\n\n\n\n\n\nWhat is artificial intelligence?\n\n\ncomputers doing tasks that normally require intelligence 1\n\n\n\n\n\n\n\n\n\n\nWhat is artificial general intelligence?\n\n\nGeneral purpose AI that performs a range of tasks in different domains like humans\n\n\n\n\nthese are my own definitions"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#ai-subsumes-rule-based-systems-and-machine-learning",
    "href": "talks/240418-ii-spring-meeting/index.html#ai-subsumes-rule-based-systems-and-machine-learning",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "AI subsumes rule-based systems and machine learning",
    "text": "AI subsumes rule-based systems and machine learning\n\nRule-based AI: knowledge base of rules\nMachine learning: statistical learning from examples #- (traditional) machine learning (logistic regression, SVM, RF, #GBM) #- modern machine learning: deep learning and foundation models"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#rule-based-systems-are-ai",
    "href": "talks/240418-ii-spring-meeting/index.html#rule-based-systems-are-ai",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "Rule-based systems are AI",
    "text": "Rule-based systems are AI\n\nrule: all cows are animals\nobservation: this is a cow \\(\\to\\) it is an animal\napplications:\n\nmedication interaction checkers\nbedside patient monitors"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#ml-tasks",
    "href": "talks/240418-ii-spring-meeting/index.html#ml-tasks",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "ML tasks",
    "text": "ML tasks\n\n\n\n\n\n\n\n\ndata:\n\n\n\ni\nlength\nweight\nsex\n\n\n\n\n1\n137\n30\nboy\n\n\n2\n122\n24\ngirl\n\n\n3\n101\n18\ngirl\n\n\n…\n…\n…\n…\n\n\n\n\n\\[l_i,w_i,s_i \\sim p(l,w,s)\\]"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#ml-tasks-generation",
    "href": "talks/240418-ii-spring-meeting/index.html#ml-tasks-generation",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "ML tasks: generation",
    "text": "ML tasks: generation\n\n\n\n\n\n\n\n\nuse samples to learn model \\(p_{\\theta}\\) for joint distribution \\(p\\) \\[\n  l_j,w_j,s_j \\sim p_{\\theta}(l,w,s)\n\\]"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#ml-tasks-conditional-generation",
    "href": "talks/240418-ii-spring-meeting/index.html#ml-tasks-conditional-generation",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "ML tasks: conditional generation",
    "text": "ML tasks: conditional generation\n\n\n\n\n\n\n\n\nuse samples to learn model for conditional distribution \\(p\\) \\[\n  l_j,w_j \\sim p_{\\theta}(l,w|s=\\text{boy})\n\\]\n\n\n\n\ntask\n\n\n\n\n\ngeneration\n\\(l_j,w_j,s_j \\sim p_{\\theta}(l,w,s)\\)"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#ml-tasks-conditional-generation-2",
    "href": "talks/240418-ii-spring-meeting/index.html#ml-tasks-conditional-generation-2",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "ML tasks: conditional generation 2",
    "text": "ML tasks: conditional generation 2\n\n\n\n\n\n\n\n\nuse samples to learn model for conditional distribution \\(p\\) of one variable \\[\ns_j \\sim p_{\\theta}(s|l=l',w=w')\n\\]\n\n\n\n\ntask\n\n\n\n\n\ngeneration\n\\(l_j,w_j,s_j \\sim p_{\\theta}(l,w,s)\\)\n\n\nconditional generation\n\\(l_j,w_j \\sim p_{\\theta}(l,w|s=\\text{boy})\\)"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#ml-tasks-discrimination",
    "href": "talks/240418-ii-spring-meeting/index.html#ml-tasks-discrimination",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "ML tasks: discrimination",
    "text": "ML tasks: discrimination\n\n\n\n\n\n\n\n\ncall this one variable outcome and classify when expected value passes threshold (e.g. 0.5): \\[\ns_j = p_{\\theta}(s|l=l',w=w') &gt; 0.5\n\\]\n\n\n\n\ntask\n\n\n\n\n\ngeneration\n\\(l_j,w_j,s_j \\sim p_{\\theta}(l,w,s)\\)\n\n\nconditional generation\n\\(l_j,w_j \\sim p_{\\theta}(l,w|s=\\text{boy})\\)\n\n\ndiscrimination\n\\(p_{\\theta}(s|l=l_i,w=w_i) &gt; 0.5\\)"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#ml-tasks-reinforcement-learning",
    "href": "talks/240418-ii-spring-meeting/index.html#ml-tasks-reinforcement-learning",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "ML tasks: reinforcement learning",
    "text": "ML tasks: reinforcement learning\n\ne.g. computers playing games\nmaybe not so useful for clinical research as requires many experiments"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#machine-learning-is-statistical-learning-with-flexible-models",
    "href": "talks/240418-ii-spring-meeting/index.html#machine-learning-is-statistical-learning-with-flexible-models",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "Machine learning is statistical learning with flexible models",
    "text": "Machine learning is statistical learning with flexible models\n\n\n- There is no fundamental difference between statistics and machine learning\n- both optimize parameters to improve some criterion (loss / likelihood) that measures model fit to data\n- models used in machine learning are more flexible"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#ml-models-can-fit-more-functions-but-also-more-likely-to-overfit",
    "href": "talks/240418-ii-spring-meeting/index.html#ml-models-can-fit-more-functions-but-also-more-likely-to-overfit",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "ML models can fit more functions but also more likely to overfit",
    "text": "ML models can fit more functions but also more likely to overfit"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#should-pick-the-right-amount-of-model-complexity",
    "href": "talks/240418-ii-spring-meeting/index.html#should-pick-the-right-amount-of-model-complexity",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "Should pick the ‘right’ amount of model complexity",
    "text": "Should pick the ‘right’ amount of model complexity"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#what-is-a-large-language-model-like-chatgpt-1",
    "href": "talks/240418-ii-spring-meeting/index.html#what-is-a-large-language-model-like-chatgpt-1",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "What is a large-language model like chatGPT?",
    "text": "What is a large-language model like chatGPT?\n\n\n\n\n\n\nWhat is chatGPT?\n\n\na stochastic auto-regressive next-word predictor with a chatbot interface\n\n\n\n\ntrained by predicting the next &lt;…&gt;\n\nin a large corpus of text\nwith a large model\nfor a long time on expensive hardware"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#auto-regressive-conditional-generation",
    "href": "talks/240418-ii-spring-meeting/index.html#auto-regressive-conditional-generation",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "auto-regressive conditional generation:",
    "text": "auto-regressive conditional generation:\n\\[\\begin{align}\n    \\text{word}_1 &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{prompt})\\\\\n\\end{align}\\]"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#auto-regressive-conditional-generation-1",
    "href": "talks/240418-ii-spring-meeting/index.html#auto-regressive-conditional-generation-1",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "auto-regressive conditional generation:",
    "text": "auto-regressive conditional generation:\n\\[\\begin{align}\n    \\text{word}_1 &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{prompt})\\\\\n    \\text{word}_2 &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{word}_1,\\text{prompt})\n\\end{align}\\]"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#auto-regressive-conditional-generation-2",
    "href": "talks/240418-ii-spring-meeting/index.html#auto-regressive-conditional-generation-2",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "auto-regressive conditional generation:",
    "text": "auto-regressive conditional generation:\n\\[\\begin{align}\n    \\text{word}_1 &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{prompt})\\\\\n    \\text{word}_2 &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{word}_1,\\text{prompt})\n\\end{align}\\]"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#auto-regressive-conditional-generation-3",
    "href": "talks/240418-ii-spring-meeting/index.html#auto-regressive-conditional-generation-3",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "auto-regressive conditional generation:",
    "text": "auto-regressive conditional generation:\n\\[\\begin{align}\n    \\text{word}_1 &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{prompt})\\\\\n    \\text{word}_2 &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{word}_1,\\text{prompt})\\\\\n    \\text{word}_n &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{word}_{n-1},\\ldots,\\text{word}_1,\\text{prompt})\n\\end{align}\\]"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#auto-regressive-conditional-generation-4",
    "href": "talks/240418-ii-spring-meeting/index.html#auto-regressive-conditional-generation-4",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "auto-regressive conditional generation:",
    "text": "auto-regressive conditional generation:\n\\[\\begin{align}\n    \\text{word}_1 &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{prompt})\\\\\n    \\text{word}_2 &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{word}_1,\\text{prompt})\\\\\n    \\text{word}_n &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{word}_{n-1},\\ldots,\\text{word}_1,\\text{prompt})\\\\\n    \\text{STOP}   &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{word}_{n-1},\\ldots,\\text{word}_1,\\text{prompt})\n\\end{align}\\]"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#gpt-4-scale",
    "href": "talks/240418-ii-spring-meeting/index.html#gpt-4-scale",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "GPT-4 scale",
    "text": "GPT-4 scale"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#rule-based-vs-llms",
    "href": "talks/240418-ii-spring-meeting/index.html#rule-based-vs-llms",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "rule-based vs LLMs",
    "text": "rule-based vs LLMs\n\n\n\ndeduction from explicit knowledge\nknowledge verifiable and fast\nconstrained to deducible\n\n\n\n\n\n\n\n\nextracted from observed data\nunverifiable and compute intensive\n“chatGPT seems to know(?) much”"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#ml-versus-statistics-when-to-use-what",
    "href": "talks/240418-ii-spring-meeting/index.html#ml-versus-statistics-when-to-use-what",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "ML versus statistics, when to use what",
    "text": "ML versus statistics, when to use what\n\n\nmachine learning\n\nhave more data\nmore complex functions (images)\n\n\nstatistics (e.g. GLMs)\n\nless data\nmore domain knowledge"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#a-sobering-note",
    "href": "talks/240418-ii-spring-meeting/index.html#a-sobering-note",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "A sobering note",
    "text": "A sobering note\n- ML in medicine has been ‘hot’ since at least the 90s (Cooper et al. 1997)\n- not much evidence that it outperforms regression on most tasks (Christodoulou et al. 2019)\n- though many poorly performed studies (Dhiman et al. 2022)"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#two-questions",
    "href": "talks/240418-ii-spring-meeting/index.html#two-questions",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "two questions",
    "text": "two questions\nQuestion 1\n\nprediction model of \\(Y|X\\) fits the data really well (AUC = 0.99 and perfect calibration)\nwill changing \\(X\\) induce a change \\(Y\\)?\n\nQuestion 2\n\nGive statins when risk of cardiovascular event in 10 years exceeds 10%\nML model based on age, medication history, cardiac CT-scan predicts this very well\nwill using this model for treatment decisions improve patient outcomes?"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#improving-the-world-is-a-causal-task",
    "href": "talks/240418-ii-spring-meeting/index.html#improving-the-world-is-a-causal-task",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "Improving the world is a causal task",
    "text": "Improving the world is a causal task\n\nstatistics / ML: what to expect when we passively observe the world\nnot how we can intervene to make things better, this requires causality\nQuestion 1\n\nyellowish fingers predict lung cancer, paint fingers to skin color?\nweight loss predicts death in lung cancer, send patients to couch with McDonalds?"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#when-accurate-prediction-models-yield-harmful-self-fulfilling-prophecies",
    "href": "talks/240418-ii-spring-meeting/index.html#when-accurate-prediction-models-yield-harmful-self-fulfilling-prophecies",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "When accurate prediction models yield harmful self-fulfilling prophecies",
    "text": "When accurate prediction models yield harmful self-fulfilling prophecies"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#prediction-modeling-is-very-popular-in-medical-research",
    "href": "talks/240418-ii-spring-meeting/index.html#prediction-modeling-is-very-popular-in-medical-research",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "Prediction modeling is very popular in medical research",
    "text": "Prediction modeling is very popular in medical research"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#treatment-naive-risk-models",
    "href": "talks/240418-ii-spring-meeting/index.html#treatment-naive-risk-models",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "Treatment-naive risk models",
    "text": "Treatment-naive risk models"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#is-this-obvious",
    "href": "talks/240418-ii-spring-meeting/index.html#is-this-obvious",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "Is this obvious?",
    "text": "Is this obvious?\n\n\n\n\n\n\nTip\n\n\nIt may seem obvious that you should not ignore historical treatments in your prediction models, if you want to improve treatment decisions, but many of these models are published daily, and some guidelines even allow for implementing these models based on predictve performance only"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#other-risk-models",
    "href": "talks/240418-ii-spring-meeting/index.html#other-risk-models",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "Other risk models:",
    "text": "Other risk models:\n- condition on given treatment and traits\n- unobserved confounding (hat type) leads to wrong treatment decisions"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#recommended-validation-practices-do-not-protect-against-harm",
    "href": "talks/240418-ii-spring-meeting/index.html#recommended-validation-practices-do-not-protect-against-harm",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "Recommended validation practices do not protect against harm",
    "text": "Recommended validation practices do not protect against harm\nbecause they do not evaluate the policy change"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#bigger-data-does-not-protect-against-harmful-risk-models",
    "href": "talks/240418-ii-spring-meeting/index.html#bigger-data-does-not-protect-against-harmful-risk-models",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "Bigger data does not protect against harmful risk models",
    "text": "Bigger data does not protect against harmful risk models"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#more-flexible-models-do-not-protect-against-harmful-risk-models",
    "href": "talks/240418-ii-spring-meeting/index.html#more-flexible-models-do-not-protect-against-harmful-risk-models",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "More flexible models do not protect against harmful risk models",
    "text": "More flexible models do not protect against harmful risk models"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#gap-between-prediction-accuracy-and-value-for-decision-making",
    "href": "talks/240418-ii-spring-meeting/index.html#gap-between-prediction-accuracy-and-value-for-decision-making",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "Gap between prediction accuracy and value for decision making",
    "text": "Gap between prediction accuracy and value for decision making"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#section",
    "href": "talks/240418-ii-spring-meeting/index.html#section",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "",
    "text": "What to do?"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#section-1",
    "href": "talks/240418-ii-spring-meeting/index.html#section-1",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "",
    "text": "What to do?\n\n\nEvaluate policy change (cluster randomized controlled trial)\nBuild models that are likely to have value for decision making"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#prediction-under-intervention-models",
    "href": "talks/240418-ii-spring-meeting/index.html#prediction-under-intervention-models",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "Prediction-under-intervention models",
    "text": "Prediction-under-intervention models\nPredict outcome under hypothetical intervention of giving certain treatment"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#when-developing-risk-models",
    "href": "talks/240418-ii-spring-meeting/index.html#when-developing-risk-models",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "When developing risk models,",
    "text": "When developing risk models,\nalways discuss:\n\n\n\n\n\n1. what is effect on treatment policy?\n2. what is effect on patient outcomes?"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#take-aways",
    "href": "talks/240418-ii-spring-meeting/index.html#take-aways",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "take-aways",
    "text": "take-aways\n\nAI subsumes rule-based programs and machine learning\nmachine learning is statistical learning from data with flexible models\nchatGPT does auto-regressive next-word prediction\nchatGPT produces beautiful mistakes: eloquently written logical fallacies\nprediction: what to expect when passively observing the world\ncausality: what happens when I change something?\nprediction models can cause harmful self-fulfilling prophecies when used for decision making\nwhen building prediction models for decision support, you cannot ignore decisions on the treatments in historic data\nmodels for prediction-under-intervention have foreseeable effects when used for decision making\nultimate test of model utility is determined by outcomes in (cluster) RCT"
  },
  {
    "objectID": "talks/240418-ii-spring-meeting/index.html#references",
    "href": "talks/240418-ii-spring-meeting/index.html#references",
    "title": "AI and its (mis)uses in medical research and practice",
    "section": "",
    "text": "thank you\n\n\n\n\nAmsterdam, Wouter A. C. van, Nan van Geloven, Jesse H. Krijthe, Rajesh Ranganath, and Giovanni Ciná. 2024. “When Accurate Prediction Models Yield Harmful Self-Fulfilling Prophecies.” arXiv. https://doi.org/10.48550/arXiv.2312.01210.\n\n\nAmsterdam, Wouter A. C. van, Pim A. de Jong, Joost J. C. Verhoeff, Tim Leiner, and Rajesh Ranganath. 2024. “From Algorithms to Action: Improving Patient Care Requires Causality.” arXiv. https://doi.org/10.48550/arXiv.2209.07397.\n\n\nChristodoulou, Evangelia, Jie Ma, Gary S. Collins, Ewout W. Steyerberg, Jan Y. Verbakel, and Ben Van Calster. 2019. “A Systematic Review Shows No Performance Benefit of Machine Learning over Logistic Regression for Clinical Prediction Models.” Journal of Clinical Epidemiology 110 (June): 12–22. https://doi.org/10.1016/j.jclinepi.2019.02.004.\n\n\nCooper, Gregory F., Constantin F. Aliferis, Richard Ambrosino, John Aronis, Bruce G. Buchanan, Richard Caruana, Michael J. Fine, et al. 1997. “An Evaluation of Machine-Learning Methods for Predicting Pneumonia Mortality.” Artificial Intelligence in Medicine 9 (2): 107–38. https://doi.org/10.1016/S0933-3657(96)00367-3.\n\n\nDhiman, Paula, Jie Ma, Constanza L. Andaur Navarro, Benjamin Speich, Garrett Bullock, Johanna A. A. Damen, Lotty Hooft, et al. 2022. “Methodological Conduct of Prognostic Prediction Models Developed Using Machine Learning in Oncology: A Systematic Review.” BMC Medical Research Methodology 22 (1): 101. https://doi.org/10.1186/s12874-022-01577-x."
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#use-ai-for-medical-imaging",
    "href": "talks/240708-imaging-ailab/index.html#use-ai-for-medical-imaging",
    "title": "Medical imaging and AI for decision support",
    "section": "Use AI for medical imaging",
    "text": "Use AI for medical imaging\nto make healthcare easier or more efficient\n\nAcquisition (\\(S \\to X\\))\n\n\n\nk-space to MRI image\nraw projection data to CT image\n\n\n\ndetection / segmentation (\\(X \\to X\\))\n\n\n\nsegmenting organs at risk in radiotherapy\n\n\n\ninference / diagnosis (\\(X \\to D\\), both at prediction time)\n\n\n\nmedical diagnosis\npsuedo CT from MRI"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#use-ai-for-medical-imaging-1",
    "href": "talks/240708-imaging-ailab/index.html#use-ai-for-medical-imaging-1",
    "title": "Medical imaging and AI for decision support",
    "section": "Use AI for medical imaging",
    "text": "Use AI for medical imaging\nto make healthcare better (improve decisions)\n\nprognosis (\\(X \\to Y\\), \\(Y\\) in the future)\n\n\n\nexpected survival time given CT-scan\n\n\n\ntreatment effect (\\(X\\) determines effect of a treatment \\(T\\) on outcome \\(Y\\) in the future)"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#ai-treatment-effect",
    "href": "talks/240708-imaging-ailab/index.html#ai-treatment-effect",
    "title": "Medical imaging and AI for decision support",
    "section": "Why would you estimate treatment effects based on images?",
    "text": "Why would you estimate treatment effects based on images?\n\n\ntreatments have different effects on patients based on their (disease) characteristics\nfor example, whether tamoxifen increases survival for breast cancer patients depends on whether their tumor is hormone sensitive\nsome characteristics may be well captured in medical imaging:\n\nT-cell distributions around tumors related to effect of immunotherapy in cancer\nheterogeneity of tumor on CT may predict response to radiotherapy\nholistic view of ‘body composition’ on CT-scans determines whether patient can tolerate chemotherapy"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#how-to-estimate-treatment-effects-based-on-images",
    "href": "talks/240708-imaging-ailab/index.html#how-to-estimate-treatment-effects-based-on-images",
    "title": "Medical imaging and AI for decision support",
    "section": "How to estimate treatment effects based on images?",
    "text": "How to estimate treatment effects based on images?\n\nIn principle the same as estimating a subgroup treatment effect (e.g. male vs female)\n\nConduct a randomized controlled trial where the treatments of interest are randomly allocated\nCollect (imaging) data at randomization timepoint\nUse a statistical learning technique like TARnet (Shalit, Johansson, and Sontag 2017) to estimate outcomes conditional on image and treatment\nconditional treatment effect \\(= f(X,T=1) - f(X,T=0)\\)\n\n\n\n\n\nWhat if you cannot do a (big enough) RCT?\n\n\nEmulate / approximate the ideal trial in observational data you do have, using causal inference techniques\n(which rely on untestable assumptions)"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#improving-decisions-with-ai",
    "href": "talks/240708-imaging-ailab/index.html#improving-decisions-with-ai",
    "title": "Medical imaging and AI for decision support",
    "section": "Improving decisions with AI",
    "text": "Improving decisions with AI\n\n\nprognosis (\\(X \\to Y\\), \\(Y\\) in the future)\ntreatment effect (\\(X\\) determines effect of a treatment \\(T\\) on outcome \\(Y\\) in the future)\n\n\n\nWhereas treatment effect estimation is typically thought of as a causal task requiring causal approaches (e.g. randomized controllerd trials)\nPrognosis models are often developed without any causal thinking (if it predicts it predicts)\nbut then advertised for making treatment decisions."
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#the-in-between-using-prediction-models-for-medical-decision-making",
    "href": "talks/240708-imaging-ailab/index.html#the-in-between-using-prediction-models-for-medical-decision-making",
    "title": "Medical imaging and AI for decision support",
    "section": "The in-between: using prediction models for (medical) decision making",
    "text": "The in-between: using prediction models for (medical) decision making\n\n\nprognosis (e.g. survival given medical image)"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#using-prediction-models-for-decision-making-is-often-thought-of-as-a-good-idea",
    "href": "talks/240708-imaging-ailab/index.html#using-prediction-models-for-decision-making-is-often-thought-of-as-a-good-idea",
    "title": "Medical imaging and AI for decision support",
    "section": "Using prediction models for decision making is often thought of as a good idea",
    "text": "Using prediction models for decision making is often thought of as a good idea\nFor example:\n\ngive chemotherapy to cancer patients with high predicted risk of recurrence\ngive statins to patients with a high risk of a heart attack\n\n\n\n\n\nTRIPOD+AI on prediction models (collinsTRIPODAIStatement2024?)\n\n\n“Their primary use is to support clinical decision making, such as … initiate treatment or lifestyle changes.”"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#building-models-for-decision-support-without-regards-for-the-historic-treatment-policy-is-a-bad-idea",
    "href": "talks/240708-imaging-ailab/index.html#building-models-for-decision-support-without-regards-for-the-historic-treatment-policy-is-a-bad-idea",
    "title": "Medical imaging and AI for decision support",
    "section": "Building models for decision support without regards for the historic treatment policy is a bad idea",
    "text": "Building models for decision support without regards for the historic treatment policy is a bad idea"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#treatment-naive-prediction-models",
    "href": "talks/240708-imaging-ailab/index.html#treatment-naive-prediction-models",
    "title": "Medical imaging and AI for decision support",
    "section": "Treatment-naive prediction models",
    "text": "Treatment-naive prediction models\n\n\n\n\n\\[\\begin{align}\n    E[Y|X] \\class{fragment}{= E[E_{t~\\sim \\pi_0(X)}[Y|X,t]]}\n\\end{align}\\]"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#treatment-naive-prediction-models-1",
    "href": "talks/240708-imaging-ailab/index.html#treatment-naive-prediction-models-1",
    "title": "Medical imaging and AI for decision support",
    "section": "Treatment-naive prediction models",
    "text": "Treatment-naive prediction models\n(Results from W. A. C. van Amsterdam, van Geloven, et al. 2024)\n\ngood or bad discrimination post deployment may be a sign of a harmful or a beneficial policy change\nmodels that are perfectly calibrated before and after deployment are certainly not useful for decision making because they didn’t change the distribution"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#prediction-modeling-is-very-popular-in-medical-research",
    "href": "talks/240708-imaging-ailab/index.html#prediction-modeling-is-very-popular-in-medical-research",
    "title": "Medical imaging and AI for decision support",
    "section": "Prediction modeling is very popular in medical research",
    "text": "Prediction modeling is very popular in medical research"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#recommended-validation-practices-and-reporting-guidelines-do-not-protect-against-harm",
    "href": "talks/240708-imaging-ailab/index.html#recommended-validation-practices-and-reporting-guidelines-do-not-protect-against-harm",
    "title": "Medical imaging and AI for decision support",
    "section": "Recommended validation practices and reporting guidelines do not protect against harm",
    "text": "Recommended validation practices and reporting guidelines do not protect against harm\nbecause they do not evaluate the policy change"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#bigger-data-does-not-protect-against-harmful-prediction-models",
    "href": "talks/240708-imaging-ailab/index.html#bigger-data-does-not-protect-against-harmful-prediction-models",
    "title": "Medical imaging and AI for decision support",
    "section": "Bigger data does not protect against harmful prediction models",
    "text": "Bigger data does not protect against harmful prediction models"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#more-flexible-models-do-not-protect-against-harmful-prediction-models",
    "href": "talks/240708-imaging-ailab/index.html#more-flexible-models-do-not-protect-against-harmful-prediction-models",
    "title": "Medical imaging and AI for decision support",
    "section": "More flexible models do not protect against harmful prediction models",
    "text": "More flexible models do not protect against harmful prediction models"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#section",
    "href": "talks/240708-imaging-ailab/index.html#section",
    "title": "Medical imaging and AI for decision support",
    "section": "",
    "text": "What to do?"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#section-1",
    "href": "talks/240708-imaging-ailab/index.html#section-1",
    "title": "Medical imaging and AI for decision support",
    "section": "",
    "text": "What to do?\n\n\nEvaluate policy change (cluster randomized controlled trial)\nBuild models that are likely to have value for decision making"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#deploying-a-model-is-an-intervention-that-changes-the-way-treatment-decisions-are-made",
    "href": "talks/240708-imaging-ailab/index.html#deploying-a-model-is-an-intervention-that-changes-the-way-treatment-decisions-are-made",
    "title": "Medical imaging and AI for decision support",
    "section": "Deploying a model is an intervention that changes the way treatment decisions are made",
    "text": "Deploying a model is an intervention that changes the way treatment decisions are made"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#how-do-we-learn-about-the-effect-of-an-intervention",
    "href": "talks/240708-imaging-ailab/index.html#how-do-we-learn-about-the-effect-of-an-intervention",
    "title": "Medical imaging and AI for decision support",
    "section": "How do we learn about the effect of an intervention?",
    "text": "How do we learn about the effect of an intervention?\nWith a randomized experiment\n\n\nfor using a decision support model, the unit of intervention is usually the doctor\nrandomly assign doctors to have access to the model or not\nmeasure differences in treatment decisions and patient outcomes\nthis called a cluster RCT\nif using model improves outcomes, use that one\n\n\n\n\n\nUsing cluster RCTs to evaluated models for decision making is not a new idea (Cooper et al. 1997)\n\n\n“As one possibility, suppose that a trial is performed in which clinicians are randomized either to have or not to have access to such a decision aid in making decisions about where to treat patients who present with pneumonia.”\n\n\n\n\n\n\n\n\n\n\n\nWhat we don’t learn\n\n\nwas the model predicting anything sensible?"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#so-build-treatment-naive-prediction-models-and-trial-them-for-decision-support",
    "href": "talks/240708-imaging-ailab/index.html#so-build-treatment-naive-prediction-models-and-trial-them-for-decision-support",
    "title": "Medical imaging and AI for decision support",
    "section": "So build treatment-naive prediction models and trial them for decision support?",
    "text": "So build treatment-naive prediction models and trial them for decision support?\nNot a good idea\n\nbaking a cake without a recipe\nhoping it turns into something nice\nnot pleasant to people that need to taste result of the experiment\n\n(i.e. patients may have side-effects / die)"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#we-should-build-models-that-are-likely-to-be-valuable-for-decision-making",
    "href": "talks/240708-imaging-ailab/index.html#we-should-build-models-that-are-likely-to-be-valuable-for-decision-making",
    "title": "Medical imaging and AI for decision support",
    "section": "We should build models that are likely to be valuable for decision making",
    "text": "We should build models that are likely to be valuable for decision making\n\nBuild models that predict expected outcomes under hypothetical interventions (prediction-under-intervention models)\ndoctor / patient can pick the treatment with best expected outcomes, depending on patient’s values and preferences\nwhereas treatment-naive prediction models average out over the historic treatment policy, prediction-under-intervention allows the user to select a treatment option\n\n\n\n\n\nHilden and Habbema on prognosis (Hilden and Habbema 1987)\n\n\n“Prognosis cannot be divorced from contemplated medical action, nor from action to be taken by the patient in response to prognostication.”\n\n\n\n\nprediction-under-intervention is not a new idea, but language and methods on causality have come a long way since (Hilden and Habbema 1987)."
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#estimand-for-prediction-under-intervention-models",
    "href": "talks/240708-imaging-ailab/index.html#estimand-for-prediction-under-intervention-models",
    "title": "Medical imaging and AI for decision support",
    "section": "Estimand for prediction-under-intervention models",
    "text": "Estimand for prediction-under-intervention models\nWhat is the estimand?\n\nprediction: \\(E[Y|X]\\)\naverage treatment effect: \\(E[Y|\\text{do}(T=1)] - E[Y|\\text{do}(T=0)]\\)\nconditional average treatment effect: \\(E[Y|\\text{do}(T=1),X] - E[Y|\\text{do}(T=0),X]\\)\nprediction-under-intervention: \\(E[Y|\\text{do}(T=t),X]\\)"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#more-on-prediction-under-intervention-models",
    "href": "talks/240708-imaging-ailab/index.html#more-on-prediction-under-intervention-models",
    "title": "Medical imaging and AI for decision support",
    "section": "More on prediction-under-intervention models",
    "text": "More on prediction-under-intervention models\ndevelopment:\n\nideally estimated from RCTs, but these are often too small or don’t measure the right data\nalternatively can use observational data and causal inference methods\nassumption of no unobserved confounding often hard to justify in observational data\nbut there’s more between heaven (RCT) and earth (confounder adjustment)\n\nproxy-variable methods (e.g. Miao, Geng, and Tchetgen Tchetgen 2018; Wouter A. C. van Amsterdam et al. 2022)\nconstant relative treatment effect assumption (e.g. Alaa et al. 2021; Wouter A. C. van Amsterdam and Ranganath 2023; Candido dos Reis et al. 2017)\ndiff-in-diff\ninstrumental variable analysis (Wald 1940; Puli and Ranganath 2021; Hartford et al. 2017)\nfront-door analysis\n\nmany of these have potential new applications with AI and medical imaging"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#evaluation-of-prediction-under-intervention-models",
    "href": "talks/240708-imaging-ailab/index.html#evaluation-of-prediction-under-intervention-models",
    "title": "Medical imaging and AI for decision support",
    "section": "Evaluation of prediction-under-intervention models",
    "text": "Evaluation of prediction-under-intervention models\n\nprediction accuracy can be tested in RCTs, or in observational data with specialized methods accounting for confounding (e.g. Keogh and van Geloven 2024)\nin confounded observational data, typical metrics (e.g. AUC or calibration) are not sufficient as we want to predict well in data from other distribution than observed data (i.e. other treatment decisions)\na new policy can be evaluated in historic RCTs (e.g. Karmali et al. 2018)\nultimate test is cluster RCT\nif not perfect, likely a better recipe than treatment-naive models"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#take-aways",
    "href": "talks/240708-imaging-ailab/index.html#take-aways",
    "title": "Medical imaging and AI for decision support",
    "section": "Take-aways",
    "text": "Take-aways\n\ndeploying models for decision support is an intervention and should be evaluated as such\nwhen developing or evaluating (AI) prediction models for medical decisions, think about\n\nwhat is the effect of using this model on medical decisions?\nwhat is the effect of this policy change on patient outcomes?\n\nprediction-under-intervention models have a foreseeable effect on patient oucomes when used for decision making\n\n\n\n\n\n\n\n\n\nFrom algorithms to action: improving patient care requires causality (W. A. C. van Amsterdam, Jong, et al. 2024)\n\n\n\n\n\n\nWhen accurate prediction models yield harmful sel-fulfilling prophecies (W. A. C. van Amsterdam, van Geloven, et al. 2024)"
  },
  {
    "objectID": "talks/240708-imaging-ailab/index.html#references",
    "href": "talks/240708-imaging-ailab/index.html#references",
    "title": "Medical imaging and AI for decision support",
    "section": "References",
    "text": "References\n\n\n\n\nAlaa, Ahmed M., Deepti Gurdasani, Adrian L. Harris, Jem Rashbass, and Mihaela van der Schaar. 2021. “Machine Learning to Guide the Use of Adjuvant Therapies for Breast Cancer.” Nature Machine Intelligence, June, 1–11. https://doi.org/10/gk6bh7.\n\n\nCandido dos Reis, Francisco J., Gordon C. Wishart, Ed M. Dicks, David Greenberg, Jem Rashbass, Marjanka K. Schmidt, Alexandra J. van den Broek, et al. 2017. “An Updated PREDICT Breast Cancer Prognostication and Treatment Benefit Prediction Model with Independent Validation.” Breast Cancer Research 19 (1): 58. https://doi.org/10/gbhgpq.\n\n\nCooper, Gregory F., Constantin F. Aliferis, Richard Ambrosino, John Aronis, Bruce G. Buchanan, Richard Caruana, Michael J. Fine, et al. 1997. “An Evaluation of Machine-Learning Methods for Predicting Pneumonia Mortality.” Artificial Intelligence in Medicine 9 (2): 107–38. https://doi.org/10.1016/S0933-3657(96)00367-3.\n\n\nHartford, Jason, Greg Lewis, Kevin Leyton-Brown, and Matt Taddy. 2017. “Deep IV: A Flexible Approach for Counterfactual Prediction.” In International Conference on Machine Learning, 1414–23. PMLR.\n\n\nHilden, Jørgen, and J. Dik F. Habbema. 1987. “Prognosis in Medicine: An Analysis of Its Meaning and rôles.” Theoretical Medicine 8 (3): 349–65. https://doi.org/10.1007/BF00489469.\n\n\nKarmali, Kunal N., Donald M. Lloyd-Jones, Joep van der Leeuw, David C. Goff Jr, Salim Yusuf, Alberto Zanchetti, Paul Glasziou, et al. 2018. “Blood Pressure-Lowering Treatment Strategies Based on Cardiovascular Risk Versus Blood Pressure: A Meta-Analysis of Individual Participant Data.” PLOS Medicine 15 (3): e1002538. https://doi.org/10.1371/journal.pmed.1002538.\n\n\nKeogh, Ruth H., and Nan van Geloven. 2024. “Prediction Under Interventions: Evaluation of Counterfactual Performance Using Longitudinal Observational Data.” arXiv. https://doi.org/10.48550/arXiv.2304.10005.\n\n\nMiao, Wang, Zhi Geng, and Eric J Tchetgen Tchetgen. 2018. “Identifying Causal Effects with Proxy Variables of an Unmeasured Confounder.” Biometrika 105 (4): 987–93. https://doi.org/10.1093/biomet/asy038.\n\n\nPuli, Aahlad Manas, and Rajesh Ranganath. 2021. “General Control Functions for Causal Effect Estimation from Instrumental Variables.” arXiv:1907.03451 [Cs, Stat], February. https://arxiv.org/abs/1907.03451.\n\n\nShalit, Uri, Fredrik D. Johansson, and David Sontag. 2017. “Estimating Individual Treatment Effect: Generalization Bounds and Algorithms.” arXiv:1606.03976 [Cs, Stat], May. https://arxiv.org/abs/1606.03976.\n\n\nvan Amsterdam, W. A. C., Pim A. de Jong, Joost J. C. Verhoeff, Tim Leiner, and Rajesh Ranganath. 2024. “From Algorithms to Action: Improving Patient Care Requires Causality.” BMC Medical Informatics and Decision Making 24 (1). https://doi.org/10.1186/s12911-024-02513-3.\n\n\nvan Amsterdam, W. A. C., Nan van Geloven, Jesse H. Krijthe, Rajesh Ranganath, and Giovanni Ciná. 2024. “When Accurate Prediction Models Yield Harmful Self-Fulfilling Prophecies.” arXiv. https://doi.org/10.48550/arXiv.2312.01210.\n\n\nvan Amsterdam, Wouter A. C., and Rajesh Ranganath. 2023. “Conditional Average Treatment Effect Estimation with Marginally Constrained Models.” Journal of Causal Inference 11 (1): 20220027. https://doi.org/10.1515/jci-2022-0027.\n\n\nvan Amsterdam, Wouter A. C., Joost J. C. Verhoeff, Netanja I. Harlianto, Gijs A. Bartholomeus, Aahlad Manas Puli, Pim A. de Jong, Tim Leiner, Anne S. R. van Lindert, Marinus J. C. Eijkemans, and Rajesh Ranganath. 2022. “Individual Treatment Effect Estimation in the Presence of Unobserved Confounding Using Proxies: A Cohort Study in Stage III Non-Small Cell Lung Cancer.” Scientific Reports 12 (1): 5848. https://doi.org/10.1038/s41598-022-09775-9.\n\n\nWald, Abraham. 1940. “The Fitting of Straight Lines If Both Variables Are Subject to Error.” The Annals of Mathematical Statistics 11 (3): 284–300. https://doi.org/10.1214/aoms/1177731868."
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#about",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#about",
    "title": "An introduction to AI for biostatisticians",
    "section": "About",
    "text": "About\n\nUniversity Medical Center Utrecht\n\nDivision: Julius Center for Health Sciences and Primary Care\n\nDepartment: Data Science & Biostatistics\n\nSub-department: Data Science Methods\n\n\n\nBackground:\n\nphysics (BSc.)\nmedicine (MD.)\nmachine learning / causal inference in healthcare (PhD.)\nepidemiology / biostatistics (MSc.)\n\nWork on:\n\ncausal inference and machine learning in health care\nmethods and applications"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#disclaimer",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#disclaimer",
    "title": "An introduction to AI for biostatisticians",
    "section": "Disclaimer",
    "text": "Disclaimer\n\nof course, I used AI to help with the slides\n\ngenerate tikz diagrams with github copilot\nwrite text and equations with github copilot\ngenerate vector illustrations in adobe illustrator\ngenerate png images with Bing chat\n\nno competing interests"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#definition",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#definition",
    "title": "An introduction to AI for biostatisticians",
    "section": "Definition",
    "text": "Definition\n\n\n\n\n\n\nWhat is AI?\n\n\nArtificial Intelligence is the branch of computer science that focuses on creating systems capable of performing tasks that typically require human intelligence. (Russell and Norvig 2020)\n\n\n\n\nThese tasks include: learning, reasoning, problem-solving, perception, natural language understanding, and decision-making.\nAI systems can be designed to operate autonomously, adapt to new inputs, and improve their performance over time."
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#early-milestones",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#early-milestones",
    "title": "An introduction to AI for biostatisticians",
    "section": "Early Milestones",
    "text": "Early Milestones\n\n1940s: Concept of AI emerged with Alan Turing’s work on computation and intelligence.\n1956: The term “Artificial Intelligence” was coined at the Dartmouth Conference by John McCarthy.\n1960s-1970s: Early AI programs focused on solving algebra, proving theorems, and playing games (e.g., Chess)."
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#key-developments",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#key-developments",
    "title": "An introduction to AI for biostatisticians",
    "section": "Key Developments",
    "text": "Key Developments\n\n1980s: Introduction of expert systems (rule-based systems for decision making).\n1990s: Machine learning began gaining traction, allowing AI systems to learn from data.\n2010s: Deep learning and neural networks revolutionized AI, enabling breakthroughs in areas like image recognition, natural language processing, and more."
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#ai-landscape-what-is-ai",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#ai-landscape-what-is-ai",
    "title": "An introduction to AI for biostatisticians",
    "section": "AI landscape: what is AI?",
    "text": "AI landscape: what is AI?"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#rule-based-systems-are-ai",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#rule-based-systems-are-ai",
    "title": "An introduction to AI for biostatisticians",
    "section": "Rule-based systems are AI",
    "text": "Rule-based systems are AI\n\n\n\n\n\n\n\nrule: all cows are animals\nobservation: this is a cow \\(\\to\\) it is an animal\napplications in health care:\n\nmedication interaction checkers\nbedside patient monitors\n\ne.g. if heart rate &gt; 100, alert nurse"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#assume-we-have-this-data",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#assume-we-have-this-data",
    "title": "An introduction to AI for biostatisticians",
    "section": "Assume we have this data",
    "text": "Assume we have this data\n\n\n\n\n\n\n\n\n\n\n\ni\nlength\nweight\nsex\n\n\n\n\n1\n137\n30\nboy\n\n\n2\n122\n24\ngirl\n\n\n3\n101\n18\ngirl\n\n\n…\n…\n…\n…\n\n\n\n\nWe typically assume these data are (i.i.d.) samples from some unknown distribution \\(p(l,w,s)\\):\n\\[l_i,w_i,s_i \\sim p(l,w,s)\\]"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#ml-tasks-generation",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#ml-tasks-generation",
    "title": "An introduction to AI for biostatisticians",
    "section": "ML tasks: generation",
    "text": "ML tasks: generation\n\n\n\n\n\n\n\n\n\nformulate a model for joint distribution \\(p_{\\theta}\\)\n\nstatistics: ‘small’ model family\nmachine learning: ‘large’ model family\n\nuse samples to optimize \\(\\theta\\)\ngenerate new samples\n\n\\[l_j,w_j,s_j \\sim p_{\\theta}(l,w,s)\\]\n\n\n\n\ntask\n\n\n\n\n\ngeneration\n\\(l_j,w_j,s_j \\sim p_{\\theta}(l,w,s)\\)\n\n\n\n\n\napplication: simulate data for power calculations, privacy-preserving data sharing"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#ml-tasks-conditional-generation",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#ml-tasks-conditional-generation",
    "title": "An introduction to AI for biostatisticians",
    "section": "ML tasks: conditional generation",
    "text": "ML tasks: conditional generation\n\n\n\n\n\n\n\n\nuse samples to learn model for conditional distribution \\(p\\) \\[\n  l_j,w_j \\sim p_{\\theta}(l,w|s=\\text{boy})\n\\]\n\n\n\n\ntask\n\n\n\n\n\ngeneration\n\\(l_j,w_j,s_j \\sim p_{\\theta}(l,w,s)\\)\n\n\nconditional generation\n\\(l_j,w_j \\sim p_{\\theta}(l,w|s=\\text{boy})\\)\n\n\n\n\n\napplication: imputation, question answering"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#ml-tasks-conditional-generation-2",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#ml-tasks-conditional-generation-2",
    "title": "An introduction to AI for biostatisticians",
    "section": "ML tasks: conditional generation 2",
    "text": "ML tasks: conditional generation 2\n\n\n\n\n\n\n\n\nuse samples to learn model for conditional distribution \\(p\\) of one variable \\[\ns_j \\sim p_{\\theta}(s|l=l',w=w')\n\\]\n\n\n\ntask\n\n\n\n\n\ngeneration\n\\(l_j,w_j,s_j \\sim p_{\\theta}(l,w,s)\\)\n\n\nconditional generation\n\\(l_j,w_j \\sim p_{\\theta}(l,w|s=\\text{boy})\\)"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#ml-tasks-discrimination-classification",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#ml-tasks-discrimination-classification",
    "title": "An introduction to AI for biostatisticians",
    "section": "ML tasks: discrimination / classification",
    "text": "ML tasks: discrimination / classification\n\n\n\n\n\n\n\n\ncall this one variable outcome and - classify when majority of generated samples are of a certain class - or: have a model that outputs expected values \\[\ns_j = p_{\\theta}(s|l=l',w=w') &gt; 0.5\n\\]\n\n\n\ntask\n\n\n\n\n\ngeneration\n\\(l_j,w_j,s_j \\sim p_{\\theta}(l,w,s)\\)\n\n\nconditional generation\n\\(l_j,w_j \\sim p_{\\theta}(l,w|s=\\text{boy})\\)\n\n\ndiscrimination\n\\(p_{\\theta}(s|l=l_i,w=w_i) &gt; 0.5\\)\n\n\n\n\napplication: prediction, diagnosis"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#ml-tasks-reinforcement-learning",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#ml-tasks-reinforcement-learning",
    "title": "An introduction to AI for biostatisticians",
    "section": "ML tasks: reinforcement learning",
    "text": "ML tasks: reinforcement learning\n\ne.g. computers playing games\ntypically requires many experiments, maybe not too useful in health care"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#neural-networks-and-deep-learning",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#neural-networks-and-deep-learning",
    "title": "An introduction to AI for biostatisticians",
    "section": "Neural Networks and Deep Learning",
    "text": "Neural Networks and Deep Learning\nFrom Linear Regression …\n\n\n\n\n\n\n\n\n\n\\[y = \\sum_{i=0}^5 x_i \\beta_i\\]\n\noptimize \\(\\beta_i\\) to minimize mean squared error, e.g. using second-order methods"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#neural-networks-and-deep-learning-1",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#neural-networks-and-deep-learning-1",
    "title": "An introduction to AI for biostatisticians",
    "section": "Neural Networks and Deep Learning",
    "text": "Neural Networks and Deep Learning\n… to ‘Deep’ Learning\n\n\n\n\n\n\n\n\n\n\\[\\begin{align}\n    h_i &= w_{0i} + w_{1i} x_1 + \\ldots \\\\\n    h_i &= g(h_i) \\\\\n      y &= \\sum_{i=1}^3 h_i w_i\n\\end{align}\\]\n\nsticked \\(h_i\\) between input and output\n\\(g\\) is a non-linear function: each \\(h_i\\) is a non-linear transformation of the input\nrenamed \\(\\beta_i\\) (‘coefficients’) to \\(w_{0i}\\) and \\(w_i\\) (‘weights’)"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#why-would-neural-networks-work",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#why-would-neural-networks-work",
    "title": "An introduction to AI for biostatisticians",
    "section": "Why would neural networks work?",
    "text": "Why would neural networks work?\n\ntrue underlying relationships may be non-linear\nuniversal approximation theorem: a neural network with one hidden layer of sufficient width can approximate any continuous function\nproblems:\n\nno longer convex optimization\ntypical second-order optimizers scale quadratically or worse with number of parameters\ndeterministic computation, but not easily understandable (black box)"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#training-neural-networks",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#training-neural-networks",
    "title": "An introduction to AI for biostatisticians",
    "section": "Training neural networks",
    "text": "Training neural networks\n\nuse framework to define ‘forward-pass’ of network (e.g. PyTorch, TensorFlow, Keras, Jax)\ndeep learning: initialize parameters randomly, use gradient descent (first-order) methods\ndefine loss function (e.g. mean squared error, cross-entropy (a.k.a. log-loss))\nuse optimizer to minimize loss function (e.g. Stochastic Gradient Descent, Adam)"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#stochastic-gradient-descent",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#stochastic-gradient-descent",
    "title": "An introduction to AI for biostatisticians",
    "section": "Stochastic gradient descent",
    "text": "Stochastic gradient descent\n\\[L(\\theta) = \\sum_{i=1}^n \\ell(y_i, f(x_i;\\theta))\\]\n\ntake mini-batch of size \\(m &lt;&lt; n\\)\ncalculate loss on mini-batch and approximate gradient:\n\n\\[\\nabla L(\\theta) \\approx \\frac{1}{m} \\sum_{i=1}^m \\nabla \\ell(y_i, f(x_i;\\theta))\\]\n\nupdate parameter one step\n\n\\[\\theta_{t+1} = \\theta_t - \\alpha \\nabla L(\\theta)\\]"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#training-neural-networks-1",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#training-neural-networks-1",
    "title": "An introduction to AI for biostatisticians",
    "section": "Training neural networks",
    "text": "Training neural networks\n\nbig networks require much memory and computation: do parallel on graphics processing units (GPUs) with mini-batches of data (i.e. stochastic gradient descent)\ntrain on training data, validate on validation data\nafter all tuning is done, evaluate on test data\nhow to prevent over-fitting?"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#regularization",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#regularization",
    "title": "An introduction to AI for biostatisticians",
    "section": "Regularization",
    "text": "Regularization\n\nregularization:\n\nL1 (lasso) / L2 (Ridge): add penalty to weights"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#early-stopping",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#early-stopping",
    "title": "An introduction to AI for biostatisticians",
    "section": "Early stopping",
    "text": "Early stopping"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#regularization-1",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#regularization-1",
    "title": "An introduction to AI for biostatisticians",
    "section": "Regularization",
    "text": "Regularization\n\nregularization:\n\nL1 (lasso) / L2 (Ridge): add penalty to weights\nearly stopping: stop training when validation error starts increasing\nrandom initialization: initialize weights randomly\nalso:\n\ndropout: randomly set some weights to zero\nbatch normalization: normalize inputs of each layer\ndata augmentation: increase diversity of training data\n\n\n\n\n\n\n\n\n\n\nParameter counting is a bad proxy for model complexity in neural networks\n\n\nWhereas in regression models, model complexity is well-captured by the number of parameters, this is not the case for neural networks."
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#convolutional-neural-networks",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#convolutional-neural-networks",
    "title": "An introduction to AI for biostatisticians",
    "section": "Convolutional Neural Networks",
    "text": "Convolutional Neural Networks\nImage as matrix of pixel values\n\nDOI: 10.1093/llc/fqy085"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#convolutional-neural-networks-1",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#convolutional-neural-networks-1",
    "title": "An introduction to AI for biostatisticians",
    "section": "Convolutional Neural Networks",
    "text": "Convolutional Neural Networks\nConvolution operation"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#convolutional-neural-networks-2",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#convolutional-neural-networks-2",
    "title": "An introduction to AI for biostatisticians",
    "section": "Convolutional Neural Networks",
    "text": "Convolutional Neural Networks\nImages have local structure"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#convolutional-neural-networks-3",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#convolutional-neural-networks-3",
    "title": "An introduction to AI for biostatisticians",
    "section": "Convolutional Neural Networks",
    "text": "Convolutional Neural Networks\nCNNs build hierarchical features with local invariant structure"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#where-would-cnns-be-useful-in-healthcare",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#where-would-cnns-be-useful-in-healthcare",
    "title": "An introduction to AI for biostatisticians",
    "section": "Where would CNNs be useful in healthcare?",
    "text": "Where would CNNs be useful in healthcare?\n\nimages crucial importance in many healthcare setting, e.g. dermatology, radiology\ntake lung cancer diagnosis on chest radiographs\n\ntraditional statistical approach: ask radiologist to summarize medical image with some key features\n\ntumor size, location\noutcome: benign or malignant\n\nCNN approach: learn directly from images to outcome\n\nlearn representation while doing so\nincorporate domain knowledge (e.g. invariances to e.g. translations)"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#neural-networks-for-sequence-data",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#neural-networks-for-sequence-data",
    "title": "An introduction to AI for biostatisticians",
    "section": "Neural Networks for Sequence data",
    "text": "Neural Networks for Sequence data\n\n\n\n\n\n\n\nmany data are sequences: text, time series, DNA\nspecific architectures for sequence data\n\nRecurrent Neural Networks (RNNs)\nnatural language processing: Transformers (Vaswani et al. 2023)\n\n\n\n\n\n\n\nTransformer Architecture"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#chatgpt-a-stochastic-auto-regressive-conditional-generator-with-a-chatbot-interface",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#chatgpt-a-stochastic-auto-regressive-conditional-generator-with-a-chatbot-interface",
    "title": "An introduction to AI for biostatisticians",
    "section": "chatGPT: a stochastic auto-regressive conditional generator with a chatbot interface",
    "text": "chatGPT: a stochastic auto-regressive conditional generator with a chatbot interface\n\n\n\n\n\n\n\ntrained by predicting the next &lt;…&gt; (word)\n\nin a large corpus of text\nwith a large model\nfor a long time on expensive hardware\n\npost-processed to optimize user experience (remove offensive language, etc.)\n\n\npresent test-user with two generated answers, ask which is better\nif user picks one, use that as training signal"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#auto-regressive-conditional-generation",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#auto-regressive-conditional-generation",
    "title": "An introduction to AI for biostatisticians",
    "section": "auto-regressive conditional generation:",
    "text": "auto-regressive conditional generation:\n\\[\\begin{align}\n    \\text{word}_1 &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{prompt})\n\\end{align}\\]"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#auto-regressive-conditional-generation-1",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#auto-regressive-conditional-generation-1",
    "title": "An introduction to AI for biostatisticians",
    "section": "auto-regressive conditional generation:",
    "text": "auto-regressive conditional generation:\nPrompt=“Frank went to the bar and”\n\\[\\begin{align}\n    \\color{green}{had} &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{Frank went to the bar and})\n\\end{align}\\]"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#auto-regressive-conditional-generation-2",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#auto-regressive-conditional-generation-2",
    "title": "An introduction to AI for biostatisticians",
    "section": "auto-regressive conditional generation:",
    "text": "auto-regressive conditional generation:\nPrompt=“Frank went to the bar and”\n\\[\\begin{align}\n    \\color{green}{had} &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{Frank went to the bar and})\\\\\n    \\color{orange}{a} &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{Frank went to the bar and } \\color{green}{had})\n\\end{align}\\]"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#auto-regressive-conditional-generation-3",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#auto-regressive-conditional-generation-3",
    "title": "An introduction to AI for biostatisticians",
    "section": "auto-regressive conditional generation:",
    "text": "auto-regressive conditional generation:\nPrompt=“Frank went to the bar and”\n\\[\\begin{align}\n    \\color{green}{had} &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{Frank went to the bar and})\\\\\n    \\color{orange}{a} &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{Frank went to the bar and } \\color{green}{had})\\\\\n    \\color{red}{drink} &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{Frank went to the bar and } \\color{green}{had} \\ \\color{orange}{a})\n\\end{align}\\]"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#auto-regressive-conditional-generation-4",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#auto-regressive-conditional-generation-4",
    "title": "An introduction to AI for biostatisticians",
    "section": "auto-regressive conditional generation:",
    "text": "auto-regressive conditional generation:\nPrompt=“Frank went to the bar and”\n\\[\\begin{align}\n    \\color{green}{had} &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{Frank went to the bar and})\\\\\n    \\color{orange}{a} &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{Frank went to the bar and } \\color{green}{had})\\\\\n    \\color{red}{drink} &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{Frank went to the bar and } \\color{green}{had} \\ \\color{orange}{a})\\\\\n    \\text{STOP} &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{Frank went to the bar and } \\color{green}{had} \\ \\color{orange}{a} \\ \\color{red}{drink})\n\\end{align}\\]"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#stochastic-auto-regressive-conditional-generation",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#stochastic-auto-regressive-conditional-generation",
    "title": "An introduction to AI for biostatisticians",
    "section": "stochastic auto-regressive conditional generation:",
    "text": "stochastic auto-regressive conditional generation:\nPrompt=“Frank went to the bar and”\n\\[\\begin{align}\n    \\color{green}{met} &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{Frank went to the bar and})\n\\end{align}\\]"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#stochastic-auto-regressive-conditional-generation-1",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#stochastic-auto-regressive-conditional-generation-1",
    "title": "An introduction to AI for biostatisticians",
    "section": "stochastic auto-regressive conditional generation:",
    "text": "stochastic auto-regressive conditional generation:\nPrompt=“Frank went to the bar and”\n\\[\\begin{align}\n    \\color{green}{met} &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{Frank went to the bar and})\\\\\n    \\color{orange}{a} &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{Frank went to the bar and } \\color{green}{met})\n\\end{align}\\]"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#stochastic-auto-regressive-conditional-generation-2",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#stochastic-auto-regressive-conditional-generation-2",
    "title": "An introduction to AI for biostatisticians",
    "section": "stochastic auto-regressive conditional generation:",
    "text": "stochastic auto-regressive conditional generation:\nPrompt=“Frank went to the bar and”\n\\[\\begin{align}\n    \\color{green}{met} &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{Frank went to the bar and})\\\\\n    \\color{orange}{a} &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{Frank went to the bar and } \\color{green}{met})\\\\\n    \\color{red}{friend} &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{Frank went to the bar and } \\color{green}{met} \\ \\color{orange}{a})\n\\end{align}\\]"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#stochastic-auto-regressive-conditional-generation-3",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#stochastic-auto-regressive-conditional-generation-3",
    "title": "An introduction to AI for biostatisticians",
    "section": "stochastic auto-regressive conditional generation:",
    "text": "stochastic auto-regressive conditional generation:\nPrompt=“Frank went to the bar and”\n\\[\\begin{align}\n    \\color{green}{met} &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{Frank went to the bar and})\\\\\n    \\color{orange}{a} &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{Frank went to the bar and } \\color{green}{met})\\\\\n    \\color{red}{friend} &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{Frank went to the bar and } \\color{green}{met} \\ \\color{orange}{a})\\\\\n    \\text{STOP} &\\sim p_{\\text{chatGPT}}(\\text{word}|\\text{Frank went to the bar and } \\color{green}{met} \\ \\color{orange}{a} \\ \\color{red}{friend})\n\\end{align}\\]"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#gpt-4-scale-underlying-current-chatgpt",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#gpt-4-scale-underlying-current-chatgpt",
    "title": "An introduction to AI for biostatisticians",
    "section": "GPT-4 scale (underlying current ChatGPT)",
    "text": "GPT-4 scale (underlying current ChatGPT)"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#for-complex-tasks-neural-networks-keep-getting-better-with",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#for-complex-tasks-neural-networks-keep-getting-better-with",
    "title": "An introduction to AI for biostatisticians",
    "section": "For complex tasks, neural networks keep getting better with:",
    "text": "For complex tasks, neural networks keep getting better with:\n- more compute resources\n- bigger data\n- bigger models (enabled by data and compute)\n\n\n\n\n(Kaplan et al. 2020)\n\n\n\n\n\n(Kaplan et al. 2020)\n\n\n\n\n\n(Kaplan et al. 2020)"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#scaling-over-time",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#scaling-over-time",
    "title": "An introduction to AI for biostatisticians",
    "section": "scaling over time",
    "text": "scaling over time"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#neural-network-architectures",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#neural-network-architectures",
    "title": "An introduction to AI for biostatisticians",
    "section": "Neural Network Architectures",
    "text": "Neural Network Architectures\n\ncommon theme:\nuse an architecture that fits the data type well\n\nimages with local structure: CNNs\ntime series: RNNs\n\nscale!"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#rule-based-ai-versus-chatgpt",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#rule-based-ai-versus-chatgpt",
    "title": "An introduction to AI for biostatisticians",
    "section": "rule-based AI versus chatGPT",
    "text": "rule-based AI versus chatGPT\n\n\n\n\n\n\n\nrule-based AI:\n\nexplicit rules\nno learning, restricted to rules\ndependable, verifiable\n\n\n\n\nLLMs:\n\nno explicit rules\nlearned from data, can ‘learn’ almost anything\nnot dependable, not verifiable\nproduces text that may have appeared in training data (‘the internet’)"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#what-we-dont-know-about-chatgpt",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#what-we-dont-know-about-chatgpt",
    "title": "An introduction to AI for biostatisticians",
    "section": "What we don’t know about chatGPT",
    "text": "What we don’t know about chatGPT\n\nwhat data was it trained on, what is the architecture?\ndoes it have a world model? does it understand?\ndoes next-word prediction imply understanding?\ncan we interrogate it to self-explain: chain of thought tests?\nare these explanations faithful?\nare these explanations correct?"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#what-might-llms-be-useful-for-in-health-care",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#what-might-llms-be-useful-for-in-health-care",
    "title": "An introduction to AI for biostatisticians",
    "section": "What might LLMs be useful for in health care?",
    "text": "What might LLMs be useful for in health care?\n\nanything with expert control:\n\nadministration:\n\ndraft discharge letters\n\nthinking ‘outside the box’:\n\ngenerate hypotheses (potential diagnoses)\n\n\nmore dangerous\n\neducation\n\nunreliable\n\ndecision support"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#ai-wrap-up",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#ai-wrap-up",
    "title": "An introduction to AI for biostatisticians",
    "section": "AI wrap-up",
    "text": "AI wrap-up\n\nbeen around for long\nbecame very successful in past decades with deep learning\nimages: convolutional neural networks\nLLMs: next-word prediction\nscaling: more data, more compute, bigger models"
  },
  {
    "objectID": "talks/240926-bmsaned-ai-in-health/index.html#references",
    "href": "talks/240926-bmsaned-ai-in-health/index.html#references",
    "title": "An introduction to AI for biostatisticians",
    "section": "References",
    "text": "References\n\n\n\n\nKaplan, Jared, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. 2020. “Scaling Laws for Neural Language Models.” arXiv. https://doi.org/10.48550/arXiv.2001.08361.\n\n\nMoen, Erick, Dylan Bannon, Takamasa Kudo, William Graf, Markus Covert, and David Van Valen. 2019. “Deep Learning for Cellular Image Analysis.” Nature Methods 16 (12): 1233–46. https://doi.org/10.1038/s41592-019-0403-1.\n\n\nRussell, Stuart, and Peter Norvig. 2020. Artificial Intelligence: A Modern Approach. Pearson.\n\n\nSamuel, A. L. 1959. “Some Studies in Machine Learning Using the Game of Checkers.” IBM Journal of Research and Development 3 (3): 210–29. https://doi.org/10.1147/rd.33.0210.\n\n\nVaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2023. “Attention Is All You Need.” arXiv. https://arxiv.org/abs/1706.03762."
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#ai-may-have-many-uses-in-health-care",
    "href": "talks/240530-weon-masterclass/index.html#ai-may-have-many-uses-in-health-care",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "AI may have many uses in health care",
    "text": "AI may have many uses in health care\nUse AI to make health care\n\n\nmore efficient or easier\n\nadministration / documentation\ntranslation\n\n\nbetter: change decisions\n\ndiagnosis (e.g. skin cancer from imaging)\nprognosis (e.g. survival given medical image)\ntreatment effect (e.g. genetic biomarker)"
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#section",
    "href": "talks/240530-weon-masterclass/index.html#section",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "",
    "text": "prognosis (e.g. survival given medical image)\ntreatment effect (e.g. genetic biomarker)\n\n\n\n\n\n\nTip\n\n\nWhereas treatment effect estimation is typically thought of as a causal task requiring causal approaches (e.g. randomized controllerd trials), prognosis models are often advertised for making treatment decisions."
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#the-in-between-using-prediction-models-for-medical-decision-making",
    "href": "talks/240530-weon-masterclass/index.html#the-in-between-using-prediction-models-for-medical-decision-making",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "The in-between: using prediction models for (medical) decision making",
    "text": "The in-between: using prediction models for (medical) decision making\n\n\nprognosis (e.g. survival given medical image)"
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#using-prediction-models-for-decision-making-is-often-thought-of-as-a-good-idea",
    "href": "talks/240530-weon-masterclass/index.html#using-prediction-models-for-decision-making-is-often-thought-of-as-a-good-idea",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "Using prediction models for decision making is often thought of as a good idea",
    "text": "Using prediction models for decision making is often thought of as a good idea\nFor example:\n\ngive chemotherapy to cancer patients with high predicted risk of recurrence\ngive statins to patients with a high risk of a heart attack\n\n\n\n\n\nTRIPOD+AI on prediction models (collinsTRIPODAIStatement2024?)\n\n\n“Their primary use is to support clinical decision making, such as … initiate treatment or lifestyle changes.”"
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#building-models-for-decision-support-without-regards-for-the-historic-treatment-policy-is-a-bad-idea",
    "href": "talks/240530-weon-masterclass/index.html#building-models-for-decision-support-without-regards-for-the-historic-treatment-policy-is-a-bad-idea",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "Building models for decision support without regards for the historic treatment policy is a bad idea",
    "text": "Building models for decision support without regards for the historic treatment policy is a bad idea"
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#treatment-naive-prediction-models",
    "href": "talks/240530-weon-masterclass/index.html#treatment-naive-prediction-models",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "Treatment-naive prediction models",
    "text": "Treatment-naive prediction models\n\n\n\n\n\\[\\begin{align}\n    E[Y|X] \\class{fragment}{= E[E_{t~\\sim \\pi_0(X)}[Y|X,t]]}\n\\end{align}\\]"
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#treatment-naive-prediction-models-1",
    "href": "talks/240530-weon-masterclass/index.html#treatment-naive-prediction-models-1",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "Treatment-naive prediction models",
    "text": "Treatment-naive prediction models\nResults from (vanamsterdamWhenAccuratePrediction2024a?)\n\ngood or bad discrimination post deployment may be a sign of a harmful or a beneficial policy change\nmodels that are perfectly calibrated before and after deployment are certainly not useful for decision making because they didn’t change the distribution"
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#prediction-modeling-is-very-popular-in-medical-research",
    "href": "talks/240530-weon-masterclass/index.html#prediction-modeling-is-very-popular-in-medical-research",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "Prediction modeling is very popular in medical research",
    "text": "Prediction modeling is very popular in medical research"
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#recommended-validation-practices-and-reporting-guidelines-do-not-protect-against-harm",
    "href": "talks/240530-weon-masterclass/index.html#recommended-validation-practices-and-reporting-guidelines-do-not-protect-against-harm",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "Recommended validation practices and reporting guidelines do not protect against harm",
    "text": "Recommended validation practices and reporting guidelines do not protect against harm\nbecause they do not evaluate the policy change"
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#bigger-data-does-not-protect-against-harmful-prediction-models",
    "href": "talks/240530-weon-masterclass/index.html#bigger-data-does-not-protect-against-harmful-prediction-models",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "Bigger data does not protect against harmful prediction models",
    "text": "Bigger data does not protect against harmful prediction models"
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#more-flexible-models-do-not-protect-against-harmful-prediction-models",
    "href": "talks/240530-weon-masterclass/index.html#more-flexible-models-do-not-protect-against-harmful-prediction-models",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "More flexible models do not protect against harmful prediction models",
    "text": "More flexible models do not protect against harmful prediction models"
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#gap-between-prediction-accuracy-and-value-for-decision-making",
    "href": "talks/240530-weon-masterclass/index.html#gap-between-prediction-accuracy-and-value-for-decision-making",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "Gap between prediction accuracy and value for decision making",
    "text": "Gap between prediction accuracy and value for decision making"
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#section-1",
    "href": "talks/240530-weon-masterclass/index.html#section-1",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "",
    "text": "What to do?"
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#section-2",
    "href": "talks/240530-weon-masterclass/index.html#section-2",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "",
    "text": "What to do?\n\n\nEvaluate policy change (cluster randomized controlled trial)\nBuild models that are likely to have value for decision making"
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#deploying-a-model-is-an-intervention-that-changes-the-way-treatment-decisions-are-made",
    "href": "talks/240530-weon-masterclass/index.html#deploying-a-model-is-an-intervention-that-changes-the-way-treatment-decisions-are-made",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "Deploying a model is an intervention that changes the way treatment decisions are made",
    "text": "Deploying a model is an intervention that changes the way treatment decisions are made"
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#how-do-we-learn-about-the-effect-of-an-intervention",
    "href": "talks/240530-weon-masterclass/index.html#how-do-we-learn-about-the-effect-of-an-intervention",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "How do we learn about the effect of an intervention?",
    "text": "How do we learn about the effect of an intervention?\nWith a randomized experiment\n\n\nfor using a decision support model, the unit of intervention is usually the doctor\nrandomly assign doctors to have access to the model or not\nmeasure differences in treatment decisions and patient outcomes\nthis called a cluster RCT\nif using model improves outcomes, use that one\n\n\n\n\n\nUsing cluster RCTs to evaluated models for decision making is not a new idea (Cooper et al. 1997)\n\n\n“As one possibility, suppose that a trial is performed in which clinicians are randomized either to have or not to have access to such a decision aid in making decisions about where to treat patients who present with pneumonia.”\n\n\n\n\n\n\n\n\n\n\n\nWhat we don’t learn\n\n\nwas the model predicting anything sensible?"
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#so-build-treatment-naive-prediction-models-and-trial-them-for-decision-support",
    "href": "talks/240530-weon-masterclass/index.html#so-build-treatment-naive-prediction-models-and-trial-them-for-decision-support",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "So build treatment-naive prediction models and trial them for decision support?",
    "text": "So build treatment-naive prediction models and trial them for decision support?\nNot a good idea\n\nbaking a cake without a recipe\nhoping it turns into something nice\nnot pleasant to people that need to taste result of the experiment\n\n(i.e. patients may have side-effects / die)"
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#we-should-build-models-that-are-likely-to-be-valuable-for-decision-making",
    "href": "talks/240530-weon-masterclass/index.html#we-should-build-models-that-are-likely-to-be-valuable-for-decision-making",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "We should build models that are likely to be valuable for decision making",
    "text": "We should build models that are likely to be valuable for decision making\n\nBuild models that predict expected outcomes under hypothetical interventions (prediction-under-intervention models)\ndoctor / patient can pick the treatment with best expected outcomes, depending on patient’s values\nwhereas treatment-naive prediction models average out over the historic treatment policy, prediction-under-intervention allows the user to select a treatment option\n\n\n\n\n\nHilden and Habbema on prognosis (Hilden and Habbema 1987)\n\n\n“Prognosis cannot be divorced from contemplated medical action, nor from action to be taken by the patient in response to prognostication.”\n\n\n\n\nprediction-under-intervention is not a new idea, but language and methods on causality have come a long way since (Hilden and Habbema 1987)."
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#estimand-for-prediction-under-intervention-models",
    "href": "talks/240530-weon-masterclass/index.html#estimand-for-prediction-under-intervention-models",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "Estimand for prediction-under-intervention models",
    "text": "Estimand for prediction-under-intervention models\nWhat is the estimand?\n\nprediction: \\(E[Y|X]\\)\ntreatment effect: \\(E[Y|\\text{do}(T=1)] - E[Y|\\text{do}(T=0)]\\)\nprediction-under-intervention: \\(E[Y|\\text{do}(T=t),X]\\)"
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#more-on-prediction-under-intervention-models",
    "href": "talks/240530-weon-masterclass/index.html#more-on-prediction-under-intervention-models",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "More on prediction-under-intervention models",
    "text": "More on prediction-under-intervention models\ndevelopment:\n\nideally estimated from RCTs, but these are often too small or don’t measure the right data\nalternatively can use observational data and causal inference methods\n\nthis approach relies on strong assumptions especially regarding confounding\n\nbut likely a better recipe than treatment-naive models\n\n\nevaluation:\n\nprediction accuracy can be tested in RCTs, or in observational data with specialized methods accounting for confounding (e.g. Keogh and van Geloven 2024)\na new policy can be evaluated in historic RCTs (e.g. Karmali et al. 2018)\nultimate test is cluster RCT"
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#take-aways",
    "href": "talks/240530-weon-masterclass/index.html#take-aways",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "Take-aways",
    "text": "Take-aways\n\nwhen developing or evaluating (AI) prediction models for medical decisions, think about\n\nwhat is the effect of using this model on medical decisions?\nwhat is the effect of this policy change on patient outcomes?\n\ndeploying models for decision support is an intervention and should be evaluated as such\nprediction-under-intervention models have a foreseeable effect on patient oucomes when used for decision making\n\n\n\n\n\n\n\n\n\nFrom algorithms to action: improving patient care requires causality (amsterdamAlgorithmsActionImproving2024?)\n\n\n\n\n\n\nWhen accurate prediction models yield harmful sel-fulfilling prophecies (vanamsterdamWhenAccuratePrediction2024a?)"
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#new-summerschool-introduction-to-causal-inference-and-causal-data-science",
    "href": "talks/240530-weon-masterclass/index.html#new-summerschool-introduction-to-causal-inference-and-causal-data-science",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "New summerschool: Introduction to Causal Inference and Causal Data Science",
    "text": "New summerschool: Introduction to Causal Inference and Causal Data Science\nLearn more about causal data science\n\n\n\n\nDates: 5 Aug. - 9 Aug. 2024\nLocation: Utrecht\nInstructors:\n\nOisin Ryan\nBas Penning-de Vries\nWouter van Amsterdam\n\nSign up still possible\n\n\n\n\nCourse website"
  },
  {
    "objectID": "talks/240530-weon-masterclass/index.html#references",
    "href": "talks/240530-weon-masterclass/index.html#references",
    "title": "Uses and pitfalls with AI for decision support - harmful self-fulfilling prophecies",
    "section": "References",
    "text": "References\n\n\n\n\nCooper, Gregory F., Constantin F. Aliferis, Richard Ambrosino, John Aronis, Bruce G. Buchanan, Richard Caruana, Michael J. Fine, et al. 1997. “An Evaluation of Machine-Learning Methods for Predicting Pneumonia Mortality.” Artificial Intelligence in Medicine 9 (2): 107–38. https://doi.org/10.1016/S0933-3657(96)00367-3.\n\n\nHilden, Jørgen, and J. Dik F. Habbema. 1987. “Prognosis in Medicine: An Analysis of Its Meaning and rôles.” Theoretical Medicine 8 (3): 349–65. https://doi.org/10.1007/BF00489469.\n\n\nKarmali, Kunal N., Donald M. Lloyd-Jones, Joep van der Leeuw, David C. Goff Jr, Salim Yusuf, Alberto Zanchetti, Paul Glasziou, et al. 2018. “Blood Pressure-Lowering Treatment Strategies Based on Cardiovascular Risk Versus Blood Pressure: A Meta-Analysis of Individual Participant Data.” PLOS Medicine 15 (3): e1002538. https://doi.org/10.1371/journal.pmed.1002538.\n\n\nKeogh, Ruth H., and Nan van Geloven. 2024. “Prediction Under Interventions: Evaluation of Counterfactual Performance Using Longitudinal Observational Data.” arXiv. https://doi.org/10.48550/arXiv.2304.10005."
  },
  {
    "objectID": "talks/250127-dagstuhl/index.html#ai-deployment-as-an-intervention",
    "href": "talks/250127-dagstuhl/index.html#ai-deployment-as-an-intervention",
    "title": "my priorities for AI in health",
    "section": "AI deployment as an intervention",
    "text": "AI deployment as an intervention"
  },
  {
    "objectID": "talks/250127-dagstuhl/index.html#when-accurate-prediction-models-yield-harmful-self-fulfilling-prophecies",
    "href": "talks/250127-dagstuhl/index.html#when-accurate-prediction-models-yield-harmful-self-fulfilling-prophecies",
    "title": "my priorities for AI in health",
    "section": "When accurate prediction models yield harmful self-fulfilling prophecies",
    "text": "When accurate prediction models yield harmful self-fulfilling prophecies\nHow this can go wrong if we misalign the AI evaluation metric and the patient oucome\nPatterns, 2025"
  },
  {
    "objectID": "talks/250127-dagstuhl/index.html#why-is-it-hard",
    "href": "talks/250127-dagstuhl/index.html#why-is-it-hard",
    "title": "my priorities for AI in health",
    "section": "why is it hard:",
    "text": "why is it hard:\n\nAI deployment is an intervention, knowing whether this improved outcomes for patients is causal inference (Joshi et al. 2025) \nbefore-after comparison plagued by potential time-trends\noptimal pre-deployment evidence: (cluster) RCT\nafter deployment: changes in the data\n\nby the deployment (that was what we wanted)\nand many other factors.\n\nmeasures of prediction accuracy do not automatically translate in patient benefit (van Amsterdam et al. 2025)"
  },
  {
    "objectID": "talks/250127-dagstuhl/index.html#opportunities",
    "href": "talks/250127-dagstuhl/index.html#opportunities",
    "title": "my priorities for AI in health",
    "section": "opportunities",
    "text": "opportunities\n\nwhat to track after deployment?\n\naccuracy, outcomes\n\nhow to track after deployment?\n\nrandomization on center level: need many centers (possible in large health systems in the US?);\nrandomization on patient label: need consent\n\nethics in randomization; who provides consent?\ncombine AI + causal inference + trial design + ethics"
  },
  {
    "objectID": "talks/250127-dagstuhl/index.html#prediction-under-intervention-why-work-on-it",
    "href": "talks/250127-dagstuhl/index.html#prediction-under-intervention-why-work-on-it",
    "title": "my priorities for AI in health",
    "section": "Prediction-under-intervention, why work on it?",
    "text": "Prediction-under-intervention, why work on it?\nPrediction under intervention is estimating expected outcomes under hypothetical interventions, conditional on patient characteristics\n\n(aka counterfactual prediction)\n\n\n\\[E[Y|X,\\text{do}(T)]\\]\n\n\n\n\n\nthis is not the fast road from computer science experiment to impact, but may be the most rewarding\n\n\n\n\nwhy work on it? holy grail: know what to do"
  },
  {
    "objectID": "talks/250127-dagstuhl/index.html#what-is-not-prediction-under-intervention",
    "href": "talks/250127-dagstuhl/index.html#what-is-not-prediction-under-intervention",
    "title": "my priorities for AI in health",
    "section": "What is not prediction under intervention",
    "text": "What is not prediction under intervention\nUsing QRISK to decide on blood pressure medication (which it’s not intended for)"
  },
  {
    "objectID": "talks/250127-dagstuhl/index.html#is-qrisk-bad",
    "href": "talks/250127-dagstuhl/index.html#is-qrisk-bad",
    "title": "my priorities for AI in health",
    "section": "Is QRISK bad?",
    "text": "Is QRISK bad?\n\nis it inaccurate? no, it informs of the risk of an event given that the patient has blood pressure medication (post-decision model)\nthis is not the same as the risk if we were to give blood pressure medication or not\nthese are only the same when all factors going into the decision to given the blood pressure medication are accounted for (confounders, causal inference assumptions)"
  },
  {
    "objectID": "talks/250127-dagstuhl/index.html#what-is-qrisk",
    "href": "talks/250127-dagstuhl/index.html#what-is-qrisk",
    "title": "my priorities for AI in health",
    "section": "What is QRISK?",
    "text": "What is QRISK?\n\nintended for deciding on statin treatment, excludes patients who have statins ‘on baseline’\nis trained on patients of whom some recieced statins, reducing their risk of cardiovascular events\npredicts risk of cardiovascular events under current standard of care\n‘a treatment-naive model’"
  },
  {
    "objectID": "talks/250127-dagstuhl/index.html#counseling-with-and-without-prediction-under-intervention",
    "href": "talks/250127-dagstuhl/index.html#counseling-with-and-without-prediction-under-intervention",
    "title": "my priorities for AI in health",
    "section": "Counseling with and without prediction under intervention",
    "text": "Counseling with and without prediction under intervention\nImagine this dialogue between a patient who has just been diagnosed with cancer and their oncologist First, we’ll see a conversation informed by\n\nRCT data\n\naverage outcomes (or contrast) between treatment \\(A\\) and \\(B\\)\n\nnon-causal prediction models:\n\npredict outcome given features \\(X\\), ignoring effects of potential treatments (treatment-naive / average treatment policy)\npredict outcome given features \\(X\\) and treatment \\(T\\), ignoring confounding by \\(Z\\) (post-decision models)"
  },
  {
    "objectID": "talks/250127-dagstuhl/index.html#now-a-conversation-with-prediction-under-intervention-models",
    "href": "talks/250127-dagstuhl/index.html#now-a-conversation-with-prediction-under-intervention-models",
    "title": "my priorities for AI in health",
    "section": "Now a conversation with prediction-under-intervention models",
    "text": "Now a conversation with prediction-under-intervention models\n\n\n\nOncologist: Your work-up is done, we now know your cancer type and stage\n\n\n\n\n\n\nPatient: What is my prognosis?\n\n\n\n\n\n\n\nOncologist (prediction under intervention): That depends on the treatment we choose; patients like you would on average live … years on treatment A, versus … years on treatment B.\n\n\n\n\n\n\n\n\nPatient: Thank you for this information. I will discuss this with my family and friends to decide what we think is best for me."
  },
  {
    "objectID": "talks/250127-dagstuhl/index.html#prediction-under-intervention-why-is-it-hard",
    "href": "talks/250127-dagstuhl/index.html#prediction-under-intervention-why-is-it-hard",
    "title": "my priorities for AI in health",
    "section": "Prediction under intervention, why is it hard:",
    "text": "Prediction under intervention, why is it hard:\n\nanswer a causal question, often cannot do (big enough) experiment (RCT), need assumptions otherwise (confounding, positivity)\nassumptions undermine trust; is it rigorous?\nthis holds for development and evaluations, cannot simply evaluate on held-out data\nas with any AI deployment: a trial is best level of evidence\nother forms of off policy evaluation possible (especially attractive when you have RCTs that randomized the treatments) (Uehara, Shi, and Kallus 2022)"
  },
  {
    "objectID": "talks/250127-dagstuhl/index.html#opportunities-1",
    "href": "talks/250127-dagstuhl/index.html#opportunities-1",
    "title": "my priorities for AI in health",
    "section": "opportunities:",
    "text": "opportunities:\n\nkey pieces of puzzle for personalized treatment\nboom in causal inference interest, applications can improve"
  },
  {
    "objectID": "talks/250127-dagstuhl/index.html#references",
    "href": "talks/250127-dagstuhl/index.html#references",
    "title": "my priorities for AI in health",
    "section": "References",
    "text": "References\n\n\n\n\nJoshi, Shalmali, Iñigo Urteaga, Wouter A C van Amsterdam, George Hripcsak, Pierre Elias, Benjamin Recht, Noémie Elhadad, et al. 2025. “AI as an Intervention: Improving Clinical Outcomes Relies on a Causal Approach to AI Development and Validation.” Journal of the American Medical Informatics Association, January, ocae301. https://doi.org/10.1093/jamia/ocae301.\n\n\nUehara, Masatoshi, Chengchun Shi, and Nathan Kallus. 2022. “A Review of Off-Policy Evaluation in Reinforcement Learning.” arXiv. https://doi.org/10.48550/arXiv.2212.06355.\n\n\nvan Amsterdam, W. A. C., Nan van Geloven, Jesse H. Krijthe, Rajesh Ranganath, and Giovanni Ciná. 2025. “When Accurate Prediction Models Yield Harmful Self-Fulfilling Prophecies.” Patterns. https://arxiv.org/abs/2312.01210."
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#todays-readings",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#todays-readings",
    "title": "Pearl Causal Hierarchy",
    "section": "Today’s readings:",
    "text": "Today’s readings:\n\nBareinboim’s paper / book chapter: Bareinboim et al. (2022)\nBook of why chapter 1: Pearl and Mackenzie (2018)\nPearl’s note on hierarchy: Pearl (n.d.)"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#the-ladder-is-a-hierarchy-of-questions",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#the-ladder-is-a-hierarchy-of-questions",
    "title": "Pearl Causal Hierarchy",
    "section": "The ladder is a hierarchy of questions",
    "text": "The ladder is a hierarchy of questions\n\ntable 1"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#notation",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#notation",
    "title": "Pearl Causal Hierarchy",
    "section": "Notation",
    "text": "Notation\n\n\\(X\\): treatment (binary, 0,1)\n\\(Y\\): outcome (binary)\n\\(Z\\): covariate (age, sex)\n\\(p(Y|Z)\\): conditional distribution of \\(Y\\) given \\(Z\\) (e.g. regression, ‘prediction’)\n\\(p(Y_x)\\): the causal effect of \\(X\\) on \\(Y\\), e.g.:\n\n\\(p(Y_{X=1}=1)\\): the probability that \\(Y\\) would take value 1 when we would set \\(X\\) to 1 by intervention\n\\(P(Y_1) - P(Y_0) = \\text{ATE}\\) (average treatment effect)"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#layer-1-association",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#layer-1-association",
    "title": "Pearl Causal Hierarchy",
    "section": "Layer 1: association",
    "text": "Layer 1: association\n\nWhat is the relationship between two or more variables?\nrequired:\n\ndata (observational / non-experimental): \\(p(X,Y,Z)\\)\n\nquestions:\n\nwhat is the expected survival for men, and for women? \\(p(Y|Z=1)\\), \\(p(Y|Z=0)\\)"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#layer-2-intervention",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#layer-2-intervention",
    "title": "Pearl Causal Hierarchy",
    "section": "Layer 2: intervention",
    "text": "Layer 2: intervention\n\nWhat happens if we intervene on a variable?\nby how much would survival change if we would treat every patient with a certain drug?\n\nthis can be made subgroup specific (the conditional average treatment effect: CATE), e.g. covariate \\(Z\\): \\(p(Y_{X=1}|Z) - p(Y_{X=0}|Z)\\)\nwhen covariate \\(Z\\) is continuous, every patient has a different CATE, but conceptually this is still the CATE (average over population with same / similar value of \\(Z\\)), not individual treatment effect\n\n\\(p(Y_{X=1}=1|Z=z)\\): the conditional probability that \\(Y\\) would take value 1 when we would set \\(X\\) to 1 by intervention, given that \\(Z=z\\)\n\naka ‘prediction under (hypothertical) intervention’\naka ‘potential outcome prediction’\naka ‘counterfactual prediction’"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#layer-2-intervention-what-is-required",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#layer-2-intervention-what-is-required",
    "title": "Pearl Causal Hierarchy",
    "section": "Layer 2: intervention, what is required?",
    "text": "Layer 2: intervention, what is required?\n\ndata where \\(X\\) is controlled by experimentation (randomized controlled trial)\nobservational data + sufficient assumptions, typically:\n\n\nthe directed acyclic graph (DAG) for the variables and no unobserved confounders\n\n\n\n\n\nDAG 1"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#layer-3-counterfactuals",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#layer-3-counterfactuals",
    "title": "Pearl Causal Hierarchy",
    "section": "Layer 3: counterfactuals",
    "text": "Layer 3: counterfactuals\n\nWhat would have happened if we had done something else?\nquestions:\n\ngiven that the ICU patient got vancomycin and developed acute kidney injury, would she have developed AKI if she had not received vancomycin?\n\\(P(Y_{X=0}=1|Y=1,X=1)\\)\n\ncounterfactuals have an element of:\n\nsomething occured in the world (a fact)\nwhat if we went back to the world and changed a thing, what would have occured then? (a counterfact)\n\nrequired:\n\nknowledge of functional relationships"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#the-hierarchy-what-are-the-worlds",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#the-hierarchy-what-are-the-worlds",
    "title": "Pearl Causal Hierarchy",
    "section": "The hierarchy, what are the worlds?",
    "text": "The hierarchy, what are the worlds?"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#layer-2-directed-acyclic-graph-dag",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#layer-2-directed-acyclic-graph-dag",
    "title": "Pearl Causal Hierarchy",
    "section": "Layer 2: directed acyclic graph (DAG)",
    "text": "Layer 2: directed acyclic graph (DAG)\n\nassociation: the world as it is\nintervention: the world as we could be under an intervention (as it would be / is in an experiment)\ncounterfactuals: the world as it was, and how it might have been if something had been different"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#the-hierarchy-what-are-the-worlds-1",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#the-hierarchy-what-are-the-worlds-1",
    "title": "Pearl Causal Hierarchy",
    "section": "The hierarchy, what are the worlds?",
    "text": "The hierarchy, what are the worlds?\n\none real world\none hypothetical world (or real in experiment)\none real world and a hypothetical world"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#what-are-the-layers-useful-for",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#what-are-the-layers-useful-for",
    "title": "Pearl Causal Hierarchy",
    "section": "What are the layers useful for?",
    "text": "What are the layers useful for?\n\nassociation: description, prediction (know what to expect when observing the world with hands on our backs)\nintervention: policy making, decision making (know what to expect when we change the world)\ncounterfactuals: explanation, understanding:\n\n\ndrug side effects\ndigital twins: a digital representation of a physical object or system: typically assumes counterfactual level knowledge, e.g. Sel et al. (2024)\nquestions of fairness"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#what-is-a-scm",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#what-is-a-scm",
    "title": "Pearl Causal Hierarchy",
    "section": "What is a SCM?",
    "text": "What is a SCM?\n\ndefinition of SCM\n\\(U\\) is a set of background variables, also called exogenous variables, that are determined by factors outside the model;\n\\(V\\) is a set \\(\\{V_1,V_2,...,V_n\\}\\) of variables, called endogenous, that are determined by other variables in the model - that is, variables in \\(U\\cup V\\);\n\\(F\\) is a set of functions \\(\\{ f_1, f_2,..., f_n\\}\\) such that each fiis a mapping from (the respective domains of) \\(U_i \\cup Pa_i \\to V_i\\), where \\(U_i \\subset U\\), \\(Pa_i \\subset V - Vi\\), and the entire set \\(F\\) forms a mapping from \\(U\\) to \\(V\\). That is, for \\(i = 1,...,n\\), each \\(f_i \\in F\\) is such that\n\n\n\\[v_i \\leftarrow f_i(pa_i, u_i)\\]\n\ni.e., it assigns a value to \\(V_i\\) that depends on (the values of) a select set of variables in \\(U \\cup V\\); and\n\\(P(U)\\) is a probability function defined over the domain of \\(U\\)."
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#how-are-scms-and-dags-related",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#how-are-scms-and-dags-related",
    "title": "Pearl Causal Hierarchy",
    "section": "How are SCMs and DAGs related?",
    "text": "How are SCMs and DAGs related?\nA recursive SCM implies a DAG, by following the order of arguments in the set of functions \\(F\\). E.G.:\n\n\n\n\n\n\n\\[\nF = \\begin{cases}\n      Z \\leftarrow f(U_Z)\n\\end{cases}\n\\]"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#how-are-scms-and-dags-related-1",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#how-are-scms-and-dags-related-1",
    "title": "Pearl Causal Hierarchy",
    "section": "How are SCMs and DAGs related?",
    "text": "How are SCMs and DAGs related?\nA recursive SCM implies a DAG, by following the order of arguments in the set of functions \\(F\\). E.G.:\n\n\n\n\n\n\n\\[\nF = \\begin{cases}\n      Z \\leftarrow f(U_Z) \\\\\n      X \\leftarrow f(Z, U_X)\n\\end{cases}\n\\]"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#how-are-scms-and-dags-related-2",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#how-are-scms-and-dags-related-2",
    "title": "Pearl Causal Hierarchy",
    "section": "How are SCMs and DAGs related?",
    "text": "How are SCMs and DAGs related?\nA recursive SCM implies a DAG, by following the order of arguments in the set of functions \\(F\\). E.G.:\n\n\n\n\n\n\n\\[\nF = \\begin{cases}\n      Z \\leftarrow f(U_Z) \\\\\n      X \\leftarrow f(Z, U_X) \\\\\n      Y \\leftarrow f(X, Z, U_Y)\n\\end{cases}\n\\]"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#how-are-scms-and-dags-related-3",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#how-are-scms-and-dags-related-3",
    "title": "Pearl Causal Hierarchy",
    "section": "How are SCMs and DAGs related?",
    "text": "How are SCMs and DAGs related?\n\nA (recursive) SCM implies a DAG,\nbut has strictly more information as not only the functional arguments are known,\nbut also the functions themselves"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#intervening-in-a-scm-a-submodel",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#intervening-in-a-scm-a-submodel",
    "title": "Pearl Causal Hierarchy",
    "section": "Intervening in a SCM: a submodel",
    "text": "Intervening in a SCM: a submodel\nA recursive SCM implies a DAG, by following the order of arguments in the set of functions \\(F\\). E.G.:\n\n\n\n\n\n\n\\[\nF = \\begin{cases}\n      Z \\leftarrow f(U_Z) \\\\\n      X \\leftarrow X' \\\\\n      Y \\leftarrow f(X, Z, U_Y)\n\\end{cases}\n\\]\n\n\n\n\nWe can compute the effect of an action by replacing one \\(f\\) with a constant, e.g. \\(X \\leftarrow X'\\), keep everything else the same, and evaluate the outcomes"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#intermezzo-critique-on-the-hierarchy",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#intermezzo-critique-on-the-hierarchy",
    "title": "Pearl Causal Hierarchy",
    "section": "Intermezzo: critique on the hierarchy",
    "text": "Intermezzo: critique on the hierarchy\n\nThe Pearl Causal Hierarchy is a hiearchy of questions\nSome (rightly) argue that the ‘higher’ we go, the more prior assumptions are needed, and the less we rely on experiments\nIn a sense of empirical science, the hierarchy is upside down"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#theorem-1",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#theorem-1",
    "title": "Pearl Causal Hierarchy",
    "section": "Theorem 1",
    "text": "Theorem 1\n\nTheorem 1"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#example-7a",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#example-7a",
    "title": "Pearl Causal Hierarchy",
    "section": "example 7a",
    "text": "example 7a\n\\(X\\): treatment, \\(Y\\): outcome, \\(U_1, U_2\\): exogenous noise variables; \\(p(U_1=1)=p(U_2=1)=0.5\\)\n\\[\nF = \\begin{cases}\n      X \\leftarrow U_1 \\\\\n      Y \\leftarrow U_2\n\\end{cases}\n\\]\n\ntreatment: coin flip\nsurvival: coin flip (not affected by \\(X\\))\n\n\n\\[\nF' = \\begin{cases}\n      X \\leftarrow 1_{U_1=U_2} \\\\\n      Y \\leftarrow U_1 + 1_{X=1,U+1=0,U_2=1}\n\\end{cases}\n\\]\n\nsurvival: affected by \\(X\\)"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#example-7a-1",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#example-7a-1",
    "title": "Pearl Causal Hierarchy",
    "section": "example 7a",
    "text": "example 7a\n\\[\nF = \\begin{cases}\n      X \\leftarrow U_1 \\\\\n      Y \\leftarrow U_2\n\\end{cases}\n\\]\n\\[\nF' = \\begin{cases}\n      X \\leftarrow 1_{U_1=U_2} \\\\\n      Y \\leftarrow U_1 + 1_{X=1,U+1=0,U_2=1}\n\\end{cases}\n\\]\n\nboth models: same level 1 (observational) distribution \\(p(X,Y)\\)\ndifferent level 2: \\(Y_{X}\\)\ncannot tell models apart from observatoinal data alone (i.e. causal effect not identified)"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#example-7b",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#example-7b",
    "title": "Pearl Causal Hierarchy",
    "section": "example 7b",
    "text": "example 7b\n\\(X\\): treatment, \\(Y\\): outcome, \\(U_1, U_2\\): exogenous noise variables; \\(p(U_1=1)=p(U_2=1)=0.5\\)\n\\[\nF = \\begin{cases}\n      X \\leftarrow U_1 \\\\\n      Y \\leftarrow U_2\n\\end{cases}\n\\]\n\n\\[\nF' = \\begin{cases}\n      X \\leftarrow U_1 \\\\\n      Y \\leftarrow X U_2 + (1-X)(1-U_2)\n\\end{cases}\n\\]\n\n‘the effect of treatment is determined by the coinflip’\n\n\n\n\nboth models: same level 2 (interventional) distributions\ndifferent level 3: \\(Y_{X=0}=1|X=1,Y=0)\\)\ncannot tell models apart from level 2 data alone"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#potential-outcomes-framwork",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#potential-outcomes-framwork",
    "title": "Pearl Causal Hierarchy",
    "section": "Potential outcomes framwork:",
    "text": "Potential outcomes framwork:\nImage two possible futures for a patient"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#potential-outcomes-vs-scms",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#potential-outcomes-vs-scms",
    "title": "Pearl Causal Hierarchy",
    "section": "Potential outcomes vs SCMs",
    "text": "Potential outcomes vs SCMs\n\nwhy I like the term potential outcomes: it has a clear sense of futures\ncounterfactual in the PO framework: has a clear definition and interpretation\nwhat I don’t like: using the term counterfactual outcomes when the potential outcomes are meant, and neither has occured yet\n\ne.g. counterfactual prediction\n\nin the SCM frawmwork, counterfactuals are closer to the word:\n\na fact has been observed (the real world)\na counter fact has been asked\nthis actually conditions on the observed factual data (often not the case in PO framework)\n\n“given that the ICU patient got vancomycin and developed acute kidney injury, would she have developed AKI if she had not received vancomycin?”"
  },
  {
    "objectID": "talks/241104-pearl-causal-hierarchy/index.html#references",
    "href": "talks/241104-pearl-causal-hierarchy/index.html#references",
    "title": "Pearl Causal Hierarchy",
    "section": "References",
    "text": "References\n\n\n\n\nBareinboim, Elias, Juan Correa, Duligur Ibeling, and Thomas Icard. 2022. “On Pearl’s Hierarchy and the Foundations of Causal Inference (1st Edition).” In Probabilistic and Causal Inference: The Works of Judea Pearl, edited by Hector Geffner, Rita Dechter, and Joseph Halpern, 507–56. ACM Books.\n\n\nPearl, Judea. n.d. “The Three Layer Causal Hierarchy.” Accessed November 4, 2024.\n\n\nPearl, Judea, and Dana Mackenzie. 2018. The Book of Why: The New Science of Cause and Effect. 1st edition. New York: Basic Books.\n\n\nSel, Kaan, Deen Osman, Fatemeh Zare, Sina Masoumi Shahrbabak, Laura Brattain, Jin-Oh Hahn, Omer T. Inan, et al. 2024. “Building Digital Twins for Cardiovascular Health: From Principles to Clinical Impact.” Journal of the American Heart Association 13 (19): e031981. https://doi.org/10.1161/JAHA.123.031981."
  },
  {
    "objectID": "talks/240922-causalai-4cities/index.html#causal-inference-groups",
    "href": "talks/240922-causalai-4cities/index.html#causal-inference-groups",
    "title": "Causal Inference for AI meetup",
    "section": "Causal Inference groups",
    "text": "Causal Inference groups\n\n\n\n\n\n\n\n\n\nCausal Inference in AI mailing-list\n\n\n\n\n\n\n\nUtrecht - Special Interest Group Causal Data Science"
  },
  {
    "objectID": "talks/240922-causalai-4cities/index.html#program",
    "href": "talks/240922-causalai-4cities/index.html#program",
    "title": "Causal Inference for AI meetup",
    "section": "Program",
    "text": "Program\n\n30 minutes + 10 minutes Q&A\nborrel afterwards\n\n\n\n\n\n\n\n\n\n\nCausal Inference in AI mailing-list\n\n\n\n\n\n\n\nUtrecht - Special Interest Group Causal Data Science"
  },
  {
    "objectID": "talks/240515-aibia-ai-medical-imaging-decision-support/index.html#outline",
    "href": "talks/240515-aibia-ai-medical-imaging-decision-support/index.html#outline",
    "title": "Decision support based on AI in medical imaging",
    "section": "Outline",
    "text": "Outline\n\ndifferent uses of AI in medical imaging\nusing AI for treatment effect estimation\nwarning: harmful self-fulfilling prophecies"
  },
  {
    "objectID": "talks/240515-aibia-ai-medical-imaging-decision-support/index.html#uses-of-ai-in-medical-imaging",
    "href": "talks/240515-aibia-ai-medical-imaging-decision-support/index.html#uses-of-ai-in-medical-imaging",
    "title": "Decision support based on AI in medical imaging",
    "section": "Uses of AI in medical imaging",
    "text": "Uses of AI in medical imaging\n\nAcquisition (\\(S \\to X\\)) \ndetection / segmentation (\\(X \\to X\\)) \ninference / diagnosis (\\(X \\to D\\), both at prediction time) \nprognosis (\\(X \\to Y\\), \\(Y\\) in the future) \ntreatment effect (\\(X\\) determines effect of a treatment)"
  },
  {
    "objectID": "talks/240515-aibia-ai-medical-imaging-decision-support/index.html#ai-treatment-effect",
    "href": "talks/240515-aibia-ai-medical-imaging-decision-support/index.html#ai-treatment-effect",
    "title": "Decision support based on AI in medical imaging",
    "section": "Why would you estimate treatment effects based on images?",
    "text": "Why would you estimate treatment effects based on images?\n\ntreatments have different effects on patients based on their (disease) characteristics\nfor example, whether tamoxifen increases survival for breast cancer patients depends on whether their tumor is hormone sensitive\nsome characteristics may be well captured in medical imaging:\n\nT-cell distributions around tumors related to effect of immunotherapy in cancer"
  },
  {
    "objectID": "talks/240515-aibia-ai-medical-imaging-decision-support/index.html#how-to-estimate-treatment-effects-based-on-images",
    "href": "talks/240515-aibia-ai-medical-imaging-decision-support/index.html#how-to-estimate-treatment-effects-based-on-images",
    "title": "Decision support based on AI in medical imaging",
    "section": "How to estimate treatment effects based on images?",
    "text": "How to estimate treatment effects based on images?\nIn principle the same as estimating a subgroup treatment effect (e.g. male vs female)\n\nConduct a randomized controlled trial where the treatments of interest are randomly allocated\nCollect (imaging) data at randomization timepoint\nUse a statistical learning technique like TARnet (Shalit, Johansson, and Sontag 2017) to estimate outcomes conditional on image and treatment\nconditional treatment effect \\(= f(X,T=1) - f(X,T=0)\\)\n\n\n\n\n\nWhat if you cannot do a (big enough) RCT?\n\n\nEmulate / approximate the ideal trial in observational data you do have, using causal inference techniques\n(which rely on untestable assumptions)"
  },
  {
    "objectID": "talks/240515-aibia-ai-medical-imaging-decision-support/index.html#the-in-between-predicting-prognosis-and-using-the-predictions-for-decision-support",
    "href": "talks/240515-aibia-ai-medical-imaging-decision-support/index.html#the-in-between-predicting-prognosis-and-using-the-predictions-for-decision-support",
    "title": "Decision support based on AI in medical imaging",
    "section": "The in-between: predicting prognosis and using the predictions for decision support",
    "text": "The in-between: predicting prognosis and using the predictions for decision support\nFor example:\n\ngive chemotherapy to cancer patients with high predicted risk of recurrence\ngive statins to patients with a high risk of a heart attack\n\n\n\n\n\nTRIPOD+AI on prediction models (Collins et al. 2024)\n\n\n“Their primary use is to support clinical decision making, such as … initiate treatment or lifestyle changes.”"
  },
  {
    "objectID": "talks/240515-aibia-ai-medical-imaging-decision-support/index.html#when-building-a-prediction-model-always-discuss",
    "href": "talks/240515-aibia-ai-medical-imaging-decision-support/index.html#when-building-a-prediction-model-always-discuss",
    "title": "Decision support based on AI in medical imaging",
    "section": "When building a prediction model, always discuss",
    "text": "When building a prediction model, always discuss\n\nwhat treatments are assumed in the predicted risk?\nwhat is the effect of using the model on the treatment policy?\nwhat is the effect on patient outcomes?\n\n\n\n\n\nFrom algorithms to action: improving patient care requires causality (W. A. C. van Amsterdam et al. 2024b)\n\n\nWhen accurate prediction models yield harmful sel-fulfilling prophecies (W. A. C. van Amsterdam et al. 2024a)"
  },
  {
    "objectID": "talks/240515-aibia-ai-medical-imaging-decision-support/index.html#references",
    "href": "talks/240515-aibia-ai-medical-imaging-decision-support/index.html#references",
    "title": "Decision support based on AI in medical imaging",
    "section": "References",
    "text": "References\n\n\n\n\nAmsterdam, Wouter A. C. van, Nan van Geloven, Jesse H. Krijthe, Rajesh Ranganath, and Giovanni Ciná. 2024a. “When Accurate Prediction Models Yield Harmful Self-Fulfilling Prophecies.” arXiv. https://doi.org/10.48550/arXiv.2312.01210.\n\n\nAmsterdam, Wouter A. C. van, Pim A. de Jong, Joost J. C. Verhoeff, Tim Leiner, and Rajesh Ranganath. 2024b. “From Algorithms to Action: Improving Patient Care Requires Causality.” BMC Medical Informatics and Decision Making 24 (1). https://doi.org/10.1186/s12911-024-02513-3.\n\n\nCollins, Gary S., Karel G. M. Moons, Paula Dhiman, Richard D. Riley, Andrew L. Beam, Ben Van Calster, Marzyeh Ghassemi, et al. 2024. “TRIPOD+AI Statement: Updated Guidance for Reporting Clinical Prediction Models That Use Regression or Machine Learning Methods.” BMJ 385 (April): e078378. https://doi.org/10.1136/bmj-2023-078378.\n\n\nShalit, Uri, Fredrik D. Johansson, and David Sontag. 2017. “Estimating Individual Treatment Effect: Generalization Bounds and Algorithms.” arXiv:1606.03976 [Cs, Stat], May. http://arxiv.org/abs/1606.03976."
  },
  {
    "objectID": "posts/210720-good_predictions_bad_decisions.html",
    "href": "posts/210720-good_predictions_bad_decisions.html",
    "title": "When good predictions lead to bad decisions",
    "section": "",
    "text": "A common premise in prediction research for clinical outcomes is that better predictions lead to better (informed) decisions. This causal statement, that the intervention of introducing a new prediction rule leads to better decisions and thus better outcomes, is generally not substantiated with sufficient causal arguments. We now present an example where naively introducing a validated new prediction rule can lead to worse clinical decisions.\nFor a certain cancer type there are two treatment options: treatment A and treatment B. From randomized trials, it is known that treatment A is more effective in treating the tumor than treatment B. There is no known variation of treatment effect among subgroups defined by clinical patient characteristics. However, not all patients respond well to treatment. Treatment A is a longer and more intensive treatment regimen than treatment B and leads to more side-effects. The consensus is that it is unethical to give treatment A to patients with a lower than 10% chance of surviving one year, due to the higher risk of side-effects and the lengthy treatment regimen associated with treatment A. In current clinical practice, the probability of 1-year survival is estimated using clinical characteristics. A new research group tries to improve the 1-year survival predictions using a new biomarker. The research endeavor is a success as it turns out that predicting survival with the clinical characteristics and the new biomarker is significantly more accurate than using only the clinical characteristics. A high value for the biomarker is associated with worse overall survival. Having conducted a predictive study, it is not discovered that the treatment effect of treatment A versus B is actually more in favor of treatment A for patients with higher levels of the biomarker. If the new prediction rule would be implemented naively with the same 10% cut-off for 1-year overall survival, this would lead to worse treatment decisions than without using the new prediction model. Some patients with high biomarker values will fall under the 10% cut-off based on the new biomarker, while without the biomarker they would have had a higher than 10% survival probability. This erroneously leads to not recommending treatment A, even though these patients have a high benefit of treatment A.\nNote that this is not an unreasonable example for cancer, as aggressive / fast-growing cancers tend to respond better to treatments like chemotherapy and radiotherapy. One example is non-seminoma versus seminoma testicular cancer."
  },
  {
    "objectID": "posts/210720-good_predictions_bad_decisions.html#defining-the-policies",
    "href": "posts/210720-good_predictions_bad_decisions.html#defining-the-policies",
    "title": "When good predictions lead to bad decisions",
    "section": "Defining the policies",
    "text": "Defining the policies\nThe current clinical policy is:\n\\[\\pi_0(x) = \\mathbf{I}_{E[y|x] &gt; 0}\\]\nSo we should give treatment \\(t=1\\) whenever the expected outcome exceeds the reference cut-off. Let the true data generating mechanism be as following:\n\\[y = \\beta z t + x - z\\]\nAs \\(y\\) is a deterministic function of \\(t,x,z\\), we drop the expectation symbol in the following discussion. Let \\(x,z \\sim \\mathbf{U}(-1,1)\\) be independent variables following a uniform distribution between -1 and 1. We can new express the baseline policy as \\[\\pi_0(x) = \\mathbf{I}_{y|x &gt; 0} = \\mathbf{I}_{E_{z}[y|x,z]&gt;0} \\iff \\mathbf{I}_{x &gt; 0}\\]\nA naive implementation of the new prediction rule incorporating \\(z\\) would lead to the policy \\(\\pi_z(x,z) = \\mathbf{I}_{y|x,z &gt; 0}\\). Plugging in the data generating mechanism we can identify\n\\[\\begin{aligned}\n  y|x,z &= E_{t \\sim \\pi_0(x)}[y|t,x,z] \\\\\n    &= E_{t \\sim \\pi_0(x)}[\\beta z t + x - z] \\\\\n    &= \\beta z E_{t \\sim \\pi_0(x)} [t] + x - z \\\\\n    &= \\beta z E_x [\\mathbf{I}_{x &gt; 0}] + x - z \\\\\n    &= 0.5 \\beta z  + x - z \\\\\n    &= x - (1 - 0.5 \\beta)z\\end{aligned}\\]\nThus \\(\\pi_z(x,z) = \\mathbf{I}_{x + (0.5 \\beta - 1)z &gt; 0}\\).\nFrom the data generating mechanism it is clear that the conditional average treatment effect reduces to\n\\[\\begin{aligned}\n  \\text{CATE(x,z)} &= E[y|\\text{do}(t=1),x,z] - E[y|\\text{do}(t=0),x,z] \\\\\n                   &= \\beta z - 0\\end{aligned}\\]\nThe policy that maximizes the outcome \\(y\\) is \\(\\pi_{\\text{max}(y)}(z) = \\mathbf{I}_{z &gt; 0}\\) as \\(\\text{do}(t=1)\\) leads to better outcomes if and only if \\(z&gt;0\\). To conform with the ethical consensus that the intensive treatment is justified when \\(y|\\text{do}(t),x,z&gt;0\\), we set\n\\[\\begin{aligned}\n    \\pi^*(x,z) &= \\mathbf{I}_{y|\\text{do}(t=1),x,z &gt; 0} \\\\\n           &= \\mathbf{I}_{\\beta z * 1 + x - z &gt; 0} \\\\\n           &= \\mathbf{I}_{x + (\\beta - 1) z &gt; 0}\\end{aligned}\\]"
  },
  {
    "objectID": "posts/210720-good_predictions_bad_decisions.html#expected-utility-of-different-policies",
    "href": "posts/210720-good_predictions_bad_decisions.html#expected-utility-of-different-policies",
    "title": "When good predictions lead to bad decisions",
    "section": "Expected utility of different policies",
    "text": "Expected utility of different policies\nWe can now calculate the expected utility of the different policies \\(\\pi \\in \\{\\pi_0,\\pi_z,\\pi_{\\text{max}(y)},\\pi^*\\}\\) as the expected outcome, \\(U(\\pi) = E_{x,z}E_{t\\sim \\pi(x,z)}y|t,x,z = E_{x,z}\\beta z \\pi(x,z) + x - z\\). The calculation of these expected utilities depends on the treatment effect, which will we assume to be \\(\\beta = 1.5\\). We will use the marginal indepence of \\(x\\) and \\(z\\) to equate \\(E_{x,z}[.] = E_z E_x [.]\\).\n\\[\\begin{aligned}\n    U(\\pi_0) &= E_z E_x [\\beta z \\mathbf{I}_{x &gt; 0} + x - z] \\\\\n         &= \\beta E_z z E_x \\mathbf{I}_{x&gt;0} \\\\\n         &= \\beta E_z z 0.5 \\\\\n         &= 0\\end{aligned}\\]\nWe have \\(\\pi_z(x,z) = \\mathbf{I}_{x - (1 - 0.5 \\beta)z &gt; 0} = \\mathbf{I}_{x &gt; 0.25z}\\)\n\\[\\begin{aligned}\n    U(\\pi_z) &= E_z E_x [\\beta z \\mathbf{I}_{x &gt; 0.25z} + x - z] \\\\\n         &= \\beta E_z z E_x \\mathbf{I}_{x &gt; 0.25z} \\\\\n         &= \\beta E_z z \\text{Pr}(x &gt; 0.25z) \\\\\n         &=^1 \\frac{\\beta}{2} \\int_{-1}^{1} z \\text{Pr}(x &gt; 0.25z) dz\\\\\n         &=^2 \\frac{\\beta}{2} \\int_{-1}^{1} z (1 - \\frac{0.25z+1}{2}) dz\\\\\n         &= \\frac{\\beta}{4} \\int_{-1}^{1} z (1 - 0.25z)dz \\\\\n         &= \\frac{\\beta}{4} \\left[ \\frac{1}{2} z^2 - \\frac{0.25}{3}z^3 + C \\right]_{-1}^1 \\\\\n         &= \\frac{\\beta}{4} \\left( ( \\frac{1}{2} - \\frac{0.25}{3}) - ( \\frac{1}{2} + \\frac{0.25}{3}) \\right) \\\\\n         &= - \\frac{\\beta}{2} \\frac{0.25}{3} \\\\\n         &= - 0.075\\end{aligned}\\]\nWhere in \\(^1\\) we used the \\(U(-1,1)\\) distribution of \\(z\\) and in \\(^2\\) we used the probability density function of \\(x\\) and the fact that \\(-1 &lt; 0.25z &lt; 1\\). This demonstrates that the policy following the (accurate!) prediction model \\(y|x,z\\) leads to worse clinical outcomes than the previous situation that relied on \\(x\\) only.\nThe reader may verify that \\[\\begin{aligned}\n    U(\\pi_{\\text{max}(y)}) &= 0.375 \\\\\n    U(\\pi^*) &= 0.125\\end{aligned}\\]"
  },
  {
    "objectID": "posts/240607-jama-causal-language/index.html",
    "href": "posts/240607-jama-causal-language/index.html",
    "title": "Is the JAMA opening up their language for causal effects?",
    "section": "",
    "text": "Randomized controlled trials (RCTs) measure the causal effect of interventions, but results from observational studies should be interpreted as mere associations, right? In a great piece in the JAMA, Issa Dehabreh and Kirsten Bibbins-Domingo describe a framework with a more balanced view.\nBlack-and-white thinking about causal effects dictated medical research for a long time. But then, some not-so-well conducted RCTs (e.g. no blinding of outcome assessment, selective loss to follow-up, …) do not provide valid estimates of treatment effects. How can we distinguish the good ‘causal’ RCTs from the bad ones if the criterion for causality is whether a study is an RCT or not?\nIn the past decades the field of causal inference produced several principled definitions of causal effects and established requirements for a study to yield valid causal estimates (e.g. Pearl and Mackenzie 2018; Pearl 2009; Miguel A. Hernán and Robins 2020). According to these approaches, RCTs are clearly preferable for treatment effect estimation as in RCTs the requirements for estimating causal effects can be controlled experimentally. Unfortunately, some relevant questions are very hard to answer using RCTs because of logistical or ethical limitations. At the same time, the definitions of causal effects from causal inference imply that causal effects can be estimated outside of RCTs with observational data as well. Though for observational studies, causal estimates are only valid when specific assumptions are met and unfortunately these assumptions cannot be checked with the data, so caution is required. But clearly, the black-and-white RCT=causation and observational=association must be replaced with a more nuanced view.\nFor a long time, prestigious journals such as the Journal of the American Medical Association (JAMA) restricted the use of causal language (e.g. effect or efficacy) to reporting the primary results of RCTs (“Instructions for Authors  JAMA  JAMA Network” n.d.), further entrenching the black-and-white mindset and evoking criticism from causal inference researchers (e.g. Miguel A. Hernán 2018). Recently, the JAMA opened itself up for discussion on this topic with a very thoughtful publication by Issa Dehabreh and Kirsten Bibbins-Domingo (Dahabreh and Bibbins-Domingo 2024), accompanied by an editorial (Flanagin et al. 2024).\nAs a researcher in causal inference and machine learning for healthcare I think this a great step towards a more rational and balanced approach to distinghuising causal effects from assocations. This is much needed because causal effects teach us what to do, i.e. what interventions will lead to better patient outcomes. Opening up the language to better express causal research questions and analysis approaches combined with the ability to incorporate both well conducted RCTs and observational studies (mentioning the assumptions required for their estimates to have a causal interpretation) when evaluating interventions will lead to better evidence accumulation and ultimately better outcomes for patients.\n\n\n\n\n\n\n\n\n\nReferences\n\nDahabreh, Issa J., and Kirsten Bibbins-Domingo. 2024. “Causal Inference About the Effects of Interventions From Observational Studies in Medical Journals.” JAMA 331 (21): 1845–53. https://doi.org/10.1001/jama.2024.7741.\n\n\nFlanagin, Annette, Roger J. Lewis, Christopher C. Muth, and Gregory Curfman. 2024. “What Does the Proposed Causal Inference Framework for Observational Studies Mean for JAMA and the JAMA Network Journals?” JAMA 331 (21): 1812–13. https://doi.org/10.1001/jama.2024.8107.\n\n\nHernán, Miguel A. 2018. “The C-Word: Scientific Euphemisms Do Not Improve Causal Inference From Observational Data.” American Journal of Public Health 108 (5): 616–19. https://doi.org/10.2105/AJPH.2018.304337.\n\n\nHernán, Miguel A, and James M Robins. 2020. Causal Inference: What If. Boca Raton: Champan & Hall/CRC.\n\n\n“Instructions for Authors  JAMA  JAMA Network.” n.d. https://jamanetwork.com/journals/jama/pages/instructions-for-authors. Accessed August 3, 2021.\n\n\nPearl, Judea. 2009. Causality. Cambridge University Press.\n\n\nPearl, Judea, and Dana Mackenzie. 2018. The Book of Why: The New Science of Cause and Effect. 1st edition. New York: Basic Books.\n\nCitationBibTeX citation:@online{van_amsterdam2024,\n  author = {van Amsterdam, Wouter},\n  title = {Is the {JAMA} Opening up Their Language for Causal Effects?},\n  date = {2024-06-07},\n  url = {https://vanamsterdam.github.io/posts/240607-jama-causal-language/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nAmsterdam, Wouter van. 2024. “Is the JAMA Opening up Their\nLanguage for Causal Effects?” June 7, 2024. https://vanamsterdam.github.io/posts/240607-jama-causal-language/."
  },
  {
    "objectID": "posts/210725-counterfactualvsinterventional.html",
    "href": "posts/210725-counterfactualvsinterventional.html",
    "title": "The difference between intervention and counterfactuals",
    "section": "",
    "text": "Sometimes there is confusion about the difference between counterfactual predictions and interventional predictions. According to the ladder of causation introduced by Pearl and presented in the ‘Book of Why’, interventional is rung 2 and counterfactuals are rung 3 (associations are rung 1). Models that predict the treatment effect for a new patient based on some covariates \\(X\\) require interventional models, not counterfactual. The difference between interventional and counterfactual models is relevant as counterfactual models require more assumptions, they require knowledge of the structural mechanisms. In words, the interventional question is “What is the expected outcome under treatment \\(t\\) given that we know \\(X\\)”, or “What is the expected difference in outcomes between treatment \\(t\\) and \\(t'\\) given that we know \\(X\\)”. The counterfactual question is “What would have been the outcome if we had given treatment \\(t'\\) given that we gave \\(t\\) and observed outcome \\(y\\)”."
  },
  {
    "objectID": "posts/210725-counterfactualvsinterventional.html#intro",
    "href": "posts/210725-counterfactualvsinterventional.html#intro",
    "title": "The difference between intervention and counterfactuals",
    "section": "",
    "text": "Sometimes there is confusion about the difference between counterfactual predictions and interventional predictions. According to the ladder of causation introduced by Pearl and presented in the ‘Book of Why’, interventional is rung 2 and counterfactuals are rung 3 (associations are rung 1). Models that predict the treatment effect for a new patient based on some covariates \\(X\\) require interventional models, not counterfactual. The difference between interventional and counterfactual models is relevant as counterfactual models require more assumptions, they require knowledge of the structural mechanisms. In words, the interventional question is “What is the expected outcome under treatment \\(t\\) given that we know \\(X\\)”, or “What is the expected difference in outcomes between treatment \\(t\\) and \\(t'\\) given that we know \\(X\\)”. The counterfactual question is “What would have been the outcome if we had given treatment \\(t'\\) given that we gave \\(t\\) and observed outcome \\(y\\)”."
  },
  {
    "objectID": "posts/210725-counterfactualvsinterventional.html#example",
    "href": "posts/210725-counterfactualvsinterventional.html#example",
    "title": "The difference between intervention and counterfactuals",
    "section": "Example",
    "text": "Example\nTo illustrate the difference between a counterfactual prediction and an interventional prediction (or conditional average treatment effect estimates), consider this very simple setup.\nYou have data from a randomized trial with two treatment arms \\(t \\in \\{0,1\\}\\) and an outcome \\(Y\\) on a continuous scale. Denote \\(Y_0\\) the potential outcome under intervening on treatment \\(t=0\\) and \\(Y_1\\) the potential outcome under intervening on treatment \\(t=1\\). As we are dealing with data from a randomized trial, we can easily estimate the average treatment effect as \\(E[Y_1 - Y_0] = E[Y|t=0] - E[Y|t=1]\\), assuming consistency (ignorability and overlap are satisfied due to the study design).\nA counterfactual question is: what would have been the outcome \\(Y_0\\) under treatment \\(t=1\\), given that we observed the outcome \\(y_1\\) under treamtent \\(t=1\\), so it is \\(E[Y_0|Y=y_1, t=1]\\).\nNow assume that the data come from a mixture of Gaussians such that\n\\[y|t \\sim (1 - t) \\mathcal{N}(1,0.1^2) + t \\mathcal{N}(10,2.5^2)\\]\nAnd \\(p(t=1)=0.5\\) so both arms are equally large. Treatment \\(t=1\\) leads to higher outcome but also more spread. The relevant interventional expectations are easily calculated by just calculating group means \\(E[Y_0] = E[Y|t=0] = 1\\), \\(E[Y_1] = E[Y|t=1] = 10\\).\n\nCalculating the counterfactuals\nTo see that calculating counterfactuals requires more knowledge, namely of the structural equations, we now calculate the counterfactual prediction for a patient with \\(Y=Y_1=15\\). This is a patient with a relatively large ‘residual’, the outcome is 2 standard deviations above the mean for treatment group \\(t=1\\).\nFirst we calculate the counterfactual outcome under a wrong outcome model. Researchers tried to model the outcomes using linear regression, and failed to appreciate the difference in variances between the two treatment arms (heteroscedasticity). Assuming a large sample, they will arrive at a model:\n\\[\\hat{y}_{\\text{wrong}} = 1 + t * 9 + \\mathcal{N}(0,\\sigma^2)\\]\nWhere \\(\\sigma = \\sqrt{\\frac{0.1^2 + 2.5^2}{2}} \\approx 1.77\\) (standard devation of mixture of Gaussians with (conditional) mean of 0 and standard deviations 0.1 and 2.5, with 50 / 50 mixing). Note that the estimate of the treatment effect is correct, and so are \\(E[Y_0]\\) and \\(E[Y_1]\\). If there was a binary pre-treatment covariate, the conditional average treatment effect could be estimated by repeating this exercise for both levels of the covariate. To calculate the counterfactual outcome of our patient, we first need to determine the value of their noise variable for the outcome. According to \\(\\hat{y}_{\\text{wrong}}\\), the residual for a patient with \\(Y_1=15\\) is \\(5\\), which is \\(5/\\sigma \\approx 2.82\\) standard deviations away from the expected value for \\(t=1\\). Given this residual we can now calculate the counterfactual:\n\\[\\widehat{E_{\\text{wrong}}}[Y_0|Y=15,t=1] \\approx E[Y_0] + 2.82 \\sigma =6\\]\nGiven that we know the data generating mechanism, we know that this counterfactual prediction is 50 standard deviations from the conditional mean of \\(t=0\\) in the data generating mechanism, clearly this counterfactual prediction is wrong.\nIf we did model the data correctly with a mixture of Gaussians indexed by the treatment group, we would instead say that \\(Y_1=15\\) is 2 standard deviations above the conditional mean, and we would calculate:\n\\[\\widehat{E^*}[Y_0|Y=15,t=1] = E[Y_0] + 2 * 0.1 =1.2\\]\nWhich is correct."
  },
  {
    "objectID": "posts/210725-counterfactualvsinterventional.html#conclusion",
    "href": "posts/210725-counterfactualvsinterventional.html#conclusion",
    "title": "The difference between intervention and counterfactuals",
    "section": "Conclusion",
    "text": "Conclusion\nTo calculate counterfactual predictions, you need to correctly specify the structural equations. For treatment recommendations for future patients, these are not needed, interventional estimates (conditional average treatment effect) are sufficient, and obviously the factual outcome is not observed yet so it is impossible to calculate counterfactuals (the factual is not yet known).\nPost-script: for ‘real’ patient counsellling the expected values under the treatments would generally not suffice, some measure of spread / uncertainty would be required. Ideally, one would learn the distribution of the potential outcomes."
  },
  {
    "objectID": "talks.html",
    "href": "talks.html",
    "title": "Talks",
    "section": "",
    "text": "Here is a selection of my talks.\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nSubtitle\n\n\n\n\n\n\nApr 17, 2025\n\n\nCausal Data Science in Utrecht: causality for prediction model generalization\n\n\nApplied Data Science event Utrecht University\n\n\n\n\nJan 27, 2025\n\n\nmy priorities for AI in health\n\n\nDagstuhl Seminar 2025\n\n\n\n\nNov 25, 2024\n\n\nA causal viewpoint on prediction model performance under changes in case-mix\n\n\nMethods meeting at the Julius Center, UMC Utrecht\n\n\n\n\nNov 6, 2024\n\n\nPearl Causal Hierarchy\n\n\nCausal Inference at Julius reading group\n\n\n\n\nSep 26, 2024\n\n\nAn introduction to AI for biostatisticians\n\n\nBMS-Aned seminar\n\n\n\n\nJul 8, 2024\n\n\nMedical imaging and AI for decision support\n\n\nMedical Imaging AI lab meeting\n\n\n\n\nMay 30, 2024\n\n\nUses and pitfalls with AI for decision support - harmful self-fulfilling prophecies\n\n\nWEON masterclass 2024 - AI-based prediction models in healthcare: from development to implementation\n\n\n\n\nMay 16, 2024\n\n\nCausality and prediction: developing and validating models for decision making\n\n\nCausal Data Science Special Interest Group - Utrecht\n\n\n\n\nMay 15, 2024\n\n\nDecision support based on AI in medical imaging\n\n\nAI in medical imaging (AIBIA) parallel session\n\n\n\n\nMay 7, 2024\n\n\nAn intro to causal inference and its uses in radiotherapy\n\n\nESTRO - Understanding dose-effects: Can we go beyond association - symposium\n\n\n\n\nApr 18, 2024\n\n\nAI and its (mis)uses in medical research and practice\n\n\nInfection and Immunity spring meeting\n\n\n\n\nAug 10, 2023\n\n\nThe value of observational causal inference for medical decision making\n\n\nMLHC causality pre-conference workshop\n\n\n\n\nJun 24, 2023\n\n\nMy risk model is super accurate so it will be useful for treatment decision making, right? Wrong!\n\n\nCHIL 2023 - lightning talk\n\n\n\n\nMar 1, 2023\n\n\nIndividual treatment effect estimation in the presence of unobserved confounding using proxies\n\n\nSeminar at Manchester University\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Posts",
    "section": "",
    "text": "What is stronger evidence of prediction model robustness?\n\n\n\n\n\n\nstatistics\n\n\nprediction\n\n\ncausal inference\n\n\n\n\n\n\n\n\n\nApr 25, 2025\n\n\nWouter van Amsterdam\n\n\n\n\n\n\n\n\n\n\n\n\nIs the JAMA opening up their language for causal effects?\n\n\n\n\n\n\ncausal inference\n\n\n\n\n\n\n\n\n\nJun 7, 2024\n\n\nWouter van Amsterdam\n\n\n\n\n\n\n\n\n\n\n\n\nPartial residual plots with multiply imputed data\n\n\n\n\n\n\nr\n\n\nlinear regression\n\n\ndata visualization\n\n\n\n\n\n\n\n\n\nMar 22, 2024\n\n\nWouter van Amsterdam\n\n\n\n\n\n\n\n\n\n\n\n\nThe need for speed, performing simulation studies in R, JAX and Julia\n\n\n\n\n\n\nr\n\n\njulia\n\n\njax\n\n\npython\n\n\nsimulation studies\n\n\n\n\n\n\n\n\n\nMar 8, 2024\n\n\nWouter van Amsterdam\n\n\n\n\n\n\n\n\n\n\n\n\nThe difference between intervention and counterfactuals\n\n\n\n\n\n\ncausal inference\n\n\nstatistics\n\n\n\n\n\n\n\n\n\nJul 25, 2021\n\n\nWouter van Amsterdam\n\n\n\n\n\n\n\n\n\n\n\n\nWhen good predictions lead to bad decisions\n\n\n\n\n\n\ncausal inference\n\n\npredictions\n\n\n\n\n\n\n\n\n\nJul 20, 2021\n\n\nWouter van Amsterdam\n\n\n\n\n\n\n\n\n\n\n\n\nFinding the functional form for multiple linear regression\n\n\n\n\n\n\nstatistics\n\n\nsimulations\n\n\nlinear regression\n\n\n\n\n\n\n\n\n\nAug 16, 2019\n\n\nWouter van Amsterdam\n\n\n\n\n\n\nNo matching items"
  }
]