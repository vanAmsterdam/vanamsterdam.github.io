[
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Posts",
    "section": "",
    "text": "The need for speed, performing simulation studies in R, JAX and Julia\n\n\n\n\n\n\nr\n\n\njulia\n\n\njax\n\n\npython\n\n\n\n\n\n\n\n\n\nWouter van Amsterdam\n\n\n\n\n\n\n\n\n\n\n\n\nThe difference between intervention and counterfactuals\n\n\n\n\n\n\ncausal inference\n\n\nstatistics\n\n\n\n\n\n\n\n\n\nJul 25, 2021\n\n\nWouter van Amsterdam\n\n\n\n\n\n\n\n\n\n\n\n\nWhen good predictions lead to bad decisions\n\n\n\n\n\n\ncausal inference\n\n\npredictions\n\n\n\n\n\n\n\n\n\nJul 20, 2021\n\n\nWouter van Amsterdam\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "talks/240312-dsbiostats-twitter/index.html#why-i-use-x-1",
    "href": "talks/240312-dsbiostats-twitter/index.html#why-i-use-x-1",
    "title": "Wouter’s twitter X-peri(ments/ences)",
    "section": "Why (I) use X?",
    "text": "Why (I) use X?\n\n\n\nlearn\n\npapers\nevents (AAAI 2019)\ndiscussions of (/ with?) famous researchers\n\nconnect\nadvertise work"
  },
  {
    "objectID": "talks/240312-dsbiostats-twitter/index.html#why-not-use-x",
    "href": "talks/240312-dsbiostats-twitter/index.html#why-not-use-x",
    "title": "Wouter’s twitter X-peri(ments/ences)",
    "section": "Why not use X?",
    "text": "Why not use X?\n\ntwitter is dead, and X is dying\ndistractions\npolitics"
  },
  {
    "objectID": "talks/240312-dsbiostats-twitter/index.html#x-compared-to",
    "href": "talks/240312-dsbiostats-twitter/index.html#x-compared-to",
    "title": "Wouter’s twitter X-peri(ments/ences)",
    "section": "X compared to",
    "text": "X compared to\n\nlinkedin: fake interactions\ntwitter: too real interactions\nmastodon: too hacky / nerdy?\nthreads: twitter clone by meta (facebook)\nbluesky: way to go?"
  },
  {
    "objectID": "talks/240312-dsbiostats-twitter/index.html#twitter-history-and-status",
    "href": "talks/240312-dsbiostats-twitter/index.html#twitter-history-and-status",
    "title": "Wouter’s twitter X-peri(ments/ences)",
    "section": "Twitter history and status",
    "text": "Twitter history and status\n\njoined: Jan 2014   \n500-ish followers (Maarten has approx. 41400)\n500-ish following (this determines your timeline)\n15-minutes a day but waning"
  },
  {
    "objectID": "talks/240312-dsbiostats-twitter/index.html#first-tweet-that-got-a-like",
    "href": "talks/240312-dsbiostats-twitter/index.html#first-tweet-that-got-a-like",
    "title": "Wouter’s twitter X-peri(ments/ences)",
    "section": "first tweet that got a like",
    "text": "first tweet that got a like"
  },
  {
    "objectID": "talks/240312-dsbiostats-twitter/index.html#first-ad-for-own-paper-on-causal-ml",
    "href": "talks/240312-dsbiostats-twitter/index.html#first-ad-for-own-paper-on-causal-ml",
    "title": "Wouter’s twitter X-peri(ments/ences)",
    "section": "first ad for own paper on causal ML",
    "text": "first ad for own paper on causal ML"
  },
  {
    "objectID": "talks/240312-dsbiostats-twitter/index.html#first-joke-kind-of-success",
    "href": "talks/240312-dsbiostats-twitter/index.html#first-joke-kind-of-success",
    "title": "Wouter’s twitter X-peri(ments/ences)",
    "section": "first joke (kind-of success)",
    "text": "first joke (kind-of success)"
  },
  {
    "objectID": "talks/240312-dsbiostats-twitter/index.html#first-tweet-that-went-viral-recommending-a-paper",
    "href": "talks/240312-dsbiostats-twitter/index.html#first-tweet-that-went-viral-recommending-a-paper",
    "title": "Wouter’s twitter X-peri(ments/ences)",
    "section": "first tweet that went ‘viral’: recommending a paper",
    "text": "first tweet that went ‘viral’: recommending a paper\n\n\n\n\n\n\n259 retweets\n697 likes\n126k views\n8 new followers\nrespected researcher in field asked if I’m interested in doing a post-doc"
  },
  {
    "objectID": "talks/240312-dsbiostats-twitter/index.html#first-paper-run-through-tweet",
    "href": "talks/240312-dsbiostats-twitter/index.html#first-paper-run-through-tweet",
    "title": "Wouter’s twitter X-peri(ments/ences)",
    "section": "first paper run-through tweet",
    "text": "first paper run-through tweet"
  },
  {
    "objectID": "talks/240312-dsbiostats-twitter/index.html#first-paper-run-through-tweet-1",
    "href": "talks/240312-dsbiostats-twitter/index.html#first-paper-run-through-tweet-1",
    "title": "Wouter’s twitter X-peri(ments/ences)",
    "section": "first paper run-through tweet",
    "text": "first paper run-through tweet"
  },
  {
    "objectID": "talks/240312-dsbiostats-twitter/index.html#first-paper-run-through-tweet-2",
    "href": "talks/240312-dsbiostats-twitter/index.html#first-paper-run-through-tweet-2",
    "title": "Wouter’s twitter X-peri(ments/ences)",
    "section": "first paper run-through tweet",
    "text": "first paper run-through tweet"
  },
  {
    "objectID": "talks/240312-dsbiostats-twitter/index.html#first-paper-run-through-tweet-3",
    "href": "talks/240312-dsbiostats-twitter/index.html#first-paper-run-through-tweet-3",
    "title": "Wouter’s twitter X-peri(ments/ences)",
    "section": "first paper run-through tweet",
    "text": "first paper run-through tweet"
  },
  {
    "objectID": "talks/240312-dsbiostats-twitter/index.html#first-paper-run-through-tweet-4",
    "href": "talks/240312-dsbiostats-twitter/index.html#first-paper-run-through-tweet-4",
    "title": "Wouter’s twitter X-peri(ments/ences)",
    "section": "first paper run-through tweet",
    "text": "first paper run-through tweet"
  },
  {
    "objectID": "talks/240312-dsbiostats-twitter/index.html#first-paper-run-through-tweet-5",
    "href": "talks/240312-dsbiostats-twitter/index.html#first-paper-run-through-tweet-5",
    "title": "Wouter’s twitter X-peri(ments/ences)",
    "section": "first paper run-through tweet",
    "text": "first paper run-through tweet\n\n\n\n\n\n35 retweets\n86 likes\n18k views\n0 new followers\nnow 20 citations (5 if not for twitter?)"
  },
  {
    "objectID": "talks/240312-dsbiostats-twitter/index.html#reactions-to-paper-run-through-tweet",
    "href": "talks/240312-dsbiostats-twitter/index.html#reactions-to-paper-run-through-tweet",
    "title": "Wouter’s twitter X-peri(ments/ences)",
    "section": "reactions to paper run-through tweet",
    "text": "reactions to paper run-through tweet"
  },
  {
    "objectID": "talks/240312-dsbiostats-twitter/index.html#reactions-to-paper-run-through-tweet-1",
    "href": "talks/240312-dsbiostats-twitter/index.html#reactions-to-paper-run-through-tweet-1",
    "title": "Wouter’s twitter X-peri(ments/ences)",
    "section": "reactions to paper run-through tweet",
    "text": "reactions to paper run-through tweet"
  },
  {
    "objectID": "talks/240312-dsbiostats-twitter/index.html#favorite-tweet-meme",
    "href": "talks/240312-dsbiostats-twitter/index.html#favorite-tweet-meme",
    "title": "Wouter’s twitter X-peri(ments/ences)",
    "section": "favorite tweet (meme)",
    "text": "favorite tweet (meme)"
  },
  {
    "objectID": "talks/240312-dsbiostats-twitter/index.html#reactions-to-meme-tweet",
    "href": "talks/240312-dsbiostats-twitter/index.html#reactions-to-meme-tweet",
    "title": "Wouter’s twitter X-peri(ments/ences)",
    "section": "reactions to meme-tweet",
    "text": "reactions to meme-tweet\n\nhttps://x.com/JAASANTINHA/status/1417936729600823300?s=20"
  },
  {
    "objectID": "talks/240312-dsbiostats-twitter/index.html#reactions-to-meme-tweet-1",
    "href": "talks/240312-dsbiostats-twitter/index.html#reactions-to-meme-tweet-1",
    "title": "Wouter’s twitter X-peri(ments/ences)",
    "section": "reactions to meme-tweet",
    "text": "reactions to meme-tweet\n\nThis has been a finding from decision curve analysis for at least 10 years!— Andrew Vickers (@VickersBiostats) July 21, 2021"
  },
  {
    "objectID": "talks/240312-dsbiostats-twitter/index.html#biggest-own-tweet-thesis-cover",
    "href": "talks/240312-dsbiostats-twitter/index.html#biggest-own-tweet-thesis-cover",
    "title": "Wouter’s twitter X-peri(ments/ences)",
    "section": "biggest own tweet (thesis cover):",
    "text": "biggest own tweet (thesis cover):\n\n\n\n\n\n\n93k impressions\n673 likes\n53 retweets\n6 new followers"
  },
  {
    "objectID": "talks/240312-dsbiostats-twitter/index.html#ask-for-help-tweet",
    "href": "talks/240312-dsbiostats-twitter/index.html#ask-for-help-tweet",
    "title": "Wouter’s twitter X-peri(ments/ences)",
    "section": "ask for help-tweet",
    "text": "ask for help-tweet"
  },
  {
    "objectID": "talks/240312-dsbiostats-twitter/index.html#use-x-for",
    "href": "talks/240312-dsbiostats-twitter/index.html#use-x-for",
    "title": "Wouter’s twitter X-peri(ments/ences)",
    "section": "Use X for",
    "text": "Use X for\n\nlearning\nconnecting\nadvertising:\n\nnew work\nvacancies"
  },
  {
    "objectID": "talks/240312-dsbiostats-twitter/index.html#i-may-leave-x",
    "href": "talks/240312-dsbiostats-twitter/index.html#i-may-leave-x",
    "title": "Wouter’s twitter X-peri(ments/ences)",
    "section": "I may leave X",
    "text": "I may leave X\nnot sure where to go\n\n\n\n©Wouter van Amsterdam @WvanAmsterdam"
  },
  {
    "objectID": "talks.html",
    "href": "talks.html",
    "title": "Talks",
    "section": "",
    "text": "Wouter’s twitter X-peri(ments/ences)\n\n\n\n\n\n\n\n\n\n\n\nMar 12, 2024\n\n\nWouter van Amsterdam\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/210720-good_predictions_bad_decisions.html",
    "href": "posts/210720-good_predictions_bad_decisions.html",
    "title": "When good predictions lead to bad decisions",
    "section": "",
    "text": "A common premise in prediction research for clinical outcomes is that better predictions lead to better (informed) decisions. This causal statement, that the intervention of introducing a new prediction rule leads to better decisions and thus better outcomes, is generally not substantiated with sufficient causal arguments. We now present an example where naively introducing a validated new prediction rule can lead to worse clinical decisions.\nFor a certain cancer type there are two treatment options: treatment A and treatment B. From randomized trials, it is known that treatment A is more effective in treating the tumor than treatment B. There is no known variation of treatment effect among subgroups defined by clinical patient characteristics. However, not all patients respond well to treatment. Treatment A is a longer and more intensive treatment regimen than treatment B and leads to more side-effects. The consensus is that it is unethical to give treatment A to patients with a lower than 10% chance of surviving one year, due to the higher risk of side-effects and the lengthy treatment regimen associated with treatment A. In current clinical practice, the probability of 1-year survival is estimated using clinical characteristics. A new research group tries to improve the 1-year survival predictions using a new biomarker. The research endeavor is a success as it turns out that predicting survival with the clinical characteristics and the new biomarker is significantly more accurate than using only the clinical characteristics. A high value for the biomarker is associated with worse overall survival. Having conducted a predictive study, it is not discovered that the treatment effect of treatment A versus B is actually more in favor of treatment A for patients with higher levels of the biomarker. If the new prediction rule would be implemented naively with the same 10% cut-off for 1-year overall survival, this would lead to worse treatment decisions than without using the new prediction model. Some patients with high biomarker values will fall under the 10% cut-off based on the new biomarker, while without the biomarker they would have had a higher than 10% survival probability. This erroneously leads to not recommending treatment A, even though these patients have a high benefit of treatment A.\nNote that this is not an unreasonable example for cancer, as aggressive / fast-growing cancers tend to respond better to treatments like chemotherapy and radiotherapy. One example is non-seminoma versus seminoma testicular cancer."
  },
  {
    "objectID": "posts/210720-good_predictions_bad_decisions.html#defining-the-policies",
    "href": "posts/210720-good_predictions_bad_decisions.html#defining-the-policies",
    "title": "When good predictions lead to bad decisions",
    "section": "Defining the policies",
    "text": "Defining the policies\nThe current clinical policy is:\n\\[\\pi_0(x) = \\mathbf{I}_{E[y|x] &gt; 0}\\]\nSo we should give treatment \\(t=1\\) whenever the expected outcome exceeds the reference cut-off. Let the true data generating mechanism be as following:\n\\[y = \\beta z t + x - z\\]\nAs \\(y\\) is a deterministic function of \\(t,x,z\\), we drop the expectation symbol in the following discussion. Let \\(x,z \\sim \\mathbf{U}(-1,1)\\) be independent variables following a uniform distribution between -1 and 1. We can new express the baseline policy as \\[\\pi_0(x) = \\mathbf{I}_{y|x &gt; 0} = \\mathbf{I}_{E_{z}[y|x,z]&gt;0} \\iff \\mathbf{I}_{x &gt; 0}\\]\nA naive implementation of the new prediction rule incorporating \\(z\\) would lead to the policy \\(\\pi_z(x,z) = \\mathbf{I}_{y|x,z &gt; 0}\\). Plugging in the data generating mechanism we can identify\n\\[\\begin{aligned}\n  y|x,z &= E_{t \\sim \\pi_0(x)}[y|t,x,z] \\\\\n    &= E_{t \\sim \\pi_0(x)}[\\beta z t + x - z] \\\\\n    &= \\beta z E_{t \\sim \\pi_0(x)} [t] + x - z \\\\\n    &= \\beta z E_x [\\mathbf{I}_{x &gt; 0}] + x - z \\\\\n    &= 0.5 \\beta z  + x - z \\\\\n    &= x - (1 - 0.5 \\beta)z\\end{aligned}\\]\nThus \\(\\pi_z(x,z) = \\mathbf{I}_{x + (0.5 \\beta - 1)z &gt; 0}\\).\nFrom the data generating mechanism it is clear that the conditional average treatment effect reduces to\n\\[\\begin{aligned}\n  \\text{CATE(x,z)} &= E[y|\\text{do}(t=1),x,z] - E[y|\\text{do}(t=0),x,z] \\\\\n                   &= \\beta z - 0\\end{aligned}\\]\nThe policy that maximizes the outcome \\(y\\) is \\(\\pi_{\\text{max}(y)}(z) = \\mathbf{I}_{z &gt; 0}\\) as \\(\\text{do}(t=1)\\) leads to better outcomes if and only if \\(z&gt;0\\). To conform with the ethical consensus that the intensive treatment is justified when \\(y|\\text{do}(t),x,z&gt;0\\), we set\n\\[\\begin{aligned}\n    \\pi^*(x,z) &= \\mathbf{I}_{y|\\text{do}(t=1),x,z &gt; 0} \\\\\n           &= \\mathbf{I}_{\\beta z * 1 + x - z &gt; 0} \\\\\n           &= \\mathbf{I}_{x + (\\beta - 1) z &gt; 0}\\end{aligned}\\]"
  },
  {
    "objectID": "posts/210720-good_predictions_bad_decisions.html#expected-utility-of-different-policies",
    "href": "posts/210720-good_predictions_bad_decisions.html#expected-utility-of-different-policies",
    "title": "When good predictions lead to bad decisions",
    "section": "Expected utility of different policies",
    "text": "Expected utility of different policies\nWe can now calculate the expected utility of the different policies \\(\\pi \\in \\{\\pi_0,\\pi_z,\\pi_{\\text{max}(y)},\\pi^*\\}\\) as the expected outcome, \\(U(\\pi) = E_{x,z}E_{t\\sim \\pi(x,z)}y|t,x,z = E_{x,z}\\beta z \\pi(x,z) + x - z\\). The calculation of these expected utilities depends on the treatment effect, which will we assume to be \\(\\beta = 1.5\\). We will use the marginal indepence of \\(x\\) and \\(z\\) to equate \\(E_{x,z}[.] = E_z E_x [.]\\).\n\\[\\begin{aligned}\n    U(\\pi_0) &= E_z E_x [\\beta z \\mathbf{I}_{x &gt; 0} + x - z] \\\\\n         &= \\beta E_z z E_x \\mathbf{I}_{x&gt;0} \\\\\n         &= \\beta E_z z 0.5 \\\\\n         &= 0\\end{aligned}\\]\nWe have \\(\\pi_z(x,z) = \\mathbf{I}_{x - (1 - 0.5 \\beta)z &gt; 0} = \\mathbf{I}_{x &gt; 0.25z}\\)\n\\[\\begin{aligned}\n    U(\\pi_z) &= E_z E_x [\\beta z \\mathbf{I}_{x &gt; 0.25z} + x - z] \\\\\n         &= \\beta E_z z E_x \\mathbf{I}_{x &gt; 0.25z} \\\\\n         &= \\beta E_z z \\text{Pr}(x &gt; 0.25z) \\\\\n         &=^1 \\frac{\\beta}{2} \\int_{-1}^{1} z \\text{Pr}(x &gt; 0.25z) dz\\\\\n         &=^2 \\frac{\\beta}{2} \\int_{-1}^{1} z (1 - \\frac{0.25z+1}{2}) dz\\\\\n         &= \\frac{\\beta}{4} \\int_{-1}^{1} z (1 - 0.25z)dz \\\\\n         &= \\frac{\\beta}{4} \\left[ \\frac{1}{2} z^2 - \\frac{0.25}{3}z^3 + C \\right]_{-1}^1 \\\\\n         &= \\frac{\\beta}{4} \\left( ( \\frac{1}{2} - \\frac{0.25}{3}) - ( \\frac{1}{2} + \\frac{0.25}{3}) \\right) \\\\\n         &= - \\frac{\\beta}{2} \\frac{0.25}{3} \\\\\n         &= - 0.075\\end{aligned}\\]\nWhere in \\(^1\\) we used the \\(U(-1,1)\\) distribution of \\(z\\) and in \\(^2\\) we used the probability density function of \\(x\\) and the fact that \\(-1 &lt; 0.25z &lt; 1\\). This demonstrates that the policy following the (accurate!) prediction model \\(y|x,z\\) leads to worse clinical outcomes than the previous situation that relied on \\(x\\) only.\nThe reader may verify that \\[\\begin{aligned}\n    U(\\pi_{\\text{max}(y)}) &= 0.375 \\\\\n    U(\\pi^*) &= 0.125\\end{aligned}\\]"
  },
  {
    "objectID": "posts/240308-jaxopt-vs-r-vs-julia/index.html",
    "href": "posts/240308-jaxopt-vs-r-vs-julia/index.html",
    "title": "The need for speed, performing simulation studies in R, JAX and Julia",
    "section": "",
    "text": "When using simulations to support scientific claims, the more experiments the better. Having the ability to perform many experiments fast allows researchers to:\nThe R language has been a popular language among many biostatisticians for a long time, but it is not generally considered the top performing language in terms of speed, especially when it comes to leveraging GPUs for calculations that are amenable to vectorization (such as performing simulation studies across a large grid). In recent years, JAX (developed by Google) and Julia have arisen as general scientific computation frameworks. JAX and Julia have grown in popularity both in the neural network community as in other scientific communities (e.g. “DifferentiableUniverseInitiative/Jax_cosmo” 2024; “SciML: Open Source Software for Scientific Machine Learning” n.d.) In this blog post I’ll compare R with JAX and Julia for a simple simulation study setup with logistic regression.\nWe’ll look at the following comparisons:"
  },
  {
    "objectID": "posts/240308-jaxopt-vs-r-vs-julia/index.html#r-vs-jax-vs-julia-a-high-level-overview",
    "href": "posts/240308-jaxopt-vs-r-vs-julia/index.html#r-vs-jax-vs-julia-a-high-level-overview",
    "title": "The need for speed, performing simulation studies in R, JAX and Julia",
    "section": "R vs JAX vs Julia a high level overview",
    "text": "R vs JAX vs Julia a high level overview\nWithout going in too much details, JAX works by translating python code into an intermediate language that can be run very efficiently on different hardware backends (CPU, GPU, TPU) through just-in-time compilation (JIT). JAX prides itself on providing composable transformations for vectorization (vmap), paralellization (pmap) and automatic differentiation (grad), all compatible with jit In R, most of the heavy lifting in terms of computation (such as fitting a logistic regression model) is implemented in high-speed languages such as C++ or Fortran. The usual R-code merely provides an interface to these languages and allows the user to feed in data and analyze results. Whereas using JAX and R means working with two languages (one language to write accessible code, another to do fast computation), Julia is a just-in-time compiled language where such translation is not needed."
  },
  {
    "objectID": "posts/240308-jaxopt-vs-r-vs-julia/index.html#the-basic-setup",
    "href": "posts/240308-jaxopt-vs-r-vs-julia/index.html#the-basic-setup",
    "title": "The need for speed, performing simulation studies in R, JAX and Julia",
    "section": "The basic setup",
    "text": "The basic setup\nWe’ll be running a simple logistic regression simulation setup, where for each observation:\n\\[\n\\begin{align}\n\\mathbf{x}_{\\text{full}} &\\sim \\mathcal{N}(0,I) \\in \\mathbb{R}^{10} \\\\\ny &= ||\\mathbf{x}||_0 &gt; 0 \\\\\n\\mathbf{x}_{\\text{obs}} &= [x_0\\ x_i \\ldots x_9]\n\\end{align}\n\\]\nSo \\(y\\) is the sum of elements of \\(\\mathbf{x}_{\\text{full}}\\) and the observed \\(\\mathbf{x}_{\\text{obs}}\\) contains only the first 9 out of 10 elements of \\(\\mathbf{x}_{\\text{full}}\\).\nWe will model this data with logistic regression:\n\\[\n\\text{logit}(y) = \\mathbf{x}_{\\text{obs}} \\boldsymbol{\\beta}'\n\\]\nwhere \\(\\boldsymbol{\\beta} = [\\beta_1,\\ldots,\\beta_9]\\) is a 9-dimensional parameter vector that is to be estimated (we’re excluding the usual intercept term). We’ll generate nrep independent datasets and estimate \\(\\boldsymbol{\\beta}\\) in each one, and finally calculate the average parameter estimates \\(\\frac{1}{\\text{nrep}}\\sum_{i=1}^{\\text{nrep}}\\boldsymbol{\\beta}^i\\), averaged over each repetition i."
  },
  {
    "objectID": "posts/240308-jaxopt-vs-r-vs-julia/index.html#the-code",
    "href": "posts/240308-jaxopt-vs-r-vs-julia/index.html#the-code",
    "title": "The need for speed, performing simulation studies in R, JAX and Julia",
    "section": "The code",
    "text": "The code\nMaking the data\n\nRPythonJulia\n\n\nmake_data &lt;- function(n=1e3L) {\n    x_vec = rnorm(n*10)\n    X_full = matrix(x_vec, ncol=10)\n    eta = rowSums(X_full)\n    y = eta &gt; 0\n    # return only first 9 column to have some noise\n    X = X_full[,1:9]\n    return(list(X=X,y=y))\n}\n\n\ndef make_data(k, n=int(1e3)):\n    X_full = random.normal(k, (n,10)) # JAX needs explicit keys for psuedo random number generation\n    eta = jnp.sum(X_full, axis=-1)\n    y = eta &gt; 0\n    # return only first 9 column to have some noise\n    X = X_full[:,:9]\n    return (X, y)\n\n\nfunction make_data(n::Integer=1000)\n    X_full = randn(n,10)\n    eta = vec(sum(X_full, dims=2))\n    y = eta .&gt; 0 # vectorized greater than 0 comparison\n    X = X_full[:,1:9]\n    return X, y\nend\n\n\n\nThe write the code for a single analysis step, generating data and fitting the logistic regression. For R and Julia we will use the glm function to estimate the logistic regression model. The Julia code looks much like the R code In JAX there is no glm function. Instead, we need to specify an objective function and will use a general purpose optimizer. JaxOpt conveniently provides both binary_logreg as an objective functoin and LBFGS, a popular general purpose optimizer.\n\nRPythonJulia\n\n\nsolve &lt;- function(...) {\n  data = make_data()\n  fit = glm(data$y~data$X-1, family='binomial')\n  coefs = coef(fit)\n  return(coefs)\n}\n\n\n# initialize a generic solver with the correct objective function\nsolver = LBFGS(binary_logreg)\nw_init = jnp.zeros((9,))\n\n@jit # jit toggles just-in-time compilation, one of the main features of JAX\ndef solve(k):\n    # need to specify parameter initialization values\n    data = make_data(k)\n    param, state = solver.run(w_init, data)\n    return param\n\n\nfunction solve(i::Int64=1)\n    X, y = make_data()\n    fit = glm(X, y, Bernoulli())\n    coefs = coef(fit)\n    return coefs\nend\n\n\n\nFinally we run the experiments nrep times and calculate the average coefficient vector\n\nRPythonJulia\n\n\nset.seed(240316)\nparams &lt;- lapply(1:nreps, solve)\noutmat &lt;- do.call(rbind, params)\nmeans &lt;- colMeans(outmat)\nprint(means)\n\n\nk0 = random.PRNGKey(240316)\nks = random.split(k, nreps)\nparams = vmap(solve)(ks) # vmap vectorizes computations\nmeans = jnp.mean(params, axis=0)\nprint(means)\n\n\nRandom.seed!(240316)\noutmat = zeros(nreps, 9)\n\n@threads for i in 1:nreps # use @threads for multi-threading\n    solution = solve()\n    outmat[i,:] = solve()\nend\n\nmeans = mean(outmat, dims=1)\nprint(means)"
  },
  {
    "objectID": "posts/240308-jaxopt-vs-r-vs-julia/index.html#the-speed",
    "href": "posts/240308-jaxopt-vs-r-vs-julia/index.html#the-speed",
    "title": "The need for speed, performing simulation studies in R, JAX and Julia",
    "section": "The speed",
    "text": "The speed\nSpeed plots"
  },
  {
    "objectID": "posts/240308-jaxopt-vs-r-vs-julia/index.html#conclusions",
    "href": "posts/240308-jaxopt-vs-r-vs-julia/index.html#conclusions",
    "title": "The need for speed, performing simulation studies in R, JAX and Julia",
    "section": "Conclusions",
    "text": "Conclusions\nassuming familiarity R &gt; Julia &gt; JAX\nDimensions:\n\nhave GPU – have many threads\nrely on standard stats / need summary stats – have custom objectives / need autograd"
  },
  {
    "objectID": "posts/240308-jaxopt-vs-r-vs-julia/index.html#discussion",
    "href": "posts/240308-jaxopt-vs-r-vs-julia/index.html#discussion",
    "title": "The need for speed, performing simulation studies in R, JAX and Julia",
    "section": "Discussion",
    "text": "Discussion\nJAX was able to get a 86 times speed-up compared to single-threaded R, and 8 times compared to R on 10 threads. JAX does come with some ‘sharp bits’ (see link) that if not followed correctly lead to suboptimal performance and/or unexpected behavior, e.g. it requires functional programming.\nNote that JAX-opt gives pretty-bare bones results with only parameters, likelihood of the observed data at the final parameter estimate and some optimization statistics (number of iterations, convergence). But not e.g. variance estimates and all sorts of other things returned by glm in R.\nIn conculsion, should you learn JAX for simulations? - If you can program in python / numpy, yes - If you’ll write custom objectives and want to apply gradient-based optimization, yes. - If you don’t have a GPU but have many CPU-threads available, probably no\nFinally, when it comes to analyzing results from millions of simulation experiments, R’s data.table really shines when it comes to speed in reading, writing, subsetting and analyzing results. It’s orders of magnitudes faster than pythons pandas for many tasks and pretty much the fastest framework for in-memory data.frame-style operations across all languages.\nMy workflow: 1. run simulations in JAX 2. analyze results in R using data.table\n\nLimitations\nCannot easily set number of threads in JAX (see e.g. this issue on github)."
  },
  {
    "objectID": "posts/240308-jaxopt-vs-r-vs-julia/index.html#extensions",
    "href": "posts/240308-jaxopt-vs-r-vs-julia/index.html#extensions",
    "title": "The need for speed, performing simulation studies in R, JAX and Julia",
    "section": "Extensions",
    "text": "Extensions\nJulia is another JIT-compiled language that would be interesting to compare against."
  },
  {
    "objectID": "posts/240308-jaxopt-vs-r-vs-julia/index.html#computing-environment",
    "href": "posts/240308-jaxopt-vs-r-vs-julia/index.html#computing-environment",
    "title": "The need for speed, performing simulation studies in R, JAX and Julia",
    "section": "Computing environment",
    "text": "Computing environment\nAll tests conducted on linux cluster with 12 threads and a NVIDIA Quadro P-6000 GPU"
  },
  {
    "objectID": "posts/240308-jaxopt-vs-r-vs-julia/index.html#full-scripts",
    "href": "posts/240308-jaxopt-vs-r-vs-julia/index.html#full-scripts",
    "title": "The need for speed, performing simulation studies in R, JAX and Julia",
    "section": "Full scripts",
    "text": "Full scripts\n\nRPythonJulia\n\n\n# rspeed\nargs = commandArgs(trailingOnly = T)\nif (length(args) == 0) {\n  nreps = 100\n  nthreads = 1\n} else if (length(args) == 1) {\n  nreps = as.integer(args[1])\n  nthreads = 1\n} else {\n  nreps = as.integer(args[1])\n  nthreads = as.integer(args[2])\n  library(furrr)\n  plan(multisession, workers=nthreads)\n}\n\nmake_data &lt;- function(n=1e3L) {\n    x_vec = rnorm(n*10)\n    X_full = matrix(x_vec, ncol=10)\n    eta = rowSums(X_full)\n    y = eta &gt; 0\n    # return only first 9 column to have some noise\n    X = X_full[,1:9]\n    return(list(X=X,y=y))\n}\n\nsolve &lt;- function(...) {\n  data = make_data()\n  fit = glm(data$y~data$X-1, family='binomial')\n  coefs = coef(fit)\n  return(coefs)\n}\n\nif (nthreads == 1) {\n    set.seed(240316)\n    params &lt;- lapply(1:nreps, solve)\n} else {\n    params &lt;- future_map(1:nreps, solve, .options=furrr_options(seed=240316))\n}\n\noutmat &lt;- do.call(rbind, params)\nmeans &lt;- colMeans(outmat)\nprint(means)\n\n\n\nimport jax, jaxopt\n# jax.config.update('jax_platform_name', 'cpu')\nfrom jax import numpy as jnp, random, vmap, jit\nfrom jaxopt import LBFGS\nfrom jaxopt.objective import binary_logreg\nfrom argparse import ArgumentParser\n\nparser = ArgumentParser()\nparser.add_argument('nreps', nargs=\"?\", type=int, default=int(10))\n\ndef make_data(k, n=int(1e3)):\n    X_full = random.normal(k, (n,10)) # JAX needs explicit keys for psuedo random number generation\n    eta = jnp.sum(X_full, axis=-1)\n    y = eta &gt; 0\n    # return only first 9 column to have some noise\n    X = X_full[:,:9]\n    return (X, y)\n\n# initialize a generic solver with the correct objective function\nsolver = LBFGS(binary_logreg)\nw_init = jnp.zeros((9,))\n\n@jit # jit toggles just-in-time compilation, one of the main features of JAX\ndef solve(k):\n    # need to specify parameter initialization values\n    data = make_data(k)\n    param, state = solver.run(w_init, data)\n    return param\n\nif __name__ == '__main__':\n    args = parser.parse_args()\n    k0 = random.PRNGKey(240316)\n    ks = random.split(k0, args.nreps)\n    params = vmap(solve)(ks) # vmap vectorizes computations\n    means = jnp.mean(params, axis=0)\n    print(means)\n\n\n\n\nusing Random, GLM, StatsBase, ArgParse\nimport Base.Threads.@threads\n\nfunction parse_cmdline()\n    parser = ArgParseSettings()\n\n    @add_arg_table parser begin\n        \"nreps\"\n          help = \"number of repetitions\"\n          required = false\n          arg_type = Int\n          default = 10\n    end\n\n    return parse_args(parser)\nend\n\nfunction make_data(n::Integer=1000)\n    X_full = randn(n,10)\n    eta = vec(sum(X_full, dims=2))\n    y = eta .&gt; 0 # vectorized greater than 0 comparison\n    X = X_full[:,1:9]\n    return X, y\nend\n\nfunction solve(i::Int64=1)\n    X, y = make_data()\n    fit = glm(X, y, Bernoulli())\n    coefs = coef(fit)\n    return coefs\nend\n\nfunction main()\n    args = parse_cmdline()\n    nreps = get(args, \"nreps\", 10)\n\n    Random.seed!(240316)\n    outmat = zeros(nreps, 9)\n\n    @threads for i in 1:nreps # use @threads for multi-threading\n        solution = solve()\n        outmat[i,:] = solve()\n    end\n\n    means = mean(outmat, dims=1)\n    print(means)\nend\n\nmain()"
  },
  {
    "objectID": "posts/240308-jaxopt-vs-r-vs-julia/index.html#references",
    "href": "posts/240308-jaxopt-vs-r-vs-julia/index.html#references",
    "title": "The need for speed, performing simulation studies in R, JAX and Julia",
    "section": "References",
    "text": "References\n\n\n“DifferentiableUniverseInitiative/Jax_cosmo.” 2024. Differentiable Universe Initiative. https://github.com/DifferentiableUniverseInitiative/jax_cosmo.\n\n\n“SciML: Open Source Software for Scientific Machine Learning.” n.d. Accessed March 14, 2024. https://sciml.ai."
  },
  {
    "objectID": "posts/210725-counterfactualvsinterventional.html",
    "href": "posts/210725-counterfactualvsinterventional.html",
    "title": "The difference between intervention and counterfactuals",
    "section": "",
    "text": "Sometimes there is confusion about the difference between counterfactual predictions and interventional predictions. According to the ladder of causation introduced by Pearl and presented in the ‘Book of Why’, interventional is rung 2 and counterfactuals are rung 3 (associations are rung 1). Models that predict the treatment effect for a new patient based on some covariates \\(X\\) require interventional models, not counterfactual. The difference between interventional and counterfactual models is relevant as counterfactual models require more assumptions, they require knowledge of the structural mechanisms. In words, the interventional question is “What is the expected outcome under treatment \\(t\\) given that we know \\(X\\)”, or “What is the expected difference in outcomes between treatment \\(t\\) and \\(t'\\) given that we know \\(X\\)”. The counterfactual question is “What would have been the outcome if we had given treatment \\(t'\\) given that we gave \\(t\\) and observed outcome \\(y\\)”."
  },
  {
    "objectID": "posts/210725-counterfactualvsinterventional.html#intro",
    "href": "posts/210725-counterfactualvsinterventional.html#intro",
    "title": "The difference between intervention and counterfactuals",
    "section": "",
    "text": "Sometimes there is confusion about the difference between counterfactual predictions and interventional predictions. According to the ladder of causation introduced by Pearl and presented in the ‘Book of Why’, interventional is rung 2 and counterfactuals are rung 3 (associations are rung 1). Models that predict the treatment effect for a new patient based on some covariates \\(X\\) require interventional models, not counterfactual. The difference between interventional and counterfactual models is relevant as counterfactual models require more assumptions, they require knowledge of the structural mechanisms. In words, the interventional question is “What is the expected outcome under treatment \\(t\\) given that we know \\(X\\)”, or “What is the expected difference in outcomes between treatment \\(t\\) and \\(t'\\) given that we know \\(X\\)”. The counterfactual question is “What would have been the outcome if we had given treatment \\(t'\\) given that we gave \\(t\\) and observed outcome \\(y\\)”."
  },
  {
    "objectID": "posts/210725-counterfactualvsinterventional.html#example",
    "href": "posts/210725-counterfactualvsinterventional.html#example",
    "title": "The difference between intervention and counterfactuals",
    "section": "Example",
    "text": "Example\nTo illustrate the difference between a counterfactual prediction and an interventional prediction (or conditional average treatment effect estimates), consider this very simple setup.\nYou have data from a randomized trial with two treatment arms \\(t \\in \\{0,1\\}\\) and an outcome \\(Y\\) on a continuous scale. Denote \\(Y_0\\) the potential outcome under intervening on treatment \\(t=0\\) and \\(Y_1\\) the potential outcome under intervening on treatment \\(t=1\\). As we are dealing with data from a randomized trial, we can easily estimate the average treatment effect as \\(E[Y_1 - Y_0] = E[Y|t=0] - E[Y|t=1]\\), assuming consistency (ignorability and overlap are satisfied due to the study design).\nA counterfactual question is: what would have been the outcome \\(Y_0\\) under treatment \\(t=1\\), given that we observed the outcome \\(y_1\\) under treamtent \\(t=1\\), so it is \\(E[Y_0|Y=y_1, t=1]\\).\nNow assume that the data come from a mixture of Gaussians such that\n\\[y|t \\sim (1 - t) \\mathcal{N}(1,0.1^2) + t \\mathcal{N}(10,2.5^2)\\]\nAnd \\(p(t=1)=0.5\\) so both arms are equally large. Treatment \\(t=1\\) leads to higher outcome but also more spread. The relevant interventional expectations are easily calculated by just calculating group means \\(E[Y_0] = E[Y|t=0] = 1\\), \\(E[Y_1] = E[Y|t=1] = 10\\).\n\nCalculating the counterfactuals\nTo see that calculating counterfactuals requires more knowledge, namely of the structural equations, we now calculate the counterfactual prediction for a patient with \\(Y=Y_1=15\\). This is a patient with a relatively large ‘residual’, the outcome is 2 standard deviations above the mean for treatment group \\(t=1\\).\nFirst we calculate the counterfactual outcome under a wrong outcome model. Researchers tried to model the outcomes using linear regression, and failed to appreciate the difference in variances between the two treatment arms (heteroscedasticity). Assuming a large sample, they will arrive at a model:\n\\[\\hat{y}_{\\text{wrong}} = 1 + t * 9 + \\mathcal{N}(0,\\sigma^2)\\]\nWhere \\(\\sigma = \\sqrt{\\frac{0.1^2 + 2.5^2}{2}} \\approx 1.77\\) (standard devation of mixture of Gaussians with (conditional) mean of 0 and standard deviations 0.1 and 2.5, with 50 / 50 mixing). Note that the estimate of the treatment effect is correct, and so are \\(E[Y_0]\\) and \\(E[Y_1]\\). If there was a binary pre-treatment covariate, the conditional average treatment effect could be estimated by repeating this exercise for both levels of the covariate. To calculate the counterfactual outcome of our patient, we first need to determine the value of their noise variable for the outcome. According to \\(\\hat{y}_{\\text{wrong}}\\), the residual for a patient with \\(Y_1=15\\) is \\(5\\), which is \\(5/\\sigma \\approx 2.82\\) standard deviations away from the expected value for \\(t=1\\). Given this residual we can now calculate the counterfactual:\n\\[\\widehat{E_{\\text{wrong}}}[Y_0|Y=15,t=1] \\approx E[Y_0] + 2.82 \\sigma =6\\]\nGiven that we know the data generating mechanism, we know that this counterfactual prediction is 50 standard deviations from the conditional mean of \\(t=0\\) in the data generating mechanism, clearly this counterfactual prediction is wrong.\nIf we did model the data correctly with a mixture of Gaussians indexed by the treatment group, we would instead say that \\(Y_1=15\\) is 2 standard deviations above the conditional mean, and we would calculate:\n\\[\\widehat{E^*}[Y_0|Y=15,t=1] = E[Y_0] + 2 * 0.1 =1.2\\]\nWhich is correct."
  },
  {
    "objectID": "posts/210725-counterfactualvsinterventional.html#conclusion",
    "href": "posts/210725-counterfactualvsinterventional.html#conclusion",
    "title": "The difference between intervention and counterfactuals",
    "section": "Conclusion",
    "text": "Conclusion\nTo calculate counterfactual predictions, you need to correctly specify the structural equations. For treatment recommendations for future patients, these are not needed, interventional estimates (conditional average treatment effect) are sufficient, and obviously the factual outcome is not observed yet so it is impossible to calculate counterfactuals (the factual is not yet known).\nPost-script: for ‘real’ patient counsellling the expected values under the treatments would generally not suffice, some measure of spread / uncertainty would be required. Ideally, one would learn the distribution of the potential outcomes."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Wouter van Amsterdam, MD, PhD",
    "section": "",
    "text": "Twitter\n  \n  \n    \n     Linkedin\n  \n  \n    \n     ORCID\n  \n  \n    \n     github\n  \n  \n    \n     pubmed\n  \n  \n    \n     google-scholar\n  \n\n  \n  \n\n\nWouter van Amsterdam is an assistant professor at the University Medical Center Utrecht, working on methods and applications of machine learning and causal inference for health care.\nMaster students with a background in statistics or machine learning who want to work with me are welcome to contact me. Students enrolled at Utrecht University or UMC Utrecht can find open master projects on konjoin\n\n\n\nUniversity Medical Center Utrecht / Utrecht University\n2010 | BSc. Physics\n2017 | M.D.\n2021 | MSc. Epidemiology (med. statistics track)\n2022 | PhD. machine learning for healthcare | co-advised by Rajesh Ranganath from NYU\n\n\n\nUMC Utrecht| Assistant Professor | 2023 - now\nBabylon Health | Senior Research Scientist | 2021 - 2023\nCV (pdf)"
  },
  {
    "objectID": "index.html#selected-papers",
    "href": "index.html#selected-papers",
    "title": "Wouter van Amsterdam, MD, PhD",
    "section": "Selected papers",
    "text": "Selected papers\nWhen accurate prediction models yield harmful self-fulfilling prophecies (arXiv:2312.01210).\nvan Amsterdam, W. A. C., van Geloven, N., Krijthe, J. H., Ranganath, R., & Ciná, G. (2024). ML4H 2023 findings-track\npdf\nIndividual treatment effect estimation in the presence of unobserved confounding using proxies: A cohort study in stage III non-small cell lung cancer.  van Amsterdam, W. A. C., Verhoeff, J. J. C., Harlianto, N. I., Bartholomeus, G. A., Puli, A. M., de Jong, P. A., Leiner, T., van Lindert, A. S. R., Eijkemans, M. J. C., & Ranganath, R. (2022). Scientific Reports\npdf\nConditional average treatment effect estimation with marginally constrained models.\nvan Amsterdam, W. A. C., & Ranganath, R. (2023). Journal of Causal Inference\npdf\nDecision making in cancer: Causal questions require causal answers.\nvan Amsterdam, W. A. C., de Jong, P. A., Suijkerbuijk, K. P. M., Verhoeff, J. J. C., Leiner, T., & Ranganath, R. (2022). ArXiv pre-print\npdf\nEliminating biasing signals in lung cancer images for prognosis predictions with deep learning.\nvan Amsterdam, W. A. C., Verhoeff, J. J. C., de Jong, P. A., Leiner, T., & Eijkemans, M. J. C. (2019). Npj Digital Medicine\npdf\nMore papers at google scholar"
  },
  {
    "objectID": "index.html#talks",
    "href": "index.html#talks",
    "title": "Wouter van Amsterdam, MD, PhD",
    "section": "Talks",
    "text": "Talks\n\n\n\n\n\n\n\n\nWouter’s twitter X-peri(ments/ences)\n\n\n\n\n\n\nWouter van Amsterdam\n\n\nMar 12, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#teaching",
    "href": "index.html#teaching",
    "title": "Wouter van Amsterdam, MD, PhD",
    "section": "Teaching",
    "text": "Teaching\n\n2023 Big Data summer school\n2024 Introduction to Causal Inference and Causal Data Science summer school"
  },
  {
    "objectID": "index.html#posts",
    "href": "index.html#posts",
    "title": "Wouter van Amsterdam, MD, PhD",
    "section": "Posts",
    "text": "Posts\n\n\n\n\n\n\n\n\nThe difference between intervention and counterfactuals\n\n\n\n\n\n\nWouter van Amsterdam\n\n\nJul 25, 2021\n\n\n\n\n\n\n\n\n\n\n\n\nThe need for speed, performing simulation studies in R, JAX and Julia\n\n\n\n\n\n\nWouter van Amsterdam\n\n\n\n\n\n\n\n\n\n\n\n\nWhen good predictions lead to bad decisions\n\n\n\n\n\n\nWouter van Amsterdam\n\n\nJul 20, 2021\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#activities",
    "href": "index.html#activities",
    "title": "Wouter van Amsterdam, MD, PhD",
    "section": "Activities",
    "text": "Activities\n\n2023-BMS-ANed (Dutch biometrics society, board member)"
  },
  {
    "objectID": "index.html#contact",
    "href": "index.html#contact",
    "title": "Wouter van Amsterdam, MD, PhD",
    "section": "Contact",
    "text": "Contact\nwamster3 at umcutrecht dot nl"
  }
]