---
title: "Aligning development, deployment and monitoring for AI: a causal perspective"
subtitle: "MLHC pre-conference workshop 2025"
date: 2025/08/14
bibliography: ../../library.bib
format:
    revealjs:
        incremental: true
        theme: [../custom.scss]
        center: true
        fig-align: center
        width: 1600
        height: 900
categories:
  - prediction
  - causal inference
  - wip
  - unlisted
---

# Much of AI is predict - predict - predict

- using ECG, predict presence of structural heart disease, typically diagnosed with cardiac echo
- predict 10-year heart attack risk using basic medical information

# The goal is impact on healthcare

## ECG to SHD [@yaoArtificialIntelligenceEnabled2021]

- prediction: structural heart disease
- intervention: refer patient for cardiac echo
- outcome: diagnosis of structural heart disease
- outcome (impact): reduce preventable early cardiac death

## 10 year heart attack risk [@hippisley-coxDevelopmentValidationNew2024]

- prediction: heart attack in 10 years
- intervention: prescribe cholesterol lowering medication
- outcome: heart attack
- outcome (impact): reduce heart attacks

## Process

- data scientists optimize for predictive accuracy, which entails modeling statistical associations in the 'healthcare system'
- the hope is: better prediction $\implies$ better impact
- unfortunately, this is not automatically the case

## predictive performance vs impact

:::{.columns}

::::{.column width="50%"}

**predictive performance**

- sensitivity, specificity
- AUC
- accuracy
- calibration

![](figs/auc1.png)

::::

::::{.column width="50%"}

**healthcare impact**

- interventions (medical decisions)
- patient outcomes

::::

:::

# When accurate prediction models yield harmful self-fulfilling prophecies [@vanamsterdamWhenAccuratePrediction2025]

---

:::{.r-stack}

![](figs/rt_example1.png){.fragment height=24cm}

![](figs/rt_example2.png){.fragment height=24cm}

![](figs/rt_example3.png){.fragment height=24cm}

![](figs/rt_example4.png){.fragment height=24cm}

![](figs/rt_example5.png){.fragment height=24cm}

![](figs/rt_example6.png){.fragment height=24cm}

:::

## What happened here?

- had a 'good' model, got a bad policy
- model predicted outcome (survival) *under historic treatment policy* (always treat)
- did not predict what outcomes would be under *alternative policy* (no radiation)
- in this case, unmodeled *treatment effect heterogeneity* (aka treatment effect modification, interation, differing conditional average treatment effects)

## Let's monitor the AI model for performance over time 

:::{.r-stack}

![](figs/rt_example6.png){height=24cm}

![](figs/rt_example.png){.fragment height=24cm}

:::

## What happened in monitoring?

- took a measure of predictive performance (AUC)
- mistook it for a measure of (good) impact
- many potential examples (e.g. ICU stop treatment [@balcarcelFeedbackLoopsIntensive2025], others [@sciencemediacenterExpertReactionStudy])

# The devision of predictive performance and policy

## Prediction model: walking stick

:::{.r-stack}

![](figs/stick1.png){.fragment height=24cm}

![](figs/stick2.png){.fragment height=24cm}

:::

## Health care provider: stick user


## References
